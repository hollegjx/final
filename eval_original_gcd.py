#!/usr/bin/env python3
"""
ä¸¥æ ¼æŒ‰ç…§åŸç‰ˆGCDæ–¹å¼çš„æ¨¡å‹è¯„ä¼°è„šæœ¬

å®Œå…¨å¤åˆ¶åŸç‰ˆtest_kmeansçš„é€»è¾‘ï¼š
1. åªä½¿ç”¨base modelï¼Œä¸ç”¨projection head
2. åœ¨base modelç‰¹å¾ç©ºé—´(768ç»´)è¿›è¡Œèšç±»
3. ä¸åŸç‰ˆtrainingæ—¶çš„æµ‹è¯•å®Œå…¨ä¸€è‡´
"""

import argparse
import torch
import numpy as np
from tqdm import tqdm
import os

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from data.get_datasets import get_datasets, get_class_splits
from data.cifar100_superclass import CIFAR100_SUPERCLASSES
from methods.contrastive_training.contrastive_training import test_kmeans_superclass_eval, test_kmeans
from models import vision_transformer as vits
from config import dino_pretrain_path
from project_utils.general_utils import str2bool
from sklearn.cluster import KMeans


def load_original_gcd_model(model_path, args, device):
    """
    æŒ‰ç…§åŸç‰ˆGCDæ–¹å¼åŠ è½½æ¨¡å‹ - åªåŠ è½½base model

    Args:
        model_path: ä¸»æ¨¡å‹æƒé‡è·¯å¾„ (model.ptæˆ–model_best.pt)
        args: å‚æ•°é…ç½®
        device: è®¾å¤‡

    Returns:
        model: åªåŠ è½½base modelï¼Œä¸åŠ è½½projection head
    """
    print(f"ğŸ”„ æŒ‰ç…§åŸç‰ˆGCDæ–¹å¼åŠ è½½æ¨¡å‹...")
    print(f"   æ¨¡å‹æ–‡ä»¶: {model_path}")
    print(f"   âš ï¸  æ³¨æ„: åªåŠ è½½base modelï¼Œä¸ä½¿ç”¨projection head")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

    # æ„å»ºbase modelï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
    if args.base_model == 'vit_dino':
        model = vits.__dict__['vit_base']()

        # åŠ è½½DINOé¢„è®­ç»ƒæƒé‡ï¼ˆä½œä¸ºåŸºç¡€ï¼‰
        if os.path.exists(dino_pretrain_path):
            print(f"   åŠ è½½DINOé¢„è®­ç»ƒæƒé‡: {dino_pretrain_path}")
            dino_state_dict = torch.load(dino_pretrain_path, map_location='cpu')
            model.load_state_dict(dino_state_dict, strict=False)

        # åŠ è½½GCDè®­ç»ƒåçš„æƒé‡
        print(f"   åŠ è½½GCDè®­ç»ƒæƒé‡...")
        gcd_state_dict = torch.load(model_path, map_location='cpu')
        model.load_state_dict(gcd_state_dict)

        model.to(device)

        # æµ‹è¯•æ—¶å…³é—­æ‰€æœ‰æ¢¯åº¦è®¡ç®—
        for param in model.parameters():
            param.requires_grad = False

        print(f"âœ… Base ModelåŠ è½½æˆåŠŸ!")
        print(f"ğŸ” éªŒè¯æ¨¡å‹æ¶æ„:")
        print(f"   Base Modelè¾“å‡ºç»´åº¦: {args.feat_dim}")
        print(f"   è¯„ä¼°ç‰¹å¾ç©ºé—´: {args.feat_dim}ç»´ (base modelç‰¹å¾)")
        print(f"   åŸç‰ˆè®¾è®¡: è®­ç»ƒç”¨projectionç©ºé—´ï¼Œæµ‹è¯•ç”¨baseç©ºé—´")
        print(f"   æ¢¯åº¦è®¡ç®—: å·²å…³é—­ (æµ‹è¯•æ¨¡å¼)")

        return model

    else:
        raise NotImplementedError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {args.base_model}")


def evaluate_on_full_dataset_original(model, args, device):
    """
    ä¸¥æ ¼æŒ‰ç…§åŸç‰ˆæ–¹å¼åœ¨å®Œæ•´CIFAR-100æ•°æ®é›†ä¸Šè¯„ä¼°
    """
    print("\n" + "="*80)
    print("ğŸŒ å®Œæ•´CIFAR-100æ•°æ®é›†è¯„ä¼° (åŸç‰ˆæ–¹å¼)")
    print("="*80)

    # è·å–æ•°æ®é›†é…ç½®
    args_eval = argparse.Namespace(**vars(args))
    args_eval.dataset_name = 'cifar100'

    # è·å–ç±»åˆ«åˆ’åˆ†
    args_eval = get_class_splits(args_eval)
    args_eval.num_labeled_classes = len(args_eval.train_classes)
    args_eval.num_unlabeled_classes = len(args_eval.unlabeled_classes)

    # ç¡®ä¿test_classesåŒ…å«æ‰€æœ‰ç±»åˆ«
    all_classes = list(args_eval.train_classes) + list(args_eval.unlabeled_classes)
    args_eval.test_classes = sorted(all_classes)

    print(f"ğŸ“Š å·²çŸ¥ç±»åˆ«: {list(args_eval.train_classes)} (å…±{args_eval.num_labeled_classes}ä¸ª)")
    print(f"ğŸ“Š æœªçŸ¥ç±»åˆ«: {list(args_eval.unlabeled_classes)} (å…±{args_eval.num_unlabeled_classes}ä¸ª)")
    print(f"ğŸ“Š æµ‹è¯•ç±»åˆ«: {len(args_eval.test_classes)}ä¸ªç±»åˆ«")

    # è·å–æ­£ç¡®çš„transform (æŒ‰ç…§åŸç‰ˆGCDä½¿ç”¨imagenet transform)
    from data.augmentations import get_transform
    # åŸç‰ˆGCDåœ¨CIFARä¸Šä½¿ç”¨imagenet transformï¼Œä¼šresizeåˆ°224
    train_transform, test_transform = get_transform('imagenet', image_size=224, args=args_eval)

    train_dataset, test_dataset, unlabelled_train_examples_test, datasets = get_datasets(
        args_eval.dataset_name,
        train_transform=train_transform,
        test_transform=test_transform,
        args=args_eval
    )

    # æŒ‰ç…§åŸç‰ˆæ–¹å¼æ‰‹åŠ¨åˆ›å»ºtest_loader
    from torch.utils.data import DataLoader
    test_loader = DataLoader(
        test_dataset,
        num_workers=args_eval.num_workers,
        batch_size=args_eval.batch_size,
        shuffle=False
    )

    model.eval()

    print(f"ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (åŸç‰ˆtest_kmeansæ–¹å¼)...")
    print(f"ğŸ“Š ä½¿ç”¨è¯„ä¼°å‡½æ•°: {args_eval.eval_funcs}")
    print(f"ğŸ“Š K-meansèšç±»æ•°: {args_eval.num_labeled_classes + args_eval.num_unlabeled_classes}")

    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ” æ•°æ®åŠ è½½å™¨é…ç½®:")
    print(f"   Batch size: {args_eval.batch_size}")
    print(f"   Image size: {args_eval.image_size}")

    # æµ‹è¯•ä¸€ä¸ªbatchçš„æ•°æ®
    for batch_idx, (images, label, _) in enumerate(test_loader):
        print(f"   ç¬¬ä¸€ä¸ªbatchå½¢çŠ¶: {images.shape}")
        print(f"   æ•°æ®ç±»å‹: {type(images)}")
        break

    # ä½¿ç”¨åŸç‰ˆçš„test_kmeanså‡½æ•°
    all_acc, old_acc, new_acc = test_kmeans(
        model, test_loader, epoch=0, save_name='Original_Full_Dataset_Test',
        args=args_eval, device=device
    )

    print(f"ğŸ“ˆ å®Œæ•´æ•°æ®é›†è¯„ä¼°ç»“æœ (åŸç‰ˆæ–¹å¼):")
    print(f"   All ACC: {all_acc:.4f}")
    print(f"   Old ACC: {old_acc:.4f}")
    print(f"   New ACC: {new_acc:.4f}")

    return all_acc, old_acc, new_acc


def evaluate_on_superclass_original(model, superclass_name, args, device):
    """
    ä¸¥æ ¼æŒ‰ç…§åŸç‰ˆæ–¹å¼åœ¨æŒ‡å®šè¶…ç±»ä¸Šè¯„ä¼°
    """
    print(f"\n" + "="*80)
    print(f"ğŸ¯ è¶…ç±» '{superclass_name}' è¯„ä¼° (åŸç‰ˆæ–¹å¼)")
    print("="*80)

    if superclass_name not in CIFAR100_SUPERCLASSES:
        print(f"âŒ é”™è¯¯: æœªçŸ¥çš„è¶…ç±»åç§° '{superclass_name}'")
        return None, None, None

    # è·å–å®Œæ•´æ•°æ®é›†é…ç½®
    args_eval = argparse.Namespace(**vars(args))
    args_eval.dataset_name = 'cifar100'

    # è·å–ç±»åˆ«åˆ’åˆ†
    args_eval = get_class_splits(args_eval)
    args_eval.num_labeled_classes = len(args_eval.train_classes)
    args_eval.num_unlabeled_classes = len(args_eval.unlabeled_classes)

    # ç¡®ä¿test_classesåŒ…å«æ‰€æœ‰ç±»åˆ«
    all_classes = list(args_eval.train_classes) + list(args_eval.unlabeled_classes)
    args_eval.test_classes = sorted(all_classes)

    print(f"ğŸ“Š å·²çŸ¥ç±»åˆ«: {list(args_eval.train_classes)} (å…±{args_eval.num_labeled_classes}ä¸ª)")
    print(f"ğŸ“Š æœªçŸ¥ç±»åˆ«: {list(args_eval.unlabeled_classes)} (å…±{args_eval.num_unlabeled_classes}ä¸ª)")

    # è·å–æ­£ç¡®çš„transform (æŒ‰ç…§åŸç‰ˆGCDä½¿ç”¨imagenet transform)
    from data.augmentations import get_transform
    # åŸç‰ˆGCDåœ¨CIFARä¸Šä½¿ç”¨imagenet transformï¼Œä¼šresizeåˆ°224
    train_transform, test_transform = get_transform('imagenet', image_size=224, args=args_eval)

    train_dataset, test_dataset, unlabelled_train_examples_test, datasets = get_datasets(
        args_eval.dataset_name,
        train_transform=train_transform,
        test_transform=test_transform,
        args=args_eval
    )

    # æŒ‰ç…§åŸç‰ˆæ–¹å¼æ‰‹åŠ¨åˆ›å»ºtest_loader
    from torch.utils.data import DataLoader
    test_loader = DataLoader(
        test_dataset,
        num_workers=args_eval.num_workers,
        batch_size=args_eval.batch_size,
        shuffle=False
    )

    model.eval()

    # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¶…ç±»è¯„ä¼°
    superclass_classes = CIFAR100_SUPERCLASSES[superclass_name]
    print(f"ğŸ“Š è¶…ç±»åŒ…å«ç±»åˆ«: {superclass_classes}")
    print(f"ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (åŸç‰ˆæ–¹å¼)...")
    print(f"ğŸ“Š ä½¿ç”¨è¯„ä¼°å‡½æ•°: {args_eval.eval_funcs}")

    # ä½¿ç”¨åŸç‰ˆçš„test_kmeans_superclass_evalå‡½æ•°
    all_acc, old_acc, new_acc = test_kmeans_superclass_eval(
        model, test_loader, epoch=0, save_name=f'Original_Superclass_{superclass_name}_Test',
        args=args_eval, eval_superclass=superclass_name, device=device
    )

    return all_acc, old_acc, new_acc


def evaluate_all_superclasses_original(model, args, device):
    """
    ä¸¥æ ¼æŒ‰ç…§åŸç‰ˆæ–¹å¼åœ¨æ‰€æœ‰è¶…ç±»ä¸Šè¯„ä¼°
    """
    print("\n" + "="*80)
    print("ğŸ” æ‰€æœ‰è¶…ç±»æ‰¹é‡è¯„ä¼° (åŸç‰ˆæ–¹å¼)")
    print("="*80)

    results = {}

    for superclass_name in CIFAR100_SUPERCLASSES.keys():
        try:
            all_acc, old_acc, new_acc = evaluate_on_superclass_original(model, superclass_name, args, device)
            if all_acc is not None:
                results[superclass_name] = {
                    'all_acc': all_acc,
                    'old_acc': old_acc,
                    'new_acc': new_acc
                }
                print(f"âœ… {superclass_name}: All {all_acc:.4f} | Old {old_acc:.4f} | New {new_acc:.4f}")
            else:
                print(f"âŒ {superclass_name}: è¯„ä¼°å¤±è´¥")
        except Exception as e:
            print(f"âŒ {superclass_name}: è¯„ä¼°å‡ºé”™ - {e}")

    # æ˜¾ç¤ºæ±‡æ€»ç»“æœ
    print(f"\nğŸ“Š æ‰€æœ‰è¶…ç±»è¯„ä¼°æ±‡æ€» (åŸç‰ˆæ–¹å¼):")
    print(f"{'è¶…ç±»åç§°':<25} {'All ACC':<10} {'Old ACC':<10} {'New ACC':<10}")
    print("-" * 60)

    for superclass_name, result in results.items():
        print(f"{superclass_name:<25} {result['all_acc']:<10.4f} {result['old_acc']:<10.4f} {result['new_acc']:<10.4f}")

    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¸¥æ ¼æŒ‰ç…§åŸç‰ˆGCDæ–¹å¼è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹')

    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    parser.add_argument('--model_path', type=str, required=True,
                        help='GCDæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ (å¦‚: /path/to/model_best.pt)')

    # è¯„ä¼°æ¨¡å¼
    parser.add_argument('--eval_mode', type=str, choices=['full', 'superclass', 'all_superclasses'],
                        default='full', help='è¯„ä¼°æ¨¡å¼')
    parser.add_argument('--superclass_name', type=str, default=None,
                        help='æŒ‡å®šè¶…ç±»åç§° (å½“eval_mode=superclassæ—¶ä½¿ç”¨)')

    # æ¨¡å‹é…ç½® (åªéœ€è¦base modelç›¸å…³é…ç½®)
    parser.add_argument('--base_model', type=str, default='vit_dino')
    parser.add_argument('--feat_dim', default=768, type=int, help='Base modelç‰¹å¾ç»´åº¦')

    # æ•°æ®é›†é…ç½®
    parser.add_argument('--batch_size', default=128, type=int, help='è¯„ä¼°æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', default=8, type=int)
    parser.add_argument('--eval_funcs', nargs='+', default=['v1'], help='è¯„ä¼°å‡½æ•°')

    # è®¾å¤‡é…ç½®
    parser.add_argument('--gpu', default=0, type=int, help='GPUè®¾å¤‡ID')

    args = parser.parse_args()

    # è®¾å¤‡åˆå§‹åŒ–
    if torch.cuda.is_available():
        device = torch.device(f'cuda:{args.gpu}')
        torch.cuda.set_device(args.gpu)
        print(f"ğŸ’» ä½¿ç”¨GPUè®¾å¤‡: cuda:{args.gpu}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")

    # è®¾ç½®å¿…è¦å‚æ•° (æŒ‰ç…§åŸç‰ˆGCD)
    args.device = device
    args.writer = None
    args.use_ssb_splits = False
    args.prop_train_labels = 0.5
    args.image_size = 224  # ViTå›ºå®šä½¿ç”¨224
    args.interpolation = 3
    args.crop_pct = 0.875

    print("ğŸš€ åŸç‰ˆGCDæ¨¡å‹è¯„ä¼°å·¥å…· (ä¸¥æ ¼åŸç‰ˆæ–¹å¼)")
    print("=" * 80)
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"è¯„ä¼°æ¨¡å¼: {args.eval_mode}")
    if args.eval_mode == 'superclass':
        print(f"ç›®æ ‡è¶…ç±»: {args.superclass_name}")
    print(f"ç‰¹å¾ç»´åº¦: {args.feat_dim} (base model)")
    print("âš ï¸  æ³¨æ„: ä½¿ç”¨åŸç‰ˆè¯„ä¼°æ–¹å¼ï¼Œåªç”¨base modelç‰¹å¾")
    print("=" * 80)

    try:
        # åŠ è½½åŸç‰ˆæ–¹å¼çš„æ¨¡å‹ (åªæœ‰base model)
        model = load_original_gcd_model(args.model_path, args, device)

        # æ ¹æ®è¯„ä¼°æ¨¡å¼è¿›è¡Œè¯„ä¼°
        if args.eval_mode == 'full':
            evaluate_on_full_dataset_original(model, args, device)

        elif args.eval_mode == 'superclass':
            if args.superclass_name is None:
                print("âŒ é”™è¯¯: è¶…ç±»è¯„ä¼°æ¨¡å¼éœ€è¦æŒ‡å®š --superclass_name")
                return
            evaluate_on_superclass_original(model, args.superclass_name, args, device)

        elif args.eval_mode == 'all_superclasses':
            evaluate_all_superclasses_original(model, args, device)

        print("\nğŸ‰ åŸç‰ˆæ–¹å¼è¯„ä¼°å®Œæˆ!")

        # éªŒè¯è¯´æ˜
        print("\n" + "="*80)
        print("ğŸ“‹ åŸç‰ˆGCDè¯„ä¼°æ–¹å¼éªŒè¯:")
        print("âœ… åªä½¿ç”¨base model (768ç»´ç‰¹å¾)")
        print("âœ… ä¸ä½¿ç”¨projection head")
        print("âœ… ä½¿ç”¨å®Œæ•´æµ‹è¯•é›† (åŒ…å«æ‰€æœ‰å·²çŸ¥+æœªçŸ¥ç±»åˆ«)")
        print("âœ… ä½¿ç”¨åŸç‰ˆGCDçš„ç±»åˆ«åˆ’åˆ† (CIFAR-100: 80å·²çŸ¥ + 20æœªçŸ¥)")
        print("âœ… ä½¿ç”¨ç›¸åŒçš„K-meansèšç±»æ•° (100ä¸ªèšç±»)")
        print("âœ… ä½¿ç”¨ç›¸åŒçš„ACCè®¡ç®—æ–¹æ³• (cluster_acc + Hungarianç®—æ³•)")
        print("âœ… ä½¿ç”¨ç›¸åŒçš„maskå®šä¹‰ (åŸºäºtrain_classes)")
        print("")
        print("ğŸ” åŸç‰ˆæ¶æ„è®¾è®¡:")
        print("   è®­ç»ƒæ—¶: model(x) â†’ projection_head(features) â†’ å¯¹æ¯”å­¦ä¹ ")
        print("   è¯„ä¼°æ—¶: model(x) â†’ normalize â†’ K-meansèšç±»")
        print("   ç‰¹ç‚¹: è®­ç»ƒå’Œæµ‹è¯•åœ¨ä¸åŒç‰¹å¾ç©ºé—´è¿›è¡Œ")
        print("="*80)

    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()