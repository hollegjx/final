#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯èƒ½å¦æ­£ç¡®è¯»å–æŒ‡å®šè¶…ç±»çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®
2. æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆkmeansæ–¹æ¡ˆçš„è¦æ±‚ï¼ˆåŒ…å«labeled_or_notæ ‡è®°ï¼‰
3. åˆ†æå·²çŸ¥æ ‡ç­¾æ ·æœ¬å’ŒæœªçŸ¥æ ‡ç­¾æ ·æœ¬çš„åˆ†å¸ƒæƒ…å†µ
4. ç¡®è®¤è®­ç»ƒé›†ä¸­çš„æœ‰æ ‡ç­¾/æ— æ ‡ç­¾æ¯”ä¾‹ç¬¦åˆprop_train_labelsè®¾ç½®
5. éªŒè¯æµ‹è¯•é›†æ˜¯å¦æ­£ç¡®åŒ…å«å·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»æ ·æœ¬
6. ä¸ºè‡ªé€‚åº”èšç±»ç®—æ³•æä¾›æ­£ç¡®çš„æ•°æ®è¾“å…¥æ ¼å¼éªŒè¯

å…³é”®éªŒè¯ç‚¹ï¼š
- è®­ç»ƒé›†ä¸­å·²çŸ¥ç±»çš„æœ‰æ ‡ç­¾æ ·æœ¬æ¯”ä¾‹åº”çº¦ä¸ºprop_train_labels
- è®­ç»ƒé›†ä¸­æœªçŸ¥ç±»æ ·æœ¬åº”å…¨éƒ¨ä¸ºæ— æ ‡ç­¾
- æµ‹è¯•é›†åº”åŒ…å«å·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»æ ·æœ¬
- æ•°æ®æ ¼å¼åº”ä¸º(features, labels, indices, labeled_or_not)
"""

import sys
import os
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.get_datasets import get_datasets, get_class_splits
from data.augmentations import get_transform
from data.cifar100_superclass import CIFAR100_SUPERCLASSES, get_single_superclass_datasets
from models import vision_transformer as vits
from config import dino_pretrain_path, exp_root
from project_utils.general_utils import str2bool


def load_model(args, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆæ¨¡ä»¿eval_original_gcd.pyï¼‰
    """
    print(f"   æ¨¡å‹æ–‡ä»¶: {args.model_path}")
    print(f"   è®¾å¤‡: {device}")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")

    # æ„å»ºbase model
    if args.base_model == 'vit_dino':
        model = vits.__dict__['vit_base']()

        # åŠ è½½DINOé¢„è®­ç»ƒæƒé‡ï¼ˆä½œä¸ºåŸºç¡€ï¼‰
        if os.path.exists(dino_pretrain_path):
            print(f"   åŠ è½½DINOé¢„è®­ç»ƒæƒé‡...")
            dino_state_dict = torch.load(dino_pretrain_path, map_location='cpu')
            model.load_state_dict(dino_state_dict, strict=False)

        # åŠ è½½GCDè®­ç»ƒåçš„æƒé‡
        print(f"   åŠ è½½è®­ç»ƒæƒé‡...")
        gcd_state_dict = torch.load(args.model_path, map_location='cpu')
        model.load_state_dict(gcd_state_dict)

        model.to(device)
        model.eval()

        # å…³é—­æ¢¯åº¦è®¡ç®—
        for param in model.parameters():
            param.requires_grad = False

        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (ç‰¹å¾ç»´åº¦: {args.feat_dim})")
        return model

    else:
        raise NotImplementedError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {args.base_model}")


def test_superclass_data_loading(superclass_name='trees', prop_train_labels=0.8):
    """
    æµ‹è¯•æŒ‡å®šè¶…ç±»çš„æ•°æ®åŠ è½½å’Œæ ‡ç­¾åˆ†æ

    Args:
        superclass_name: è¶…ç±»åç§°
        prop_train_labels: è®­ç»ƒé›†æœ‰æ ‡ç­¾æ ·æœ¬æ¯”ä¾‹
    """
    print(f"ğŸ§ª æµ‹è¯•è¶…ç±» '{superclass_name}' æ•°æ®åŠ è½½")
    print("=" * 80)

    # è®¾ç½®å‚æ•°ï¼ˆæ¨¡ä»¿è®­ç»ƒè„šæœ¬ä½¿ç”¨è¶…ç±»æ•°æ®é›†ï¼‰
    class Args:
        def __init__(self):
            self.dataset_name = 'cifar100_superclass'  # ä½¿ç”¨è¶…ç±»æ•°æ®é›†
            self.superclass_name = superclass_name
            self.prop_train_labels = prop_train_labels
            self.image_size = 224  # æ¨¡ä»¿åŸç‰ˆGCDä½¿ç”¨imagenet transform
            self.num_workers = 4
            self.batch_size = 64  # å‡å°‘å†…å­˜ä½¿ç”¨
            self.base_model = 'vit_dino'
            self.feat_dim = 768  # ViT-Baseç‰¹å¾ç»´åº¦
            self.model_path = os.path.join(
                exp_root,
                'metric_learn_gcd/log/(14.09.2025_|_56.443)/checkpoints/model.pt'
            )
            self.interpolation = 3  # æ·»åŠ ç¼ºå¤±çš„å‚æ•°
            self.crop_pct = 0.875
            self.seed = 0  # æ·»åŠ éšæœºç§å­

    args = Args()

    # éªŒè¯è¶…ç±»æ˜¯å¦å­˜åœ¨
    if superclass_name not in CIFAR100_SUPERCLASSES:
        print(f"âŒ é”™è¯¯: æœªçŸ¥çš„è¶…ç±»åç§° '{superclass_name}'")
        return None, None

    # è·å–è¶…ç±»ä¿¡æ¯
    superclass_classes = set(CIFAR100_SUPERCLASSES[superclass_name])
    print(f"ğŸ“Š è¶…ç±» '{superclass_name}' åŒ…å«ç±»åˆ«: {sorted(list(superclass_classes))}")

    # åŠ è½½æ¨¡å‹ï¼ˆæ¨¡ä»¿eval_original_gcd.pyï¼‰
    print(f"\nğŸ”„ åŠ è½½æ¨¡å‹...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = load_model(args, device)

    # è·å–æ•°æ®å˜æ¢ï¼ˆæ¨¡ä»¿è®­ç»ƒè„šæœ¬ï¼‰
    print(f"ğŸ”„ è·å–æ•°æ®å˜æ¢...")
    train_transform, test_transform = get_transform('imagenet', image_size=args.image_size, args=args)

    # ä½¿ç”¨è¶…ç±»ä¸“ç”¨æ•°æ®é›†å‡½æ•°ï¼ˆæ¨¡ä»¿è®­ç»ƒè„šæœ¬ï¼‰
    print(f"ğŸ”„ åŠ è½½è¶…ç±»æ•°æ®é›†...")
    datasets = get_single_superclass_datasets(
        superclass_name=superclass_name,
        train_transform=train_transform,
        test_transform=test_transform,
        prop_train_labels=args.prop_train_labels,
        split_train_val=False,
        seed=args.seed
    )

    # è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
    train_dataset = datasets['train_labelled']  # æœ‰æ ‡ç­¾è®­ç»ƒæ•°æ®
    unlabelled_train_dataset = datasets['train_unlabelled']  # æ— æ ‡ç­¾è®­ç»ƒæ•°æ®
    test_dataset = datasets['test']  # æµ‹è¯•æ•°æ®

    # åˆ›å»ºMergedDatasetï¼ˆæ¨¡ä»¿è®­ç»ƒè„šæœ¬ï¼‰
    from data.data_utils import MergedDataset
    from copy import deepcopy
    merged_train_dataset = MergedDataset(
        labelled_dataset=deepcopy(train_dataset),
        unlabelled_dataset=deepcopy(unlabelled_train_dataset)
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆåˆ†å¼€è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰
    train_loader = DataLoader(
        merged_train_dataset, num_workers=args.num_workers,
        batch_size=args.batch_size, shuffle=False
    )
    test_loader = DataLoader(
        test_dataset, num_workers=args.num_workers,
        batch_size=args.batch_size, shuffle=False
    )

    # è·å–è¶…ç±»çš„å·²çŸ¥/æœªçŸ¥ç±»åˆ«åˆ’åˆ†ï¼ˆåŸå§‹IDï¼‰
    superclass_known_classes_orig = set([cls for cls in superclass_classes if cls < 80])
    superclass_unknown_classes_orig = set([cls for cls in superclass_classes if cls >= 80])

    # è·å–æ ‡ç­¾æ˜ å°„ï¼ˆè¶…ç±»æ•°æ®é›†ä½¿ç”¨äº†è¿ç»­æ ‡ç­¾æ˜ å°„ï¼‰
    all_classes_sorted = sorted(list(superclass_classes))
    label_mapping = {orig_cls: new_cls for new_cls, orig_cls in enumerate(all_classes_sorted)}

    # æ˜ å°„åçš„ç±»åˆ«IDï¼ˆ0,1,2,3,4ï¼‰
    superclass_known_classes = set([label_mapping[cls] for cls in superclass_known_classes_orig])
    superclass_unknown_classes = set([label_mapping[cls] for cls in superclass_unknown_classes_orig])

    print(f"ğŸ“Š è¶…ç±»å†…ç±»åˆ«åˆ’åˆ†:")
    print(f"   åŸå§‹å·²çŸ¥ç±»: {sorted(list(superclass_known_classes_orig))} -> æ˜ å°„å: {sorted(list(superclass_known_classes))}")
    print(f"   åŸå§‹æœªçŸ¥ç±»: {sorted(list(superclass_unknown_classes_orig))} -> æ˜ å°„å: {sorted(list(superclass_unknown_classes))}")
    print(f"   æ ‡ç­¾æ˜ å°„: {label_mapping}")
    print(f"   æœ‰æ ‡ç­¾æ ·æœ¬æ¯”ä¾‹: {args.prop_train_labels}")

    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
    print(f"   train_labelledå¤§å°: {len(train_dataset)}")
    print(f"   train_unlabelledå¤§å°: {len(unlabelled_train_dataset)}")
    print(f"   merged_train_datasetå¤§å°: {len(merged_train_dataset)}")
    print(f"   test_datasetå¤§å°: {len(test_dataset)}")

    # åˆ†æè®­ç»ƒé›†æ•°æ®ï¼ˆä½¿ç”¨æ¨¡å‹æå–ç‰¹å¾ï¼‰
    print(f"\nğŸ“Š åˆ†æè®­ç»ƒé›†æ•°æ®...")
    train_analysis = analyze_data_with_model(train_loader, "è®­ç»ƒé›†", model, device, superclass_classes, superclass_known_classes, superclass_unknown_classes)

    # åˆ†ææµ‹è¯•é›†æ•°æ®ï¼ˆä½¿ç”¨æ¨¡å‹æå–ç‰¹å¾ï¼‰
    print(f"\nğŸ“Š åˆ†ææµ‹è¯•é›†æ•°æ®...")
    test_analysis = analyze_data_with_model(test_loader, "æµ‹è¯•é›†", model, device, superclass_classes, superclass_known_classes, superclass_unknown_classes)

    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
    print(f"\nğŸ” æ•°æ®ä¸€è‡´æ€§éªŒè¯:")
    validate_data_consistency(train_analysis, test_analysis, args.prop_train_labels)

    return train_analysis, test_analysis


def analyze_data_with_model(data_loader, dataset_name, model, device, superclass_classes, superclass_known_classes, superclass_unknown_classes):
    """
    ä½¿ç”¨æ¨¡å‹åˆ†ææ•°æ®åŠ è½½å™¨ä¸­çš„æ ‡ç­¾åˆ†å¸ƒï¼ˆåªåˆ†æè¶…ç±»æ ·æœ¬ï¼‰
    """
    print(f"   æ­£åœ¨åˆ†æ{dataset_name}...")

    all_labels = []
    all_labeled_masks = []
    all_features = []
    batch_formats = []
    superclass_sample_count = 0

    try:
        model.eval()
        with torch.no_grad():
            for batch_idx, batch_data in enumerate(data_loader):
                # è®°å½•æ‰¹æ¬¡æ ¼å¼
                batch_formats.append(len(batch_data))

                # è§£åŒ…æ•°æ®
                if len(batch_data) == 4:
                    images, labels, indices, labeled_or_not = batch_data
                    labeled_mask = labeled_or_not.numpy().flatten()
                elif len(batch_data) == 3:
                    images, labels, indices = batch_data
                    # æµ‹è¯•é›†æ²¡æœ‰labeled_or_notï¼Œå…¨éƒ¨æ ‡è®°ä¸ºæ— æ ‡ç­¾ï¼ˆèšç±»æ—¶çœ‹ä¸åˆ°æ ‡ç­¾ï¼‰
                    labeled_mask = np.zeros(len(labels))  # æµ‹è¯•é›†å…¨éƒ¨æ— æ ‡ç­¾
                else:
                    print(f"   âš ï¸ å¼‚å¸¸æ‰¹æ¬¡æ ¼å¼: {len(batch_data)}å…ƒç´ ")
                    continue

                # æ•°æ®å·²ç»è¢«è¿‡æ»¤åˆ°è¶…ç±»ï¼Œç›´æ¥å¤„ç†æ‰€æœ‰æ ·æœ¬
                labels_np = labels.numpy()

                # é™é»˜å¤„ç†æ‰€æœ‰batchï¼Œåªåœ¨æœ€åæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯

                # ä½¿ç”¨æ¨¡å‹æå–ç‰¹å¾
                if len(images) > 0:
                    images = images.to(device)
                    with torch.no_grad():  # ç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
                        features = model(images)
                        features_cpu = features.cpu().numpy()

                    all_features.append(features_cpu)
                    all_labels.extend(labels_np)
                    all_labeled_masks.extend(labeled_mask)
                    superclass_sample_count += len(labels_np)

                    # æ¸…ç†GPUå†…å­˜
                    del images, features
                    torch.cuda.empty_cache()

                # åˆ†ææ‰€æœ‰æ‰¹æ¬¡ä»¥è·å¾—å®Œæ•´æ•°æ®åˆ†å¸ƒ
                # ä¸é™åˆ¶æ‰¹æ¬¡æ•°ï¼Œç¡®ä¿ç»Ÿè®¡å®Œæ•´

    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

    # å¦‚æœæ²¡æœ‰è¶…ç±»æ ·æœ¬ï¼Œè¿”å›ç©ºåˆ†æ
    if superclass_sample_count == 0:
        print(f"   âš ï¸ æœªæ‰¾åˆ°å±äºè¶…ç±»çš„æ ·æœ¬")
        return None

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_labels = np.array(all_labels)
    all_labeled_masks = np.array(all_labeled_masks)

    # æ‹¼æ¥ç‰¹å¾
    if all_features:
        all_features = np.concatenate(all_features, axis=0)

    print(f"   è¶…ç±»æ ·æœ¬æ€»æ•°: {superclass_sample_count}")
    print(f"   ç‰¹å¾ç»´åº¦: {all_features.shape if all_features.size > 0 else 'N/A'}")

    # åˆ†ææ ‡ç­¾åˆ†å¸ƒ
    analysis = {}
    analysis['total_samples'] = len(all_labels)
    analysis['batch_formats'] = set(batch_formats)
    analysis['features'] = all_features

    # åˆ†æå·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»ï¼ˆåœ¨è¶…ç±»èŒƒå›´å†…ï¼‰
    known_class_mask = np.isin(all_labels, list(superclass_known_classes))
    unknown_class_mask = np.isin(all_labels, list(superclass_unknown_classes))

    # å·²çŸ¥ç±»æ ·æœ¬åˆ†æ
    known_samples = np.sum(known_class_mask)
    known_labeled = np.sum(known_class_mask & (all_labeled_masks == 1))
    known_unlabeled = np.sum(known_class_mask & (all_labeled_masks == 0))

    # æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯

    # æœªçŸ¥ç±»æ ·æœ¬åˆ†æ
    unknown_samples = np.sum(unknown_class_mask)
    unknown_labeled = np.sum(unknown_class_mask & (all_labeled_masks == 1))
    unknown_unlabeled = np.sum(unknown_class_mask & (all_labeled_masks == 0))

    # æ€»ä½“æ ‡ç­¾åˆ†æ
    total_labeled = np.sum(all_labeled_masks == 1)
    total_unlabeled = np.sum(all_labeled_masks == 0)

    analysis.update({
        'known_samples': known_samples,
        'known_labeled': known_labeled,
        'known_unlabeled': known_unlabeled,
        'unknown_samples': unknown_samples,
        'unknown_labeled': unknown_labeled,
        'unknown_unlabeled': unknown_unlabeled,
        'total_labeled': total_labeled,
        'total_unlabeled': total_unlabeled,
        'superclass_known_classes': superclass_known_classes,
        'superclass_unknown_classes': superclass_unknown_classes
    })

    # è¾“å‡ºåˆ†æç»“æœ
    print(f"   æ‰¹æ¬¡æ ¼å¼: {analysis['batch_formats']}")
    print(f"   è¶…ç±»ä¸­å·²çŸ¥ç±»: {sorted(list(superclass_known_classes))}")
    print(f"   è¶…ç±»ä¸­æœªçŸ¥ç±»: {sorted(list(superclass_unknown_classes))}")
    print(f"   æ€»æœ‰æ ‡ç­¾: {total_labeled}, æ€»æ— æ ‡ç­¾: {total_unlabeled}")
    print(f"   å·²çŸ¥ç±»æ ·æœ¬: {known_samples} (æœ‰æ ‡ç­¾: {known_labeled}, æ— æ ‡ç­¾: {known_unlabeled})")
    print(f"   æœªçŸ¥ç±»æ ·æœ¬: {unknown_samples} (æœ‰æ ‡ç­¾: {unknown_labeled}, æ— æ ‡ç­¾: {unknown_unlabeled})")

    if known_samples > 0:
        known_labeled_ratio = known_labeled / known_samples
        print(f"   å·²çŸ¥ç±»æœ‰æ ‡ç­¾æ¯”ä¾‹: {known_labeled_ratio:.3f}")

    return analysis


def validate_fused_data_consistency(fused_analysis, expected_prop_train_labels, train_labelled_size, train_unlabelled_size, test_size):
    """
    éªŒè¯èåˆæ•°æ®é›†çš„ä¸€è‡´æ€§ï¼ˆæ¨¡ä»¿kmeansè¯„ä¼°æ–¹å¼ï¼‰
    """
    if fused_analysis is None:
        print("   âŒ æ— æ³•éªŒè¯ï¼šèåˆæ•°æ®åˆ†æå¤±è´¥")
        return

    print(f"   æ£€æŸ¥é¡¹ç›®:")

    # æœŸæœ›çš„æ•°æ®åˆ†å¸ƒ
    expected_total = train_labelled_size + train_unlabelled_size + test_size
    expected_train_known_samples = int(train_labelled_size / expected_prop_train_labels)  # è®­ç»ƒé›†ä¸­å·²çŸ¥ç±»æ€»æ•°
    expected_train_known_labeled = train_labelled_size  # è®­ç»ƒé›†ä¸­å·²çŸ¥ç±»æœ‰æ ‡ç­¾æ•°
    expected_test_unlabeled = test_size  # æµ‹è¯•é›†å…¨éƒ¨æ— æ ‡ç­¾ï¼ˆéœ€è¦èšç±»é¢„æµ‹ï¼‰

    print(f"   ğŸ“Š æœŸæœ›åˆ†å¸ƒ:")
    print(f"     æ€»æ ·æœ¬: {expected_total}")
    print(f"     è®­ç»ƒé›†å·²çŸ¥ç±»: {expected_train_known_samples} (æœ‰æ ‡ç­¾: {expected_train_known_labeled})")
    print(f"     æµ‹è¯•é›†: {test_size} (å…¨éƒ¨æ— æ ‡ç­¾ï¼Œå¾…èšç±»é¢„æµ‹)")

    print(f"   ğŸ“Š å®é™…åˆ†å¸ƒ:")
    print(f"     æ€»æ ·æœ¬: {fused_analysis['total_samples']}")
    print(f"     å·²çŸ¥ç±»æ ·æœ¬: {fused_analysis['known_samples']} (èšç±»ç®—æ³•çŸ¥é“è¿™äº›æ¥è‡ªè®­ç»ƒè§è¿‡çš„ç±»)")
    print(f"     æœªçŸ¥ç±»æ ·æœ¬: {fused_analysis['unknown_samples']} (èšç±»ç®—æ³•ä¸çŸ¥é“è¿™äº›æ¥è‡ªæ–°ç±»)")
    print(f"     æ€»æœ‰æ ‡ç­¾: {fused_analysis['total_labeled']} (èšç±»æ—¶å¯ä»¥åˆ©ç”¨çš„æ ‡ç­¾ä¿¡æ¯)")
    print(f"     æ€»æ— æ ‡ç­¾: {fused_analysis['total_unlabeled']} (èšç±»æ—¶éœ€è¦é¢„æµ‹çš„æ ·æœ¬)")

    # 1. æ£€æŸ¥æ€»æ ·æœ¬æ•°
    if fused_analysis['total_samples'] == expected_total:
        print(f"   âœ… èåˆæ•°æ®é›†å¤§å°æ­£ç¡®: {expected_total}")
    else:
        print(f"   âŒ èåˆæ•°æ®é›†å¤§å°å¼‚å¸¸: {fused_analysis['total_samples']} (æœŸæœ›: {expected_total})")

    # 2. æ£€æŸ¥å·²çŸ¥ç±»æœªçŸ¥ç±»åˆ†å¸ƒ
    if fused_analysis['unknown_labeled'] == 0:
        print(f"   âœ… æœªçŸ¥ç±»å…¨éƒ¨æ— æ ‡ç­¾: {fused_analysis['unknown_unlabeled']}")
    else:
        print(f"   âŒ æœªçŸ¥ç±»æœ‰æ ‡ç­¾æ ·æœ¬å¼‚å¸¸: {fused_analysis['unknown_labeled']}")

    # 3. æ£€æŸ¥æœ‰æ ‡ç­¾æ ·æœ¬æ€»æ•°ï¼ˆåº”è¯¥åªåŒ…æ‹¬è®­ç»ƒé›†çš„æœ‰æ ‡ç­¾éƒ¨åˆ†ï¼Œæµ‹è¯•é›†å…¨éƒ¨æ— æ ‡ç­¾ï¼‰
    expected_total_labeled = expected_train_known_labeled  # åªæœ‰è®­ç»ƒé›†æœ‰æ ‡ç­¾éƒ¨åˆ†
    expected_total_unlabeled = train_unlabelled_size + test_size  # è®­ç»ƒé›†æ— æ ‡ç­¾éƒ¨åˆ† + æµ‹è¯•é›†å…¨éƒ¨

    if abs(fused_analysis['total_labeled'] - expected_total_labeled) <= 50:  # å…è®¸ä¸€äº›è¯¯å·®
        print(f"   âœ… æ€»æœ‰æ ‡ç­¾æ ·æœ¬æ•°æ­£ç¡®: {fused_analysis['total_labeled']} â‰ˆ {expected_total_labeled}")
    else:
        print(f"   âš ï¸ æ€»æœ‰æ ‡ç­¾æ ·æœ¬æ•°: {fused_analysis['total_labeled']} (æœŸæœ›çº¦: {expected_total_labeled})")

    if abs(fused_analysis['total_unlabeled'] - expected_total_unlabeled) <= 50:  # å…è®¸ä¸€äº›è¯¯å·®
        print(f"   âœ… æ€»æ— æ ‡ç­¾æ ·æœ¬æ•°æ­£ç¡®: {fused_analysis['total_unlabeled']} â‰ˆ {expected_total_unlabeled}")
    else:
        print(f"   âš ï¸ æ€»æ— æ ‡ç­¾æ ·æœ¬æ•°: {fused_analysis['total_unlabeled']} (æœŸæœ›çº¦: {expected_total_unlabeled})")

    # 4. æ£€æŸ¥æ‰¹æ¬¡æ ¼å¼
    if 4 in fused_analysis['batch_formats']:
        print(f"   âœ… èåˆæ•°æ®é›†åŒ…å«labeled_or_notä¿¡æ¯")
    else:
        print(f"   âŒ èåˆæ•°æ®é›†ç¼ºå°‘labeled_or_notä¿¡æ¯")

    print(f"   ğŸ¯ æ•°æ®é›†å·²å‡†å¤‡å¥½ç”¨äºè‡ªé€‚åº”èšç±»ç®—æ³•!")
    print(f"   ğŸ’¡ èšç±»ç®—æ³•æ¥æ”¶:")
    print(f"      - ç‰¹å¾: 768ç»´ç‰¹å¾å‘é‡")
    print(f"      - å·²çŸ¥/æœªçŸ¥æ ‡è¯†: åŒºåˆ†è®­ç»ƒè§è¿‡çš„ç±»vsæ–°ç±»")
    print(f"      - æœ‰æ ‡ç­¾/æ— æ ‡ç­¾æ ‡è¯†: åŒºåˆ†æœ‰ç›‘ç£ä¿¡æ¯vséœ€è¦é¢„æµ‹çš„æ ·æœ¬")
    print(f"      - çœŸå®æ ‡ç­¾ä»…ç”¨äºæœ€ç»ˆè¯„ä¼°ACCï¼Œèšç±»è¿‡ç¨‹ä¸­ä¸å¯è§")


def validate_data_consistency(train_analysis, test_analysis, expected_prop_train_labels):
    """
    éªŒè¯æ•°æ®ä¸€è‡´æ€§
    """
    if train_analysis is None or test_analysis is None:
        print("   âŒ æ— æ³•éªŒè¯ï¼šæ•°æ®åˆ†æå¤±è´¥")
        return

    print(f"   æ£€æŸ¥é¡¹ç›®:")

    # 1. æ£€æŸ¥è®­ç»ƒé›†æœ‰æ ‡ç­¾æ¯”ä¾‹
    if train_analysis['known_samples'] > 0:
        actual_prop = train_analysis['known_labeled'] / train_analysis['known_samples']
        expected_range = (expected_prop_train_labels - 0.1, expected_prop_train_labels + 0.1)

        if expected_range[0] <= actual_prop <= expected_range[1]:
            print(f"   âœ… è®­ç»ƒé›†å·²çŸ¥ç±»æœ‰æ ‡ç­¾æ¯”ä¾‹: {actual_prop:.3f} (æœŸæœ›: {expected_prop_train_labels})")
        else:
            print(f"   âŒ è®­ç»ƒé›†å·²çŸ¥ç±»æœ‰æ ‡ç­¾æ¯”ä¾‹å¼‚å¸¸: {actual_prop:.3f} (æœŸæœ›: {expected_prop_train_labels})")

    # 2. æ£€æŸ¥è®­ç»ƒé›†æœªçŸ¥ç±»æ˜¯å¦å…¨éƒ¨æ— æ ‡ç­¾
    if train_analysis['unknown_samples'] > 0:
        if train_analysis['unknown_labeled'] == 0:
            print(f"   âœ… è®­ç»ƒé›†æœªçŸ¥ç±»å…¨éƒ¨æ— æ ‡ç­¾: {train_analysis['unknown_unlabeled']}")
        else:
            print(f"   âŒ è®­ç»ƒé›†æœªçŸ¥ç±»æœ‰æ ‡ç­¾æ ·æœ¬å¼‚å¸¸: {train_analysis['unknown_labeled']}")

    # 3. æ£€æŸ¥æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒï¼ˆåº”è¯¥å…¨éƒ¨æ— æ ‡ç­¾ï¼‰
    test_total = test_analysis['total_samples']
    if test_total > 0:
        if test_analysis['total_unlabeled'] == test_total:
            print(f"   âœ… æµ‹è¯•é›†å…¨éƒ¨æ— æ ‡ç­¾: {test_total} (èšç±»æ—¶çœ‹ä¸åˆ°çœŸå®æ ‡ç­¾)")
        elif test_analysis['total_labeled'] == test_total:
            print(f"   âŒ æµ‹è¯•é›†å…¨éƒ¨æœ‰æ ‡ç­¾: {test_total} (èšç±»æ—¶ä¸åº”è¯¥çœ‹åˆ°æ ‡ç­¾)")
        else:
            print(f"   âš ï¸ æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: æœ‰æ ‡ç­¾{test_analysis['total_labeled']}, æ— æ ‡ç­¾{test_analysis['total_unlabeled']}")

    # 4. æ£€æŸ¥æ•°æ®æ ¼å¼
    train_formats = train_analysis.get('batch_formats', set())
    test_formats = test_analysis.get('batch_formats', set())

    if 4 in train_formats:
        print(f"   âœ… è®­ç»ƒé›†åŒ…å«labeled_or_notä¿¡æ¯")
    else:
        print(f"   âš ï¸ è®­ç»ƒé›†ç¼ºå°‘labeled_or_notä¿¡æ¯")

    if 4 in test_formats or 3 in test_formats:
        print(f"   âœ… æµ‹è¯•é›†æ ¼å¼æ­£å¸¸")
    else:
        print(f"   âŒ æµ‹è¯•é›†æ ¼å¼å¼‚å¸¸")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("è‡ªé€‚åº”èšç±»æ•°æ®åŠ è½½æµ‹è¯•")
    print("=" * 80)

    # æµ‹è¯•ä¸åŒè¶…ç±»
    superclasses_to_test = ['trees', 'flowers', 'mammals']

    for superclass in superclasses_to_test:
        try:
            print(f"\n{'='*20} æµ‹è¯•è¶…ç±»: {superclass} {'='*20}")
            train_analysis, test_analysis = test_superclass_data_loading(
                superclass_name=superclass,
                prop_train_labels=0.8
            )
            print(f"âœ“ {superclass} æµ‹è¯•å®Œæˆ")

        except Exception as e:
            print(f"âœ— {superclass} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print(f"\næ•°æ®åŠ è½½æµ‹è¯•å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥ï¼šåŸºäºæ­¤æ•°æ®æ ¼å¼å®ç°è‡ªé€‚åº”èšç±»ç®—æ³•")


if __name__ == "__main__":
    main()
