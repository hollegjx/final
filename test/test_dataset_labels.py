#!/usr/bin/env python3
"""
æ•°æ®é›†å’Œæ ‡ç­¾æµ‹è¯•è„šæœ¬
æµ‹è¯•è¶…ç±»æ•°æ®é›†çš„æ•°æ®åŠ è½½å’Œæ ‡ç­¾æ˜ å°„æ˜¯å¦æ­£ç¡®
ä»¥treesè¶…ç±»ä¸ºä¾‹è¿›è¡Œæµ‹è¯•
"""

import sys
import os
import argparse
import numpy as np
import torch
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.cifar100_superclass import (
    get_single_superclass_datasets,
    CIFAR100_SUPERCLASSES,
    SUPERCLASS_NAMES,
    get_superclass_splits
)
from data.augmentations import get_transform
from data.data_utils import MergedDataset
from copy import deepcopy

def test_superclass_dataset(superclass_name='trees', verbose=True):
    """
    æµ‹è¯•è¶…ç±»æ•°æ®é›†çš„æ•°æ®åŠ è½½å’Œæ ‡ç­¾æ˜ å°„

    Args:
        superclass_name: è¦æµ‹è¯•çš„è¶…ç±»åç§°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    print(f"\n{'='*60}")
    print(f"ğŸ§ª æµ‹è¯•è¶…ç±»: {superclass_name}")
    print(f"{'='*60}")

    # 1. æ£€æŸ¥è¶…ç±»å®šä¹‰
    if superclass_name not in CIFAR100_SUPERCLASSES:
        print(f"âŒ é”™è¯¯: æœªçŸ¥çš„è¶…ç±»åç§° '{superclass_name}'")
        print(f"ğŸ“‹ å¯ç”¨çš„è¶…ç±»: {SUPERCLASS_NAMES}")
        return False

    original_classes = CIFAR100_SUPERCLASSES[superclass_name]
    print(f"ğŸ“Š åŸå§‹ç±»åˆ«å®šä¹‰: {original_classes}")

    # æŒ‰GCDæ ‡å‡†åˆ’åˆ†å·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»
    known_classes = [cls for cls in original_classes if cls < 80]
    unknown_classes = [cls for cls in original_classes if cls >= 80]

    print(f"âœ… å·²çŸ¥ç±» (< 80): {known_classes}")
    print(f"ğŸ” æœªçŸ¥ç±» (>= 80): {unknown_classes}")

    if len(known_classes) == 0:
        print(f"âš ï¸ è­¦å‘Š: è¶…ç±» '{superclass_name}' æ²¡æœ‰å·²çŸ¥ç±»")
    if len(unknown_classes) == 0:
        print(f"âš ï¸ è­¦å‘Š: è¶…ç±» '{superclass_name}' æ²¡æœ‰æœªçŸ¥ç±»")

    # 2. åˆ›å»ºæ•°æ®è½¬æ¢
    try:
        # åˆ›å»ºç®€åŒ–çš„è½¬æ¢ï¼Œé¿å…å¤æ‚çš„ä¾èµ–
        import torch
        from torchvision import transforms
        from PIL import Image

        train_transform = transforms.Compose([
            transforms.Resize((224, 224), interpolation=Image.BICUBIC),
            transforms.ToTensor(),
        ])

        test_transform = transforms.Compose([
            transforms.Resize((224, 224), interpolation=Image.BICUBIC),
            transforms.ToTensor(),
        ])

        print("âœ… æ•°æ®è½¬æ¢åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®è½¬æ¢åˆ›å»ºå¤±è´¥: {e}")
        return False

    # 3. è·å–è¶…ç±»æ•°æ®é›†
    try:
        datasets = get_single_superclass_datasets(
            superclass_name=superclass_name,
            train_transform=train_transform,
            test_transform=test_transform,
            prop_train_labels=0.8,
            split_train_val=False,
            seed=1
        )
        print("âœ… è¶…ç±»æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ è¶…ç±»æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return False

    # 4. æ£€æŸ¥æ•°æ®é›†ç»“æ„
    print(f"\nğŸ“‚ æ•°æ®é›†ç»“æ„:")
    for split_name, dataset in datasets.items():
        if dataset is not None:
            print(f"  {split_name}: {len(dataset)} æ ·æœ¬")
        else:
            print(f"  {split_name}: None")

    # 5. æµ‹è¯•æ ‡ç­¾åˆ†å¸ƒ
    print(f"\nğŸ·ï¸ æ ‡ç­¾åˆ†å¸ƒæµ‹è¯•:")

    def test_dataset_labels(dataset, dataset_name):
        """æµ‹è¯•æ•°æ®é›†çš„æ ‡ç­¾åˆ†å¸ƒ"""
        if dataset is None:
            print(f"  {dataset_name}: æ•°æ®é›†ä¸ºç©º")
            return

        labels = []
        for i in range(min(len(dataset), 100)):  # æµ‹è¯•å‰100ä¸ªæ ·æœ¬
            try:
                if len(dataset[i]) == 2:  # (img, label)
                    _, label = dataset[i]
                elif len(dataset[i]) == 3:  # (img, label, uq_idx)
                    _, label, _ = dataset[i]
                else:
                    print(f"âš ï¸ æ„å¤–çš„æ•°æ®æ ¼å¼: {len(dataset[i])} ä¸ªå…ƒç´ ")
                    continue
                labels.append(label)
            except Exception as e:
                print(f"âŒ ç¬¬{i}ä¸ªæ ·æœ¬åŠ è½½å¤±è´¥: {e}")
                break

        if labels:
            label_counts = Counter(labels)
            print(f"  {dataset_name}: æ ‡ç­¾èŒƒå›´ [{min(labels)}, {max(labels)}], åˆ†å¸ƒ: {dict(label_counts)}")

            # æ£€æŸ¥æ ‡ç­¾æ˜ å°„æ˜¯å¦æ­£ç¡®
            if hasattr(dataset, 'label_mapping') and dataset.label_mapping is not None:
                print(f"  æ ‡ç­¾æ˜ å°„: {dataset.label_mapping}")
                # éªŒè¯æ˜ å°„åçš„æ ‡ç­¾æ˜¯å¦è¿ç»­
                mapped_labels = set(labels)
                expected_labels = set(range(len(dataset.label_mapping)))
                if mapped_labels == expected_labels:
                    print(f"  âœ… æ ‡ç­¾æ˜ å°„æ­£ç¡®ï¼Œæ ‡ç­¾è¿ç»­ [0, {len(dataset.label_mapping)-1}]")
                else:
                    print(f"  âŒ æ ‡ç­¾æ˜ å°„å¼‚å¸¸:")
                    print(f"    å®é™…æ ‡ç­¾: {sorted(mapped_labels)}")
                    print(f"    æœŸæœ›æ ‡ç­¾: {sorted(expected_labels)}")
        else:
            print(f"  {dataset_name}: æ— æ³•è·å–æ ‡ç­¾")

    # æµ‹è¯•å„ä¸ªæ•°æ®é›†
    for split_name, dataset in datasets.items():
        test_dataset_labels(dataset, split_name)

    # 6. æµ‹è¯•MergedDataset
    print(f"\nğŸ”— MergedDatasetæµ‹è¯•:")
    try:
        train_dataset = MergedDataset(
            labelled_dataset=deepcopy(datasets['train_labelled']),
            unlabelled_dataset=deepcopy(datasets['train_unlabelled'])
        )
        print(f"âœ… MergedDatasetåˆ›å»ºæˆåŠŸï¼Œæ€»æ ·æœ¬æ•°: {len(train_dataset)}")

        # æµ‹è¯•å‰å‡ ä¸ªæ ·æœ¬
        print("ğŸ” æ ·æœ¬æ ¼å¼æµ‹è¯•:")
        for i in range(min(3, len(train_dataset))):
            try:
                sample = train_dataset[i]
                print(f"  æ ·æœ¬{i}: {len(sample)}ä¸ªå…ƒç´ , æ ‡ç­¾: {sample[1]}, æ˜¯å¦æ ‡è®°: {sample[3][0]}")
            except Exception as e:
                print(f"  âŒ æ ·æœ¬{i}åŠ è½½å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ MergedDatasetåˆ›å»ºå¤±è´¥: {e}")
        return False

    # 7. æµ‹è¯•ä¸è®­ç»ƒè„šæœ¬çš„å…¼å®¹æ€§
    print(f"\nğŸ¯ è®­ç»ƒå…¼å®¹æ€§æµ‹è¯•:")
    try:
        # æ¨¡æ‹Ÿè®­ç»ƒè„šæœ¬ä¸­çš„args
        class MockArgs:
            def __init__(self):
                self.superclass_name = superclass_name
                self.prop_train_labels = 0.8
                self.seed = 1

        mock_args = MockArgs()

        # è·å–ç±»åˆ«åˆ’åˆ†ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿget_class_splitsï¼‰
        superclass_splits = get_superclass_splits()
        split_info = superclass_splits[superclass_name]

        mock_args.train_classes = split_info['known_classes']
        mock_args.unlabeled_classes = split_info['unknown_classes']

        print(f"âœ… è®­ç»ƒç±»åˆ«: {mock_args.train_classes}")
        print(f"âœ… æœªæ ‡è®°ç±»åˆ«: {mock_args.unlabeled_classes}")

        print(f"âœ… ä¸è®­ç»ƒè„šæœ¬å…¼å®¹")

    except Exception as e:
        print(f"âŒ è®­ç»ƒå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

    print(f"\nğŸ‰ è¶…ç±» '{superclass_name}' æµ‹è¯•å®Œæˆ!")
    return True

def test_all_superclasses():
    """æµ‹è¯•æ‰€æœ‰è¶…ç±»"""
    print("ğŸŒŸ æµ‹è¯•æ‰€æœ‰è¶…ç±»...")
    success_count = 0

    for superclass_name in SUPERCLASS_NAMES:
        try:
            success = test_superclass_dataset(superclass_name, verbose=False)
            if success:
                success_count += 1
                print(f"âœ… {superclass_name}: æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {superclass_name}: æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {superclass_name}: æµ‹è¯•å¼‚å¸¸ - {e}")

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{len(SUPERCLASS_NAMES)} ä¸ªè¶…ç±»æµ‹è¯•é€šè¿‡")

def main():
    parser = argparse.ArgumentParser(description='æµ‹è¯•è¶…ç±»æ•°æ®é›†å’Œæ ‡ç­¾æ˜ å°„')
    parser.add_argument('--superclass', type=str, default='trees',
                        help='è¦æµ‹è¯•çš„è¶…ç±»åç§°ï¼Œé»˜è®¤ä¸ºtrees')
    parser.add_argument('--all', action='store_true',
                        help='æµ‹è¯•æ‰€æœ‰è¶…ç±»')
    parser.add_argument('--verbose', action='store_true', default=True,
                        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')

    args = parser.parse_args()

    print("ğŸ§ª è¶…ç±»æ•°æ®é›†æµ‹è¯•å·¥å…·")
    print("=" * 60)

    if args.all:
        test_all_superclasses()
    else:
        test_superclass_dataset(args.superclass, args.verbose)

if __name__ == "__main__":
    main()