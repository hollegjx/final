#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®æä¾›å™¨æ¨¡å—
ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œç¼“å­˜ä¸å­˜åœ¨æ—¶ä½¿ç”¨å®æ—¶æå–
"""

from config import feature_cache_dir
from .feature_loader import FeatureLoader
from .feature_extractor import FeatureExtractor
from .dataset_config import get_superclass_info


class DataProvider:
    """
    æ•°æ®æä¾›å™¨ç±»
    ç»Ÿä¸€ç®¡ç†ç‰¹å¾æ•°æ®çš„è·å–ï¼Œè‡ªåŠ¨é€‰æ‹©ç¼“å­˜æˆ–å®æ—¶æå–
    """

    def __init__(self, cache_base_dir=None):
        """
        åˆå§‹åŒ–æ•°æ®æä¾›å™¨

        Args:
            cache_base_dir: ç¼“å­˜åŸºç¡€ç›®å½•
        """
        cache_dir = cache_base_dir or feature_cache_dir
        self.feature_loader = FeatureLoader(cache_base_dir=cache_dir)

    def get_features(self, dataset_name, model=None, data_loaders=None,
                    use_l2=True, use_train_and_test=True, silent=False):
        """
        è·å–ç‰¹å¾æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œç¼“å­˜ä¸å­˜åœ¨æ—¶å®æ—¶æå–ï¼‰

        Args:
            dataset_name: æ•°æ®é›†åç§°ï¼ˆå¦‚è¶…ç±»åç§°ï¼‰
            model: PyTorchæ¨¡å‹ï¼ˆç¼“å­˜ä¸å­˜åœ¨æ—¶éœ€è¦ï¼‰
            data_loaders: æ•°æ®åŠ è½½å™¨å­—å…¸æˆ–å…ƒç»„ï¼ˆç¼“å­˜ä¸å­˜åœ¨æ—¶éœ€è¦ï¼‰
                - å­—å…¸æ ¼å¼: {'train': train_loader, 'test': test_loader}
                - å…ƒç»„æ ¼å¼: (train_loader, test_loader)
            use_l2: æ˜¯å¦ä½¿ç”¨L2å½’ä¸€åŒ–ç‰¹å¾
            use_train_and_test: æ˜¯å¦ä½¿ç”¨è®­ç»ƒ+æµ‹è¯•ï¼ˆFalseåˆ™åªç”¨æµ‹è¯•é›†ï¼‰
            silent: æ˜¯å¦é™é»˜æ¨¡å¼

        Returns:
            feature_dict: ç‰¹å¾æ•°æ®å­—å…¸
            source: æ•°æ®æ¥æº ('cache' or 'extraction')
        """
        # 1. ä¼˜å…ˆå°è¯•åŠ è½½ç¼“å­˜
        feature_dict = self.feature_loader.load(dataset_name, use_l2=use_l2, silent=silent)

        if feature_dict is not None:
            return feature_dict, 'cache'

        # 2. ç¼“å­˜ä¸å­˜åœ¨ï¼Œè¿›è¡Œå®æ—¶ç‰¹å¾æå–
        if model is None or data_loaders is None:
            error_msg = "ç¼“å­˜ä¸å­˜åœ¨ä¸”æœªæä¾›æ¨¡å‹æˆ–æ•°æ®åŠ è½½å™¨ï¼Œæ— æ³•æå–ç‰¹å¾"
            if not silent:
                print(f"âŒ {error_msg}")
            raise ValueError(error_msg)

        if not silent:
            print("ğŸ”„ ç¼“å­˜ä¸å­˜åœ¨ï¼Œå¼€å§‹å®æ—¶ç‰¹å¾æå–...")

        # åˆ›å»ºç‰¹å¾æå–å™¨
        device = next(model.parameters()).device  # ä»æ¨¡å‹è·å–è®¾å¤‡
        extractor = FeatureExtractor(model=model, device=device, use_l2=use_l2)

        # è§£ædata_loaders
        if isinstance(data_loaders, dict):
            train_loader = data_loaders.get('train')
            test_loader = data_loaders.get('test')
        elif isinstance(data_loaders, (tuple, list)):
            if len(data_loaders) == 2:
                train_loader, test_loader = data_loaders
            else:
                train_loader = None
                test_loader = data_loaders[0]
        else:
            train_loader = None
            test_loader = data_loaders

        # è·å–å·²çŸ¥ç±»åˆ«ä¿¡æ¯ï¼ˆç”¨äºåˆ›å»ºknown_maskï¼‰
        try:
            superclass_info = get_superclass_info(dataset_name)
            known_classes = superclass_info['known_classes_mapped']
        except:
            # å¦‚æœä¸æ˜¯è¶…ç±»æ•°æ®é›†ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
            known_classes = None

        # æå–ç‰¹å¾
        if use_train_and_test and train_loader is not None and test_loader is not None:
            feature_dict = extractor.extract_train_test(
                train_loader, test_loader, known_classes=known_classes, silent=silent
            )
        else:
            # åªä½¿ç”¨æµ‹è¯•é›†
            loader = test_loader if test_loader is not None else train_loader
            feature_dict = extractor.extract_single_dataset(
                loader, known_classes=known_classes, silent=silent
            )

        return feature_dict, 'extraction'

    def check_cache_available(self, dataset_name, use_l2=True):
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦å¯ç”¨

        Args:
            dataset_name: æ•°æ®é›†åç§°
            use_l2: æ˜¯å¦L2å½’ä¸€åŒ–

        Returns:
            bool: ç¼“å­˜æ˜¯å¦å­˜åœ¨
        """
        return self.feature_loader.check_cache_exists(dataset_name, use_l2=use_l2)

    def get_cache_info(self, dataset_name, use_l2=True):
        """
        è·å–ç¼“å­˜ä¿¡æ¯

        Args:
            dataset_name: æ•°æ®é›†åç§°
            use_l2: æ˜¯å¦L2å½’ä¸€åŒ–

        Returns:
            dict: ç¼“å­˜ä¿¡æ¯å­—å…¸
                - 'exists': æ˜¯å¦å­˜åœ¨
                - 'path': ç¼“å­˜è·¯å¾„
        """
        exists = self.feature_loader.check_cache_exists(dataset_name, use_l2=use_l2)
        path = self.feature_loader.get_cache_path(dataset_name, use_l2=use_l2)

        return {
            'exists': exists,
            'path': path
        }
