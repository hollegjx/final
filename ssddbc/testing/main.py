#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸»æµ‹è¯•ç¨‹åº
å‘½ä»¤è¡Œå…¥å£ï¼Œç”¨äºè¿è¡ŒSS-DDBCèšç±»ç®—æ³•æµ‹è¯•
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import argparse
import json
import numpy as np

from config import clustering_log_dir, error_analysis_log_dir
from project_utils.general_utils import str2bool
from ssddbc.data import set_deterministic_behavior  # ä»ssddbc/dataå¯¼å…¥

# å…¼å®¹ä¸¤ç§è¿è¡Œæ–¹å¼çš„å¯¼å…¥
try:
    from ..ssddbc.analysis import analyze_cluster_composition
    from ..baseline.kmeans import test_kmeans_baseline
    from .test_superclass import test_adaptive_clustering_on_superclass
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶çš„å¯¼å…¥
    from ssddbc.ssddbc.analysis import analyze_cluster_composition
    from ssddbc.baseline.kmeans import test_kmeans_baseline
    from ssddbc.testing.test_superclass import test_adaptive_clustering_on_superclass


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‡ªé€‚åº”å¯†åº¦èšç±»ç®—æ³•æµ‹è¯•')

    # ========== 1. å…¨å±€è®¾ç½® ==========
    parser.add_argument('--model_path', type=str, default=None,
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ï¼ˆæœªæŒ‡å®šæ—¶éœ€ç»“åˆç¼“å­˜ç‰¹å¾ä½¿ç”¨ï¼‰')
    parser.add_argument('--superclass_name', type=str, default='trees',
                        help='æµ‹è¯•çš„è¶…ç±»åç§°')
    parser.add_argument('--use_train_and_test', type=str2bool, default=True,
                        help='æ˜¯å¦åˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œèšç±»ã€‚True=åˆå¹¶(é»˜è®¤)ï¼Œåœ¨æ›´å¤§æ•°æ®é›†ä¸Šæ„å»ºæ›´é²æ£’çš„èšç±»ï¼›False=ä»…æµ‹è¯•é›†ï¼Œæ›´å¿«ä½†å¯èƒ½ä¸ç¨³å®š')
    parser.add_argument('--l2', type=str2bool, default=True,
                        help='æ˜¯å¦ä½¿ç”¨L2å½’ä¸€åŒ–ç‰¹å¾ï¼Œé»˜è®¤Trueã€‚True=ä½¿ç”¨L2å½’ä¸€åŒ–(æ¨èï¼Œä¸eval_original_gcdä¿æŒä¸€è‡´)ï¼ŒFalse=ä½¿ç”¨åŸå§‹ç‰¹å¾(ä¸æ¨è)')
    parser.add_argument('--fast_mode', type=str2bool, default=False,
                        help='å¿«é€Ÿæ¨¡å¼ï¼Œé»˜è®¤Falseã€‚True=è·³è¿‡ä¸å¿…è¦çš„è®¡ç®—ï¼ˆæœªçŸ¥ç°‡è¯†åˆ«ã€ç°‡ç±»åˆ«æ ‡ç­¾ï¼‰å’Œè°ƒè¯•è¾“å‡ºï¼Œä»…æ˜¾ç¤ºæœ€ç»ˆç»“æœï¼Œç”¨äºç½‘æ ¼æœç´¢åŠ é€Ÿæˆ–æ‰¹é‡å®éªŒï¼›False=å®Œæ•´è®¡ç®—å’Œè¾“å‡º')

    # ========== 2. å¯†åº¦è®¡ç®—ç›¸å…³å‚æ•° ==========
    parser.add_argument('--k', type=int, default=10,
                        help='Kè¿‘é‚»æ•°é‡ï¼Œç”¨äºå¯†åº¦è®¡ç®—å’Œé‚»å±…å‘ç°ã€‚èŒƒå›´[3-30]ï¼Œé»˜è®¤10ã€‚è¾ƒå¤§å€¼(15-20)é€‚åˆç¨ å¯†æ•°æ®ï¼Œè¾ƒå°å€¼(5-10)é€‚åˆç¨€ç–æ•°æ®')
    parser.add_argument('--density_percentile', type=int, default=75,
                        help='é«˜å¯†åº¦ç‚¹é€‰æ‹©çš„ç™¾åˆ†ä½é˜ˆå€¼ï¼ŒèŒƒå›´[20-100]ï¼Œé»˜è®¤75ã€‚å€¼è¶Šé«˜é€‰æ‹©çš„æ ¸å¿ƒç‚¹è¶Šå°‘ä½†è¶Šå¯é (80-90é€‚åˆå™ªå£°æ•°æ®)ï¼Œå€¼è¶Šä½é€‰æ‹©çš„æ ¸å¿ƒç‚¹è¶Šå¤šä½†å¯èƒ½åŒ…å«å™ªå£°(60-70é€‚åˆå¹²å‡€æ•°æ®)')
    parser.add_argument('--dense_method', type=int, default=0, choices=[0, 1, 2, 3],
                        help='å¯†åº¦è®¡ç®—æ–¹æ³•ï¼Œé»˜è®¤0ã€‚0=å¹³å‡è·ç¦»å€’æ•°(é€šç”¨é»˜è®¤)ï¼Œ1=ä¸­ä½æ•°è·ç¦»å€’æ•°(æŠ—å™ªå£°)ï¼Œ2=å½’ä¸€åŒ–å€’æ•°(å¯†åº¦å€¼å½’ä¸€åŒ–åˆ°[0,1])ï¼Œ3=æŒ‡æ•°å¯†åº¦(å¼ºè°ƒå±€éƒ¨å¯†é›†åº¦)ã€‚è¯¦è§ssddbc/density/DENSITY_METHODS.md')

    # ========== 3. éª¨å¹²ç½‘ç»œï¼ˆé«˜å¯†åº¦ç‚¹ï¼‰èšç±»ç›¸å…³å‚æ•° ==========
    parser.add_argument('--co_mode', type=int, default=2, choices=[1, 2, 3],
                        help='coæˆªæ­¢è·ç¦»è®¡ç®—æ¨¡å¼ï¼Œé»˜è®¤2ã€‚1=æ‰‹åŠ¨æŒ‡å®š(éœ€é…åˆ--co_manual)ï¼Œ2=Kè¿‘é‚»å¹³å‡è·ç¦»(é€šç”¨é»˜è®¤)ï¼Œ3=ç›¸å¯¹è‡ªé€‚åº”è·ç¦»(æ¯ç‚¹è‡ªé€‚åº”ï¼Œé€‚åˆä¸å‡åŒ€åˆ†å¸ƒ)ã€‚è¯¦è§ssddbc/utils/CO_MODES.md')
    parser.add_argument('--co_manual', type=float, default=None,
                        help='æ‰‹åŠ¨æŒ‡å®šçš„coæˆªæ­¢è·ç¦»å€¼(ä»…å½“co_mode=1æ—¶ä½¿ç”¨)ã€‚é€šè¿‡ç½‘æ ¼æœç´¢æˆ–å…ˆéªŒçŸ¥è¯†ç¡®å®šã€‚å…¸å‹èŒƒå›´[1.0-5.0]å–å†³äºç‰¹å¾ç©ºé—´å°ºåº¦')
    parser.add_argument('--eval_dense', type=str2bool, default=False,
                        help='æ˜¯å¦ä»…è¯„ä¼°é«˜å¯†åº¦ç‚¹(éª¨å¹²ç½‘ç»œ)ï¼Œé»˜è®¤Falseã€‚True=åªæ„å»ºå’Œè¯„ä¼°é«˜å¯†åº¦èšç±»ï¼Œè·³è¿‡ä½å¯†åº¦ç‚¹åˆ†é…ï¼Œç”¨äºè¯„ä¼°æ ¸å¿ƒèšç±»è´¨é‡')

    # ========== 4. ç¨€ç–ç‚¹åˆ†é…ç›¸å…³å‚æ•° ==========
    parser.add_argument('--assign_model', type=int, default=2, choices=[1, 2, 3],
                        help='ä½å¯†åº¦ç‚¹åˆ†é…ç­–ç•¥ï¼Œé»˜è®¤2ã€‚1=ç°‡åŸå‹å°±è¿‘(é€Ÿåº¦æœ€å¿«)ï¼Œ2=KNNæŠ•ç¥¨åŠ æƒ(æ¨èé»˜è®¤ï¼Œè€ƒè™‘é‚»åŸŸä¿¡æ¯)ï¼Œ3=ç°‡å†…Kè¿‘é‚»å¹³å‡è·ç¦»(æœ€ç²¾ç»†ä½†æ…¢)ã€‚è¯¦è§ssddbc/ssddbc/ASSIGNMENT_STRATEGIES.md')
    parser.add_argument('--voting_k', type=int, default=5,
                        help='KNNæŠ•ç¥¨æ—¶ä½¿ç”¨çš„è¿‘é‚»æ•°é‡ï¼Œé»˜è®¤5(ä»…å½“assign_model=2æ—¶ç”Ÿæ•ˆ)ã€‚èŒƒå›´[3-15]ï¼Œå€¼è¶Šå¤§åˆ†é…è¶Šç¨³å®šä½†è®¡ç®—è¶Šæ…¢')

    # ========== 5. è¯„ä¼°å’Œå¯¹æ¯”ç›¸å…³å‚æ•° ==========
    parser.add_argument('--eval_version', type=str, default='v2', choices=['v1', 'v2'],
                        help='è¯„ä¼°æŒ‡æ ‡è®¡ç®—ç‰ˆæœ¬ï¼Œé»˜è®¤v1ã€‚v1=åŸå§‹ç‰ˆæœ¬(åŒˆç‰™åˆ©ç®—æ³•)ï¼Œv2=æ–°ç‰ˆæœ¬(ä¸åŒçš„åŒ¹é…ç­–ç•¥)ã€‚ä¿æŒé»˜è®¤å³å¯')
    parser.add_argument('--run_kmeans_baseline', type=str2bool, default=False,
                        help='æ˜¯å¦è¿è¡ŒK-meansåŸºçº¿å¯¹æ¯”ï¼Œé»˜è®¤Falseã€‚True=åŒæ—¶è¿è¡ŒK-meanså¹¶è¾“å‡ºå¯¹æ¯”ç»“æœï¼Œç”¨äºéªŒè¯SS-DDBCçš„ä¼˜åŠ¿')
    parser.add_argument('--kmeans_merge', type=str2bool, default=False,
                        help='K-meansæ˜¯å¦åˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œé»˜è®¤Falseã€‚ä»…åœ¨--run_kmeans_baseline=Trueæ—¶ç”Ÿæ•ˆã€‚True=åˆå¹¶æ•°æ®é›†è¿è¡ŒK-means')

    # ========== 6. è°ƒè¯•å’Œåˆ†æç›¸å…³å‚æ•° ==========
    parser.add_argument('--detail_dense', type=str2bool, default=False,
                        help='æ˜¯å¦è®°å½•éª¨å¹²ç½‘ç»œèšç±»è¯¦ç»†æ—¥å¿—ï¼ˆå½“å‰å®ç°å·²ç²¾ç®€ä¸ºæ— æ•ˆï¼Œå ä½å‚æ•°ï¼‰ã€‚')
    parser.add_argument('--label_guide', type=str2bool, default=False,
                        help='æ˜¯å¦å¯ç”¨æ ‡ç­¾å¼•å¯¼æ¨¡å¼ï¼Œé»˜è®¤Falseã€‚True=åœ¨æ ¸å¿ƒç‚¹èšç±»å®Œæˆåï¼Œå°†å‰©ä½™ç¨€ç–ç‚¹ä¸­çš„å·²çŸ¥æ ‡ç­¾æ ·æœ¬ç›´æ¥åˆ†é…åˆ°å¯¹åº”æ ‡ç­¾çš„æ ¸å¿ƒç‚¹ç°‡ï¼Œç„¶åå†åˆ†é…å‰©ä½™æ— æ ‡ç­¾æ ·æœ¬')
    parser.add_argument('--analyze_errors', type=str2bool, default=False,
                        help='æ˜¯å¦åˆ†ææµ‹è¯•é›†é”™è¯¯æ ·æœ¬ï¼ˆå½“å‰å®ç°å·²ç§»é™¤é”™è¯¯æ ·æœ¬åˆ†æé€»è¾‘ï¼Œå ä½å‚æ•°ï¼‰ã€‚')

    # ========== 6.5 èšç±»è´¨é‡è¯„ä¼°å‚æ•° ==========
    parser.add_argument('--use_cluster_quality', type=str2bool, default=False,
                        help='æ˜¯å¦ä½¿ç”¨èšç±»è´¨é‡è¯„ä¼°æŒ‡æ ‡ä½œä¸ºL2æŸå¤±ï¼Œé»˜è®¤Falseã€‚True=ä½¿ç”¨åŸºäºç°‡é—´åˆ†ç¦»åº¦å’Œå±€éƒ¨å¯†åº¦çš„èšç±»è´¨é‡è¯„ä¼°')
    parser.add_argument('--cluster_distance_method', type=int, default=1, choices=[1, 2, 3],
                        help='ç°‡è·ç¦»è®¡ç®—æ–¹æ³•ï¼Œé»˜è®¤1ã€‚1=æœ€è¿‘kå¯¹ç‚¹å¹³å‡è·ç¦»ï¼ˆå…³æ³¨ç°‡è¾¹ç•Œï¼‰ï¼Œ2=æ‰€æœ‰ç‚¹å¯¹å¹³å‡è·ç¦»ï¼ˆæ•´ä½“åˆ†ç¦»åº¦ï¼‰ï¼Œ3=åŸå‹è·ç¦»ï¼ˆè®¡ç®—æ•ˆç‡é«˜ï¼‰')
    parser.add_argument('--l1_type', type=str, default='cross_entropy', choices=['accuracy', 'cross_entropy'],
                        help='L1ç›‘ç£æŸå¤±ç±»å‹ï¼Œé»˜è®¤cross_entropyã€‚accuracy=åŸºäºåŒˆç‰™åˆ©ç®—æ³•çš„å‡†ç¡®ç‡æŸå¤±(1-ACC)ï¼Œcross_entropy=åŸºäºç°‡ç±»åˆ«åˆ†å¸ƒçš„äº¤å‰ç†µæŸå¤±')

    # L2æŸå¤±æƒé‡å‚æ•°
    parser.add_argument('--separation_weight', type=float, default=1.0,
                        help='L2æŸå¤±ä¸­ç°‡é—´åˆ†ç¦»åº¦çš„æƒé‡ï¼ˆé»˜è®¤1.0ï¼‰ã€‚å¢å¤§æ­¤å€¼ä¼šæ›´åŠ é‡è§†ç°‡ä¹‹é—´çš„åˆ†ç¦»ç¨‹åº¦ã€‚')
    parser.add_argument('--penalty_weight', type=float, default=1.0,
                        help='L2æŸå¤±ä¸­å±€éƒ¨å¯†åº¦æƒ©ç½šçš„æƒé‡ï¼ˆé»˜è®¤1.0ï¼‰ã€‚å¢å¤§æ­¤å€¼ä¼šæ›´åŠ é‡è§†æ ·æœ¬çš„å±€éƒ¨å¯†åº¦ä¸€è‡´æ€§ï¼ˆåŒç°‡æ ·æœ¬è¿‘ï¼Œå¼‚ç°‡æ ·æœ¬è¿œï¼‰ã€‚')
    parser.add_argument('--l2_components', type=str, default=None,
                        help="æŒ‡å®šå¯ç”¨çš„ L2 ç»„ä»¶ï¼Œä½¿ç”¨ç©ºæ ¼æˆ–é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ 'separation penalty'")
    parser.add_argument('--l2_component_weights', type=str, default=None,
                        help="æŒ‡å®š L2 ç»„ä»¶æƒé‡ï¼Œæ”¯æŒ JSON å­—ç¬¦ä¸²æˆ– key=value çš„é€—å·å½¢å¼ï¼Œå¦‚ "
                             "'{\"separation\":0.5,\"penalty\":0.5}' æˆ– 'separation=0.5,penalty=0.5'")

    # ========== 7. ç½‘æ ¼æœç´¢å‚æ•°èŒƒå›´ ==========
    parser.add_argument('--grid_search', type=str2bool, default=False,
                        help='æ˜¯å¦å¯ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–å‚æ•°ï¼Œé»˜è®¤Falseã€‚True=è‡ªåŠ¨æœç´¢kå’Œdensity_percentileçš„æœ€ä½³ç»„åˆï¼Œç»“æœä¿å­˜ä¸ºCSVæ–‡ä»¶')
    parser.add_argument('--k_min', type=int, default=3,
                        help='ç½‘æ ¼æœç´¢æ—¶kå€¼çš„æœ€å°å€¼ï¼Œé»˜è®¤3ã€‚å»ºè®®èŒƒå›´[3-10]ï¼Œå¤ªå°ä¼šå¯¼è‡´å¯†åº¦ä¼°è®¡ä¸ç¨³å®š')
    parser.add_argument('--k_max', type=int, default=21,
                        help='ç½‘æ ¼æœç´¢æ—¶kå€¼çš„æœ€å¤§å€¼ï¼Œé»˜è®¤21ã€‚å»ºè®®èŒƒå›´[15-30]ï¼Œå¤ªå¤§ä¼šè¿‡åº¦å¹³æ»‘å¯†åº¦åˆ†å¸ƒã€‚æœç´¢èŒƒå›´ä¸º[k_min, k_max)ï¼Œæ­¥é•¿ä¸º2')
    parser.add_argument('--dp_min', type=int, default=50,
                        help='ç½‘æ ¼æœç´¢æ—¶å¯†åº¦ç™¾åˆ†ä½çš„æœ€å°å€¼ï¼Œé»˜è®¤20ã€‚å»ºè®®èŒƒå›´[20-50]ï¼Œå¤ªå°ä¼šé€‰æ‹©è¿‡å¤šå™ªå£°ç‚¹ä½œä¸ºæ ¸å¿ƒ')
    parser.add_argument('--dp_max', type=int, default=100,
                        help='ç½‘æ ¼æœç´¢æ—¶å¯†åº¦ç™¾åˆ†ä½çš„æœ€å¤§å€¼ï¼Œé»˜è®¤100ã€‚å»ºè®®èŒƒå›´[80-100]ã€‚æœç´¢èŒƒå›´ä¸º[dp_min, dp_max]ï¼Œæ­¥é•¿ç”±--dp_stepæŒ‡å®š')
    parser.add_argument('--dp_step', type=int, default=5,
                        help='ç½‘æ ¼æœç´¢æ—¶å¯†åº¦ç™¾åˆ†ä½çš„æ­¥é•¿ï¼Œé»˜è®¤5ã€‚æ­¥é•¿è¶Šå°æœç´¢è¶Šç²¾ç»†ä½†è€—æ—¶è¶Šé•¿ã€‚å»ºè®®èŒƒå›´[5-10]')

    args = parser.parse_args()

    def _parse_l2_components(value: str):
        if value is None:
            return None
        parts = [part.strip() for part in value.replace(',', ' ').split() if part.strip()]
        return parts

    def _parse_l2_component_weights(value: str):
        if value is None:
            return None
        try:
            parsed = json.loads(value)
            if isinstance(parsed, dict):
                return {str(k): float(v) for k, v in parsed.items()}
        except json.JSONDecodeError:
            pass

        weights = {}
        for chunk in value.split(','):
            chunk = chunk.strip()
            if not chunk:
                continue
            if '=' not in chunk:
                raise ValueError(f"æ— æ³•è§£æ l2_component_weights æ¡ç›®: {chunk}")
            key, val = chunk.split('=', 1)
            weights[key.strip()] = float(val.strip())
        return weights

    parsed_l2_components = _parse_l2_components(args.l2_components) if args.l2_components else None
    parsed_l2_weights = _parse_l2_component_weights(args.l2_component_weights) if args.l2_component_weights else None

    # è®¾ç½®ç¡®å®šæ€§è¡Œä¸ºï¼ˆä»…torchç›¸å…³ï¼‰
    set_deterministic_behavior()

    print("è‡ªé€‚åº”å¯†åº¦èšç±»ç®—æ³•æµ‹è¯•")
    print("="*80)
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"è¶…ç±»åç§°: {args.superclass_name}")
    print(f"ä½¿ç”¨è®­ç»ƒ+æµ‹è¯•: {args.use_train_and_test}")
    print(f"ç‰¹å¾å½’ä¸€åŒ–: {'L2å½’ä¸€åŒ–' if args.l2 else 'æ— L2å½’ä¸€åŒ–'}")
    print(f"è¯„ä¼°ç‰ˆæœ¬: {args.eval_version}")
    print(f"K-meansåˆå¹¶: {'å¯ç”¨' if args.kmeans_merge else 'ç¦ç”¨'}")
    print(f"ç½‘æ ¼æœç´¢: {'å¯ç”¨' if args.grid_search else 'ç¦ç”¨'}")
    print(f"éšæœºç§å­: 0 (ä¸K-meansä¿æŒä¸€è‡´)")
    print(f"ç®—æ³•å‚æ•°: k={args.k}, density_percentile={args.density_percentile}")
    print(f"ç¨€ç–ç‚¹åˆ†é…: assign_model={args.assign_model}, voting_k={args.voting_k}")
    if parsed_l2_components is not None:
        print(f"L2 ç»„ä»¶: {parsed_l2_components} (è‡ªå®šä¹‰)")
        if parsed_l2_weights:
            print(f"L2 ç»„ä»¶æƒé‡: {parsed_l2_weights}")
    else:
        print(f"L2 ç»„ä»¶: {'é»˜è®¤(separation, penalty)' if args.use_cluster_quality else 'æœªå¯ç”¨'}")
    print("="*80)

    try:
        # ç½‘æ ¼æœç´¢åŠŸèƒ½å·²è¿ç§»åˆ° ssddbc.grid_search.batch_runner
        if args.grid_search:
            print("ğŸ” ç½‘æ ¼æœç´¢åŠŸèƒ½å·²è¿ç§»åˆ° ssddbc.grid_search.batch_runner")
            print("è¯·ä½¿ç”¨: python -m ssddbc.grid_search.batch_runner")
            return
        # è¿è¡ŒSS-DDBCç®—æ³•ï¼ˆéµå®ˆK-meansçš„random_state=0è®¾è®¡ï¼‰
        ssddbc_results = test_adaptive_clustering_on_superclass(
            superclass_name=args.superclass_name,
            model_path=args.model_path,
            use_train_and_test=args.use_train_and_test,
            k=args.k,
            density_percentile=args.density_percentile,
            random_state=0,  # ä¸K-meansä¿æŒä¸€è‡´ï¼Œå›ºå®šä½¿ç”¨0
            eval_version=args.eval_version,
            run_kmeans_baseline=args.run_kmeans_baseline,  # ä¼ é€’K-meansåŸºçº¿å‚æ•°
            use_l2=args.l2,
            eval_dense=args.eval_dense,
            fast_mode=args.fast_mode,  # ä¼ é€’å¿«é€Ÿæ¨¡å¼å‚æ•°
            dense_method=args.dense_method,  # ä¼ é€’å¯†åº¦è®¡ç®—æ–¹æ³•
            assign_model=args.assign_model,  # ä¼ é€’ç¨€ç–ç‚¹åˆ†é…ç­–ç•¥
            voting_k=args.voting_k,  # ä¼ é€’KNNæŠ•ç¥¨é‚»å±…æ•°é‡
            co_mode=args.co_mode,  # ä¼ é€’coè®¡ç®—æ¨¡å¼
            co_manual=args.co_manual,  # ä¼ é€’æ‰‹åŠ¨æŒ‡å®šçš„coå€¼
            detail_dense=args.detail_dense,  # å ä½å‚æ•°ï¼ˆå½“å‰å®ç°ä¸å†è®°å½•è¯¦ç»†æ—¥å¿—ï¼‰
            label_guide=args.label_guide,  # ä¼ é€’æ ‡ç­¾å¼•å¯¼æ¨¡å¼å‚æ•°
            # analyze_errors å‚æ•°å·²ç§»é™¤ï¼Œè¿™é‡Œä¿æŒå‘åå…¼å®¹å ä½
            use_cluster_quality=args.use_cluster_quality,  # ä¼ é€’èšç±»è´¨é‡è¯„ä¼°å‚æ•°
            cluster_distance_method=args.cluster_distance_method,  # ä¼ é€’ç°‡è·ç¦»è®¡ç®—æ–¹æ³•
            l1_type=args.l1_type,  # ä¼ é€’L1æŸå¤±ç±»å‹
            separation_weight=args.separation_weight,  # ä¼ é€’L2ä¸­ç°‡é—´åˆ†ç¦»åº¦æƒé‡
            penalty_weight=args.penalty_weight,  # ä¼ é€’L2ä¸­å±€éƒ¨å¯†åº¦æƒ©ç½šæƒé‡
            l2_components=parsed_l2_components,
            l2_component_weights=parsed_l2_weights
        )

        # å¦‚æœå¼€å¯K-meansåŸºçº¿å¯¹æ¯”
        if args.run_kmeans_baseline:
            print("\n" + "="*80)
            print("ğŸ”„ è¿è¡ŒK-meansåŸºçº¿å¯¹æ¯”...")
            print("âœ… ç°åœ¨ä½¿ç”¨ä¸eval_original_gcdå®Œå…¨ç›¸åŒçš„L2å½’ä¸€åŒ–ç‰¹å¾")

            # ä½¿ç”¨SS-DDBCæµ‹è¯•ä¸­å·²æå–çš„æµ‹è¯•é›†ç‰¹å¾ (ç›¸åŒçš„L2å½’ä¸€åŒ–)
            test_features = ssddbc_results['test_features']
            test_targets = ssddbc_results['test_targets']
            test_known_mask = ssddbc_results['test_known_mask']

            # ä½¿ç”¨çœŸå®çš„ç±»åˆ«æ•°ä½œä¸ºK-meansèšç±»æ•°ï¼ˆä¸eval_original_gcd.pyä¿æŒä¸€è‡´ï¼‰
            n_true_classes = len(np.unique(test_targets))
            print(f"ğŸ¯ K-meansèšç±»æ•°é‡: {n_true_classes} (çœŸå®ç±»åˆ«æ•°)")

            # è¿è¡ŒK-means (ä½¿ç”¨ç›¸åŒçš„L2å½’ä¸€åŒ–ç‰¹å¾å’Œè¯„ä¼°ç‰ˆæœ¬)
            kmeans_results = test_kmeans_baseline(
                test_features,  # ç›¸åŒçš„L2å½’ä¸€åŒ–ç‰¹å¾
                test_targets,
                test_known_mask,
                n_clusters=n_true_classes,  # ä½¿ç”¨çœŸå®ç±»åˆ«æ•°
                random_state=0,  # K-meansä¿æŒåŸå§‹çš„random_state=0
                eval_version=args.eval_version,  # ä½¿ç”¨ç›¸åŒçš„è¯„ä¼°ç‰ˆæœ¬
                kmeans_merge=args.kmeans_merge,  # æ˜¯å¦åˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                train_features=ssddbc_results.get('train_features'),  # è®­ç»ƒé›†ç‰¹å¾
                train_targets=ssddbc_results.get('train_targets'),   # è®­ç»ƒé›†æ ‡ç­¾
                train_known_mask=ssddbc_results.get('train_known_mask')  # è®­ç»ƒé›†å·²çŸ¥æ©ç 
            )

            # æ˜¾ç¤ºK-meansèšç±»ç»†èŠ‚åˆ†æ
            print(f"\nğŸ” K-meansèšç±»ç»“æœè¯¦ç»†åˆ†æ:")
            kmeans_predictions = kmeans_results['predictions']
            kmeans_n_clusters = kmeans_results['n_clusters']

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†kmeans_mergeæ¨¡å¼
            if args.kmeans_merge and 'all_predictions' in kmeans_results:
                # åˆå¹¶æ¨¡å¼ï¼šæ˜¾ç¤ºæ•´ä¸ªåˆå¹¶æ•°æ®é›†çš„èšç±»åˆ†æ
                print(f"   æ¨¡å¼: åˆå¹¶è®­ç»ƒ+æµ‹è¯•é›†åˆ†æ")
                all_predictions_kmeans = kmeans_results['all_predictions']
                all_targets_kmeans = np.concatenate([ssddbc_results['train_targets'], test_targets], axis=0)
                all_known_mask_kmeans = np.concatenate([ssddbc_results['train_known_mask'], test_known_mask], axis=0)
                all_labeled_mask_kmeans = np.concatenate([ssddbc_results['train_labeled_mask'], np.zeros_like(test_known_mask, dtype=bool)], axis=0)

                analyze_cluster_composition(
                    all_predictions_kmeans,
                    all_targets_kmeans,
                    all_known_mask_kmeans,
                    all_labeled_mask_kmeans,
                    []  # K-meansæ²¡æœ‰æ½œåœ¨æœªçŸ¥ç±»
                )
            else:
                # ä»…æµ‹è¯•é›†æ¨¡å¼ï¼šæ˜¾ç¤ºæµ‹è¯•é›†èšç±»åˆ†æ
                print(f"   æ¨¡å¼: ä»…æµ‹è¯•é›†åˆ†æ")
                analyze_cluster_composition(
                    kmeans_predictions,
                    test_targets,
                    test_known_mask,
                    np.zeros_like(test_known_mask, dtype=bool),  # K-meansæ²¡æœ‰labeled_maskæ¦‚å¿µï¼Œè®¾ä¸ºå…¨False
                    []  # K-meansæ²¡æœ‰æ½œåœ¨æœªçŸ¥ç±»
                )

            # å¯¹æ¯”ç»“æœ
            print(f"\nğŸ“Š ç®—æ³•å¯¹æ¯”ç»“æœ:")
            print("="*80)
            print(f"{'æŒ‡æ ‡':<15} {'SS-DDBC':<12} {'K-means':<12} {'å·®å¼‚':<12}")
            print("-"*80)
            print(f"{'All ACC':<15} {ssddbc_results['all_acc']:<12.4f} {kmeans_results['all_acc']:<12.4f} {ssddbc_results['all_acc']-kmeans_results['all_acc']:<+12.4f}")
            print(f"{'Old ACC':<15} {ssddbc_results['old_acc']:<12.4f} {kmeans_results['old_acc']:<12.4f} {ssddbc_results['old_acc']-kmeans_results['old_acc']:<+12.4f}")
            print(f"{'New ACC':<15} {ssddbc_results['new_acc']:<12.4f} {kmeans_results['new_acc']:<12.4f} {ssddbc_results['new_acc']-kmeans_results['new_acc']:<+12.4f}")
            print(f"{'èšç±»æ•°':<15} {ssddbc_results['n_clusters']:<12} {kmeans_results['n_clusters']:<12} {'=':<12}")
            print("="*80)

        print("\næµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
