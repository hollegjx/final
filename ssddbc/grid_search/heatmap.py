#!/usr/bin/env python3
"""
å‚æ•°çƒ­åŠ›å›¾ç»˜åˆ¶å·¥å…·
ç»˜åˆ¶kå’Œdensity_percentileå‚æ•°ä¸ACCå…³ç³»çš„çƒ­åŠ›å›¾ï¼Œç”¨äºå¯è§†åŒ–å‚æ•°è°ƒä¼˜ç»“æœ
è°ƒç”¨test_adaptive_ssddbc.pyä¸­çš„å‡½æ•°è¿›è¡Œç½‘æ ¼æœç´¢ï¼Œé¿å…ä»£ç é‡å¤
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
from datetime import datetime
from itertools import product
import warnings
import re
import glob
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥test_adaptive_clusteringä¸­çš„ä¸»è¦å‡½æ•°ï¼ˆä¿®å¤ç›¸å¯¹å¯¼å…¥é—®é¢˜ï¼‰
from ssddbc.testing.test_superclass import test_adaptive_clustering_on_superclass
from config import (
    grid_search_output_dir,
    heatmap_output_dir,
    superclass_model_root
)


def load_existing_results(superclass_name, search_dir=grid_search_output_dir):
    """
    ä»å·²ä¿å­˜çš„æœç´¢ç»“æœæ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼Œé¿å…é‡å¤è®¡ç®—

    Args:
        superclass_name: è¶…ç±»åç§°
        search_dir: æœç´¢ç»“æœç›®å½•

    Returns:
        dict: {(k, density_percentile): {'all_acc': xx, 'old_acc': xx, ...}} æˆ– None
    """
    superclass_dir = os.path.join(search_dir, superclass_name)

    if not os.path.exists(superclass_dir):
        print(f"âš ï¸  æœç´¢ç»“æœç›®å½•ä¸å­˜åœ¨: {superclass_dir}")
        return None

    # æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
    result_files = glob.glob(os.path.join(superclass_dir, "*.txt"))
    if not result_files:
        print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœç´¢ç»“æœæ–‡ä»¶: {superclass_dir}")
        return None

    # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(result_files, key=os.path.getmtime)
    print(f"ğŸ“‚ åŠ è½½å·²æœ‰æœç´¢ç»“æœ: {latest_file}")

    try:
        results_dict = {}
        with open(latest_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æbatch_runner.pyç”Ÿæˆçš„æ–‡ä»¶æ ¼å¼
        # æ›´æ–°patternä»¥åŒ…å«labeled_acc
        pattern = r'k=(\d+), density_percentile=(\d+)\n-+\n.*?all_acc: (\d+\.?\d*)\nold_acc: (\d+\.?\d*)\nnew_acc: (\d+\.?\d*)\nclusters: (\d+)'

        matches = re.findall(pattern, content, re.DOTALL)

        # è§£ælabeled_accï¼ˆå¯é€‰å­—æ®µï¼Œå¯èƒ½ä¸ºN/Aï¼‰
        labeled_acc_pattern = r'k=(\d+), density_percentile=(\d+).*?labeled_acc: (N/A|[-\d]+\.?\d*)'
        labeled_acc_matches = re.findall(labeled_acc_pattern, content, re.DOTALL)

        # åˆ›å»ºå­—å…¸æ–¹ä¾¿æŸ¥æ‰¾
        labeled_acc_dict = {}
        for m in labeled_acc_matches:
            key = (int(m[0]), int(m[1]))
            labeled_acc_dict[key] = None if m[2] == 'N/A' else float(m[2])

        # è§£æl1_lossï¼ˆæ–°å¢å­—æ®µï¼‰
        l1_loss_pattern = r'k=(\d+), density_percentile=(\d+).*?l1_loss: (N/A|[-\d]+\.?\d*)'
        l1_loss_matches = re.findall(l1_loss_pattern, content, re.DOTALL)

        # åˆ›å»ºå­—å…¸æ–¹ä¾¿æŸ¥æ‰¾
        l1_loss_dict = {}
        for m in l1_loss_matches:
            key = (int(m[0]), int(m[1]))
            l1_loss_dict[key] = None if m[2] == 'N/A' else float(m[2])

        # åŒæ—¶å°è¯•è§£æè½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°ï¼ˆæ—§ç‰ˆå¯é€‰å­—æ®µï¼‰
        # æ³¨æ„ï¼šè½®å»“ç³»æ•°å¯ä»¥æ˜¯è´Ÿæ•°ï¼ˆèŒƒå›´-1åˆ°1ï¼‰ï¼Œæ‰€ä»¥éœ€è¦åŒ¹é…è´Ÿå·
        silhouette_pattern = r'k=(\d+), density_percentile=(\d+).*?Silhouette\s+(-?\d+\.?\d*)'
        db_pattern = r'k=(\d+), density_percentile=(\d+).*?DB Score\s+(-?\d+\.?\d*)'

        silhouette_matches = re.findall(silhouette_pattern, content, re.DOTALL)
        db_matches = re.findall(db_pattern, content, re.DOTALL)

        # åˆ›å»ºå­—å…¸æ–¹ä¾¿æŸ¥æ‰¾
        silhouette_dict = {(int(m[0]), int(m[1])): float(m[2]) for m in silhouette_matches}
        db_dict = {(int(m[0]), int(m[1])): float(m[2]) for m in db_matches}

        # è§£æèšç±»è´¨é‡æŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰
        quality_score_pattern = r'k=(\d+), density_percentile=(\d+).*?quality_score: ([-\d]+\.?\d*)'
        separation_score_pattern = r'k=(\d+), density_percentile=(\d+).*?separation_score: ([-\d]+\.?\d*)'
        penalty_score_pattern = r'k=(\d+), density_percentile=(\d+).*?penalty_score: ([-\d]+\.?\d*)'

        quality_score_matches = re.findall(quality_score_pattern, content, re.DOTALL)
        separation_score_matches = re.findall(separation_score_pattern, content, re.DOTALL)
        penalty_score_matches = re.findall(penalty_score_pattern, content, re.DOTALL)

        quality_score_dict = {(int(m[0]), int(m[1])): float(m[2]) for m in quality_score_matches}
        separation_score_dict = {(int(m[0]), int(m[1])): float(m[2]) for m in separation_score_matches}
        penalty_score_dict = {(int(m[0]), int(m[1])): float(m[2]) for m in penalty_score_matches}

        # è§£æé€šç”¨L2ç»„ä»¶æŒ‡æ ‡ - æ”¹ç”¨åˆ†å—è§£æé¿å…è·¨å‚æ•°ç»„åˆåŒ¹é…
        component_data = {}

        # æŒ‰å‚æ•°ç»„åˆåˆ†å—ï¼ˆä»¥ "k=æ•°å­—, density_percentile=æ•°å­—" ä¸ºåˆ†éš”ç¬¦ï¼‰
        param_blocks = re.split(r'(?=k=\d+, density_percentile=\d+)', content)

        for block in param_blocks:
            if not block.strip():
                continue

            # æå–å½“å‰å—çš„ k å’Œ dp
            header_match = re.match(r'k=(\d+), density_percentile=(\d+)', block)
            if not header_match:
                continue

            k = int(header_match.group(1))
            dp = int(header_match.group(2))
            key = (k, dp)

            # åœ¨å½“å‰å—å†…æŸ¥æ‰¾æ‰€æœ‰ç»„ä»¶
            comp_value_matches = re.findall(r'component_(\w+)_value: ([-\d]+\.?\d*)', block)
            comp_contrib_matches = re.findall(r'component_(\w+)_contribution: ([-\d]+\.?\d*)', block)
            comp_orient_matches = re.findall(r'component_(\w+)_orientation: ([A-Za-z]+)', block)

            if comp_value_matches:
                comp_entry = component_data.setdefault(key, {})

                for comp_name, value_str in comp_value_matches:
                    entry = comp_entry.setdefault(comp_name, {})
                    entry['value'] = float(value_str)

                for comp_name, contrib_str in comp_contrib_matches:
                    entry = comp_entry.setdefault(comp_name, {})
                    entry['contribution'] = float(contrib_str)

                for comp_name, orient in comp_orient_matches:
                    entry = comp_entry.setdefault(comp_name, {})
                    entry['orientation'] = orient

        # å°è¯•è§£æK-meansç¼“å­˜ç»“æœï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶è®°å½•ï¼‰
        kmeans_cache = {'all_acc': 0.0, 'old_acc': 0.0, 'new_acc': 0.0}

        for match in matches:
            k = int(match[0])
            density_percentile = int(match[1])
            ss_ddbc_all_acc = float(match[2])
            ss_ddbc_old_acc = float(match[3])
            ss_ddbc_new_acc = float(match[4])
            ss_ddbc_clusters = int(match[5])

            # è·å–æ‰€æœ‰è´¨é‡æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            silhouette_score = silhouette_dict.get((k, density_percentile), None)
            db_score = db_dict.get((k, density_percentile), None)
            labeled_acc_score = labeled_acc_dict.get((k, density_percentile), None)

            # è·å–èšç±»è´¨é‡æŒ‡æ ‡ï¼ˆæ–°å¢ï¼‰
            quality_score = quality_score_dict.get((k, density_percentile), None)
            separation_score = separation_score_dict.get((k, density_percentile), None)
            penalty_score = penalty_score_dict.get((k, density_percentile), None)

            results_dict[(k, density_percentile)] = {
                'all_acc': ss_ddbc_all_acc,
                'old_acc': ss_ddbc_old_acc,
                'new_acc': ss_ddbc_new_acc,
                'n_clusters': ss_ddbc_clusters,
                'kmeans_all_acc': kmeans_cache['all_acc'],  # ä½¿ç”¨ç¼“å­˜å€¼æˆ–é»˜è®¤å€¼
                'kmeans_old_acc': kmeans_cache['old_acc'],
                'kmeans_new_acc': kmeans_cache['new_acc'],
                'silhouette': silhouette_score,
                'db_score': db_score,
                'labeled_acc': labeled_acc_score,
                'l1_loss': l1_loss_dict.get((k, density_percentile), None),  # æ–°å¢L1æŸå¤±å­—æ®µ
                'quality_score': quality_score,
                'separation_score': separation_score,
                'penalty_score': penalty_score,
                'l2_components': component_data.get((k, density_percentile), {})
            }

        print(f"âœ… æˆåŠŸåŠ è½½ {len(results_dict)} ä¸ªå‚æ•°ç»„åˆçš„ç»“æœ")
        return results_dict

    except Exception as e:
        print(f"âŒ è§£æç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        return None


def detect_available_superclasses(search_dir=grid_search_output_dir):
    """
    è‡ªåŠ¨æ¢æµ‹æœç´¢ç»“æœç›®å½•ä¸­å­˜åœ¨çš„æ‰€æœ‰è¶…ç±»

    Args:
        search_dir: æœç´¢ç»“æœç›®å½•

    Returns:
        list: åŒ…å«ç»“æœæ–‡ä»¶çš„è¶…ç±»åç§°åˆ—è¡¨
    """
    if not os.path.exists(search_dir):
        print(f"âš ï¸  æœç´¢ç»“æœç›®å½•ä¸å­˜åœ¨: {search_dir}")
        return []

    superclass_list = []

    # éå†æœç´¢ç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹
    for item in os.listdir(search_dir):
        item_path = os.path.join(search_dir, item)

        # åªå¤„ç†æ–‡ä»¶å¤¹
        if os.path.isdir(item_path):
            # æ£€æŸ¥æ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰.txtç»“æœæ–‡ä»¶
            txt_files = glob.glob(os.path.join(item_path, "*.txt"))
            if txt_files:
                superclass_list.append(item)

    return sorted(superclass_list)  # æŒ‰å­—æ¯é¡ºåºæ’åº


def print_progress_bar(current, total, prefix='Progress', suffix='Complete', length=50):
    """æ‰“å°è¿›åº¦æ¡"""
    percent = f"{100 * (current / float(total)):.1f}"
    filled_length = int(length * current // total)
    bar = 'â–ˆ' * filled_length + '-' * (length - filled_length)
    print(f'\r{prefix} |{bar}| {percent}% {suffix} ({current}/{total})', end='', flush=True)
    if current == total:
        print()


def run_parameter_grid_search(superclass_name, model_path, k_range=(3, 21),
                             density_percentile_range=(20, 100), step=5,
                             eval_version='v2', merge_clusters=True):
    """
    è¿è¡Œå‚æ•°ç½‘æ ¼æœç´¢ï¼Œæ”¶é›†æ•°æ®ç”¨äºç»˜åˆ¶çƒ­åŠ›å›¾

    Args:
        superclass_name: è¶…ç±»åç§°
        model_path: æ¨¡å‹è·¯å¾„
        k_range: kå€¼èŒƒå›´ (start, end)
        density_percentile_range: å¯†åº¦ç™¾åˆ†ä½èŒƒå›´ (start, end)
        step: å¯†åº¦ç™¾åˆ†ä½æ­¥é•¿
        eval_version: è¯„ä¼°ç‰ˆæœ¬
        merge_clusters: æ˜¯å¦åˆå¹¶èšç±»

    Returns:
        results_dict: {(k, density_percentile): {'all_acc': xx, 'old_acc': xx, 'new_acc': xx, ...}}
    """
    print(f"ğŸ” å¼€å§‹å‚æ•°ç½‘æ ¼æœç´¢ - è¶…ç±»: {superclass_name}")
    print("=" * 80)

    # å‚æ•°èŒƒå›´
    k_values = list(range(k_range[0], k_range[1]))
    density_percentile_values = list(range(density_percentile_range[0],
                                         density_percentile_range[1], step))

    print(f"Kå€¼èŒƒå›´: {k_values}")
    print(f"å¯†åº¦ç™¾åˆ†ä½èŒƒå›´: {density_percentile_values}")
    print(f"è¯„ä¼°ç‰ˆæœ¬: {eval_version}")
    print(f"èšç±»åˆå¹¶: {'å¯ç”¨' if merge_clusters else 'ç¦ç”¨'}")
    print(f"æ€»å‚æ•°ç»„åˆæ•°: {len(k_values) * len(density_percentile_values)}")

    # å­˜å‚¨ç»“æœ
    results_dict = {}
    total_combinations = len(k_values) * len(density_percentile_values)
    current_combination = 0

    for k, density_percentile in product(k_values, density_percentile_values):
        current_combination += 1

        # æ˜¾ç¤ºè¿›åº¦
        print_progress_bar(current_combination - 1, total_combinations,
                         prefix=f'ç½‘æ ¼æœç´¢è¿›åº¦', suffix=f'k={k}, density_percentile={density_percentile}')

        try:
            # è°ƒç”¨test_adaptive_ssddbc.pyä¸­çš„å‡½æ•°
            results = test_adaptive_clustering_on_superclass(
                superclass_name=superclass_name,
                model_path=model_path,
                k=k,
                density_percentile=density_percentile,
                eval_version=eval_version,
                fast_mode=True,  # ç½‘æ ¼æœç´¢ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
                run_kmeans_baseline=True
            )

            if results and isinstance(results, dict):
                # å­˜å‚¨ç»“æœ
                loss_dict = results.get('loss_dict') or {}
                l2_metrics = loss_dict.get('l2_metrics', {})
                cluster_quality = l2_metrics.get('cluster_quality', {})
                results_dict[(k, density_percentile)] = {
                    'all_acc': results.get('all_acc', 0.0),
                    'old_acc': results.get('old_acc', 0.0),
                    'new_acc': results.get('new_acc', 0.0),
                    'n_clusters': results.get('n_clusters', 0),
                    'kmeans_all_acc': results.get('kmeans_all_acc', 0.0),
                    'kmeans_old_acc': results.get('kmeans_old_acc', 0.0),
                    'kmeans_new_acc': results.get('kmeans_new_acc', 0.0),
                    'l1_loss': results.get('l1'),
                    'loss': results.get('loss'),
                    'l1': results.get('l1'),
                    'l2': results.get('l2'),
                    'loss_dict': loss_dict,
                    'labeled_acc': results.get('labeled_acc'),
                    'quality_score': cluster_quality.get('quality_score'),
                    'separation_score': cluster_quality.get('separation_score'),
                    'penalty_score': cluster_quality.get('penalty_score')
                }
            else:
                print(f"\nâš ï¸  å‚æ•°ç»„åˆ k={k}, density_percentile={density_percentile} å¤±è´¥")
                results_dict[(k, density_percentile)] = {
                    'all_acc': 0.0, 'old_acc': 0.0, 'new_acc': 0.0,
                    'n_clusters': 0,
                    'kmeans_all_acc': 0.0, 'kmeans_old_acc': 0.0, 'kmeans_new_acc': 0.0,
                    'l1_loss': None,
                    'loss': None,
                    'l1': None,
                    'l2': None,
                    'loss_dict': None,
                    'labeled_acc': None,
                    'quality_score': None,
                    'separation_score': None,
                    'penalty_score': None
                }

        except Exception as e:
            print(f"\nâŒ å‚æ•°ç»„åˆ k={k}, density_percentile={density_percentile} å‡ºç°å¼‚å¸¸: {str(e)}")
            results_dict[(k, density_percentile)] = {
                'all_acc': 0.0, 'old_acc': 0.0, 'new_acc': 0.0,
                'n_clusters': 0,
                'kmeans_all_acc': 0.0, 'kmeans_old_acc': 0.0, 'kmeans_new_acc': 0.0,
                'l1_loss': None,
                'loss': None,
                'l1': None,
                'l2': None,
                'loss_dict': None,
                'labeled_acc': None,
                'quality_score': None,
                'separation_score': None,
                'penalty_score': None
            }

    # å®Œæˆæ—¶æ˜¾ç¤ºæœ€ç»ˆè¿›åº¦æ¡
    print_progress_bar(total_combinations, total_combinations,
                     prefix=f'ç½‘æ ¼æœç´¢è¿›åº¦', suffix='å®Œæˆ!')

    print(f"\nâœ… å‚æ•°ç½‘æ ¼æœç´¢å®Œæˆ")
    print(f"ğŸ“Š æˆåŠŸå®Œæˆ: {len([r for r in results_dict.values() if r['all_acc'] > 0])}/{total_combinations} ä¸ªå‚æ•°ç»„åˆ")

    return results_dict


def create_heatmap(results_dict, metric='all_acc', superclass_name='',
                  output_dir=heatmap_output_dir, save_plots=True,
                  show_clusters=False):
    """
    åˆ›å»ºå‚æ•°çƒ­åŠ›å›¾ï¼ˆç”Ÿæˆä¸¤å¼ å›¾ï¼šä¸€å¼ æ˜¾ç¤ºACCå€¼ï¼Œä¸€å¼ æ˜¾ç¤ºèšç±»æ•°ï¼‰

    Args:
        results_dict: ç½‘æ ¼æœç´¢ç»“æœå­—å…¸
        metric: è¦å¯è§†åŒ–çš„æŒ‡æ ‡ ('all_acc', 'old_acc', 'new_acc', 'l1_loss'ç­‰)
        superclass_name: è¶…ç±»åç§°
        output_dir: è¾“å‡ºç›®å½•
        save_plots: æ˜¯å¦ä¿å­˜å›¾ç‰‡
        show_clusters: æ˜¯å¦é¢å¤–ç”Ÿæˆæ˜¾ç¤ºèšç±»æ•°é‡çš„çƒ­åŠ›å›¾ï¼ˆä»…å¯¹all_accå¯ç”¨ï¼‰
    """
    print(f"ğŸ¨ ç»˜åˆ¶çƒ­åŠ›å›¾ - æŒ‡æ ‡: {metric}")

    # æ ¹æ®æŒ‡æ ‡ç±»å‹å†³å®šæ’åºæ–¹å‘ï¼šæŸå¤±ç±»æŒ‡æ ‡è¶Šå°è¶Šå¥½ï¼Œå‡†ç¡®ç‡ç±»æŒ‡æ ‡è¶Šå¤§è¶Šå¥½
    loss_metrics = ['l1_loss', 'quality_score', 'penalty_score']  # æŸå¤±ç±»æŒ‡æ ‡ï¼Œè¶Šå°è¶Šå¥½

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåŒ…å«è¶…ç±»åç§°å­ç›®å½•ï¼‰
    if save_plots:
        superclass_output_dir = os.path.join(output_dir, superclass_name)
        os.makedirs(superclass_output_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {superclass_output_dir}")

    # æå–å‚æ•°å’Œç»“æœ
    k_values = sorted(list(set([k for k, _ in results_dict.keys()])))
    density_percentile_values = sorted(list(set([dp for _, dp in results_dict.keys()])))

    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®çŸ©é˜µï¼ˆç”¨äºç€è‰²ï¼‰
    heatmap_data = np.zeros((len(density_percentile_values), len(k_values)))
    # åˆ›å»ºèšç±»æ•°çŸ©é˜µï¼ˆç”¨äºç¬¬äºŒå¼ å›¾çš„æ ‡æ³¨ï¼‰
    cluster_data = np.zeros((len(density_percentile_values), len(k_values)))

    for i, dp in enumerate(density_percentile_values):
        for j, k in enumerate(k_values):
            if (k, dp) in results_dict:
                # æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨NaN
                if metric in results_dict[(k, dp)] and results_dict[(k, dp)][metric] is not None:
                    heatmap_data[i, j] = results_dict[(k, dp)][metric]
                else:
                    heatmap_data[i, j] = np.nan
                    print(f"âš ï¸  è­¦å‘Š: (k={k}, dp={dp}) ç¼ºå°‘æŒ‡æ ‡ '{metric}'ï¼Œä½¿ç”¨NaNå¡«å……")

                cluster_data[i, j] = results_dict[(k, dp)].get('n_clusters', np.nan)
            else:
                heatmap_data[i, j] = np.nan
                cluster_data[i, j] = np.nan

    # æ‰¾åˆ°å‰3åçš„ä½ç½®
    valid_data = []
    for i in range(heatmap_data.shape[0]):
        for j in range(heatmap_data.shape[1]):
            if not np.isnan(heatmap_data[i, j]):
                valid_data.append((heatmap_data[i, j], i, j))

    if metric in loss_metrics:
        valid_data.sort(key=lambda x: x[0])  # å‡åºæ’åˆ—ï¼Œæœ€å°å€¼åœ¨å‰
    else:
        valid_data.sort(key=lambda x: x[0], reverse=True)  # é™åºæ’åˆ—ï¼Œæœ€å¤§å€¼åœ¨å‰

    top3 = valid_data[:3]

    # ==================== ç¬¬ä¸€å¼ å›¾ï¼šæ˜¾ç¤ºACCå€¼ ====================
    fig1, ax1 = plt.subplots(figsize=(12, 8))

    # æ ¹æ®æŒ‡æ ‡ç±»å‹é€‰æ‹©é¢œè‰²æ˜ å°„ï¼šæŸå¤±ç±»æŒ‡æ ‡ç”¨åå‘æ˜ å°„ï¼Œå‡†ç¡®ç‡ç±»æŒ‡æ ‡ç”¨æ­£å‘æ˜ å°„
    if metric in loss_metrics:
        cmap = 'viridis_r'  # åå‘æ˜ å°„ï¼Œä½å€¼ï¼ˆå¥½ï¼‰ç”¨æ·±è‰²ï¼Œé«˜å€¼ï¼ˆå·®ï¼‰ç”¨æµ…è‰²
        cbar_label = f'{metric.upper()} (lower better)'
    else:
        cmap = 'viridis'  # æ­£å‘æ˜ å°„,é«˜å€¼ï¼ˆå¥½ï¼‰ç”¨æ·±è‰²ï¼Œä½å€¼ï¼ˆå·®ï¼‰ç”¨æµ…è‰²
        cbar_label = f'{metric.upper()} (higher better)'

    sns.heatmap(heatmap_data,
                xticklabels=k_values,
                yticklabels=density_percentile_values,
                annot=True,
                fmt='.3f',
                cmap=cmap,
                cbar_kws={'label': cbar_label},
                ax=ax1)

    # æ ‡æ³¨å‰3å
    for rank, (value, i, j) in enumerate(top3, 1):
        ax1.plot(j + 0.5, i + 0.5, marker='*', markersize=20,
                color='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                markeredgecolor='white', markeredgewidth=1.5)
        ax1.text(j + 0.5, i + 0.2, f'#{rank}',
                ha='center', va='center',
                fontsize=10, fontweight='bold', color='white',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                         edgecolor='white', linewidth=1.5, alpha=0.8))

    ax1.set_title(f'{metric.upper()} Heatmap - {superclass_name}\nParameters: k vs density_percentile (Top 3 marked)',
              fontsize=14, fontweight='bold')
    ax1.set_xlabel('k (Number of Neighbors)', fontsize=12)
    ax1.set_ylabel('Density Percentile', fontsize=12)

    plt.tight_layout()

    # ä¿å­˜ç¬¬ä¸€å¼ å›¾
    if save_plots:
        current_time = datetime.now()
        filename1 = f"{metric}_heatmap_{current_time.month}_{current_time.day}_{current_time.hour}_{current_time.minute}.png"
        output_path1 = os.path.join(superclass_output_dir, filename1)
        plt.savefig(output_path1, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ çƒ­åŠ›å›¾1 (ACCå€¼) å·²ä¿å­˜: {output_path1}")

    plt.show()

    # ==================== ç¬¬äºŒå¼ å›¾ï¼šæ˜¾ç¤ºèšç±»æ•°ï¼ˆåªå¯¹all_accæ˜¾ç¤ºï¼‰ ====================
    if show_clusters and metric == 'all_acc':
        fig2, ax2 = plt.subplots(figsize=(12, 8))

        # ä½¿ç”¨æŒ‡æ ‡å€¼ç€è‰²ï¼Œä½†æ ‡æ³¨æ˜¾ç¤ºèšç±»æ•°ï¼ˆåªå¯¹all_accæ˜¾ç¤ºèšç±»æ•°å›¾ï¼‰
        sns.heatmap(heatmap_data,
                    xticklabels=k_values,
                    yticklabels=density_percentile_values,
                    annot=cluster_data,  # æ˜¾ç¤ºèšç±»æ•°
                    fmt='.0f',  # æ•´æ•°æ ¼å¼
                    cmap=cmap,  # ä½¿ç”¨ä¸ç¬¬ä¸€å¼ å›¾ç›¸åŒçš„é¢œè‰²æ˜ å°„
                    cbar_kws={'label': cbar_label},
                    ax=ax2)

        # æ ‡æ³¨å‰3å
        for rank, (value, i, j) in enumerate(top3, 1):
            ax2.plot(j + 0.5, i + 0.5, marker='*', markersize=20,
                     color='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                     markeredgecolor='white', markeredgewidth=1.5)
            ax2.text(j + 0.5, i + 0.2, f'#{rank}',
                     ha='center', va='center',
                     fontsize=10, fontweight='bold', color='white',
                     bbox=dict(boxstyle='round,pad=0.3', facecolor='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                               edgecolor='white', linewidth=1.5, alpha=0.8))

        ax2.set_title(f'Number of Clusters (colored by {metric.upper()}) - {superclass_name}\nParameters: k vs density_percentile (Top 3 marked)',
                      fontsize=14, fontweight='bold')
        ax2.set_xlabel('k (Number of Neighbors)', fontsize=12)
        ax2.set_ylabel('Density Percentile', fontsize=12)

        plt.tight_layout()

        # ä¿å­˜ç¬¬äºŒå¼ å›¾
        if save_plots:
            filename2 = f"{metric}_clusters_heatmap_{current_time.month}_{current_time.day}_{current_time.hour}_{current_time.minute}.png"
            output_path2 = os.path.join(superclass_output_dir, filename2)
            plt.savefig(output_path2, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ çƒ­åŠ›å›¾2 (èšç±»æ•°) å·²ä¿å­˜: {output_path2}")

        plt.show()

    # æ‰¾åˆ°æœ€ä½³å‚æ•°ç»„åˆï¼ˆæ ¹æ®æŒ‡æ ‡ç±»å‹é€‰æ‹©argmaxæˆ–argminï¼‰
    if metric in loss_metrics:
        best_idx = np.unravel_index(np.nanargmin(heatmap_data), heatmap_data.shape)
    else:
        best_idx = np.unravel_index(np.nanargmax(heatmap_data), heatmap_data.shape)
    best_dp = density_percentile_values[best_idx[0]]
    best_k = k_values[best_idx[1]]
    best_value = heatmap_data[best_idx]

    # è¾“å‡ºå‰3åå‚æ•°ç»„åˆ
    print(f"\nğŸ† Top 3 å‚æ•°ç»„åˆ ({metric.upper()}):")
    print("-" * 60)
    for rank, (value, i, j) in enumerate(top3, 1):
        k_val = k_values[j]
        dp_val = density_percentile_values[i]
        n_clusters_val = int(cluster_data[i, j])
        emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰"
        print(f"{emoji} #{rank}: k={k_val:<3}, density_percentile={dp_val:<3}, {metric}={value:.4f}, n_clusters={n_clusters_val}")

    return best_k, best_dp, best_value


def create_quality_metrics_heatmap(results_dict, acc_metric='all_acc', superclass_name='',
                                   output_dir=heatmap_output_dir, save_plots=True):
    """
    åˆ›å»ºæ–°å¼çƒ­åŠ›å›¾ï¼šèƒŒæ™¯è‰²ä½¿ç”¨ACCå€¼ï¼Œå•å…ƒæ ¼æ–‡å­—æ˜¾ç¤ºè½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°

    Args:
        results_dict: ç½‘æ ¼æœç´¢ç»“æœå­—å…¸
        acc_metric: ç”¨äºç€è‰²çš„ACCæŒ‡æ ‡ ('all_acc', 'old_acc', 'new_acc')
        superclass_name: è¶…ç±»åç§°
        output_dir: è¾“å‡ºç›®å½•
        save_plots: æ˜¯å¦ä¿å­˜å›¾ç‰‡
    """
    print(f"ğŸ¨ ç»˜åˆ¶è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ - èƒŒæ™¯è‰²æŒ‡æ ‡: {acc_metric}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_plots:
        superclass_output_dir = os.path.join(output_dir, superclass_name)
        os.makedirs(superclass_output_dir, exist_ok=True)

    # æå–å‚æ•°å’Œç»“æœ
    k_values = sorted(list(set([k for k, _ in results_dict.keys()])))
    density_percentile_values = sorted(list(set([dp for _, dp in results_dict.keys()])))

    # åˆ›å»ºæ•°æ®çŸ©é˜µ
    acc_data = np.zeros((len(density_percentile_values), len(k_values)))
    silhouette_data = np.full((len(density_percentile_values), len(k_values)), np.nan)
    db_data = np.full((len(density_percentile_values), len(k_values)), np.nan)

    for i, dp in enumerate(density_percentile_values):
        for j, k in enumerate(k_values):
            if (k, dp) in results_dict:
                acc_data[i, j] = results_dict[(k, dp)][acc_metric]

                # è¯»å–è½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
                silhouette_val = results_dict[(k, dp)].get('silhouette', None)
                db_val = results_dict[(k, dp)].get('db_score', None)

                if silhouette_val is not None:
                    silhouette_data[i, j] = silhouette_val
                if db_val is not None:
                    db_data[i, j] = db_val
            else:
                acc_data[i, j] = np.nan

    # åˆ›å»ºè‡ªå®šä¹‰æ ‡æ³¨çŸ©é˜µï¼šæ¯ä¸ªå•å…ƒæ ¼æ˜¾ç¤º "S: xx.xxx\nDB: xx.xxx"
    annot_data = np.empty((len(density_percentile_values), len(k_values)), dtype=object)
    for i in range(len(density_percentile_values)):
        for j in range(len(k_values)):
            s_val = silhouette_data[i, j]
            db_val = db_data[i, j]

            if not np.isnan(s_val) and not np.isnan(db_val):
                annot_data[i, j] = f"S: {s_val:.3f}\nDB: {db_val:.3f}"
            elif not np.isnan(s_val):
                annot_data[i, j] = f"S: {s_val:.3f}\nDB: N/A"
            elif not np.isnan(db_val):
                annot_data[i, j] = f"S: N/A\nDB: {db_val:.3f}"
            else:
                annot_data[i, j] = "N/A"

    # æ‰¾åˆ°å‰3åACCçš„ä½ç½®
    valid_data = []
    for i in range(acc_data.shape[0]):
        for j in range(acc_data.shape[1]):
            if not np.isnan(acc_data[i, j]):
                valid_data.append((acc_data[i, j], i, j))

    valid_data.sort(key=lambda x: x[0], reverse=True)
    top3 = valid_data[:3]

    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(14, 10))

    sns.heatmap(acc_data,
                xticklabels=k_values,
                yticklabels=density_percentile_values,
                annot=annot_data,
                fmt='',  # ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼
                cmap='viridis',
                cbar_kws={'label': f'{acc_metric.upper()} (background color)'},
                ax=ax,
                annot_kws={'fontsize': 7})  # è°ƒæ•´å­—ä½“å¤§å°ä»¥å®¹çº³ä¸¤è¡Œæ–‡å­—

    # æ ‡æ³¨å‰3å
    for rank, (value, i, j) in enumerate(top3, 1):
        ax.plot(j + 0.5, i + 0.5, marker='*', markersize=20,
                color='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                markeredgecolor='white', markeredgewidth=1.5)
        ax.text(j + 0.5, i + 0.15, f'#{rank}',
                ha='center', va='center',
                fontsize=9, fontweight='bold', color='white',
                bbox=dict(boxstyle='round,pad=0.3',
                         facecolor='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                         edgecolor='white', linewidth=1.5, alpha=0.8))

    ax.set_title(f'Quality Metrics (Silhouette & DB) colored by {acc_metric.upper()} - {superclass_name}\n'
                 f'Parameters: k vs density_percentile (Top 3 marked)',
                 fontsize=14, fontweight='bold')
    ax.set_xlabel('k (Number of Neighbors)', fontsize=12)
    ax.set_ylabel('Density Percentile', fontsize=12)

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    if save_plots:
        current_time = datetime.now()
        filename = f"{acc_metric}_quality_metrics_heatmap_{current_time.month}_{current_time.day}_{current_time.hour}_{current_time.minute}.png"
        output_path = os.path.join(superclass_output_dir, filename)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ å·²ä¿å­˜: {output_path}")

    plt.show()

    # è¾“å‡ºå‰3åå‚æ•°ç»„åˆåŠå…¶è´¨é‡æŒ‡æ ‡
    print(f"\nğŸ† Top 3 å‚æ•°ç»„åˆ (æŒ‰ {acc_metric.upper()} æ’åºï¼Œæ˜¾ç¤ºè´¨é‡æŒ‡æ ‡):")
    print("-" * 80)
    for rank, (value, i, j) in enumerate(top3, 1):
        k_val = k_values[j]
        dp_val = density_percentile_values[i]
        s_val = silhouette_data[i, j]
        db_val = db_data[i, j]
        emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰"

        s_str = f"{s_val:.4f}" if not np.isnan(s_val) else "N/A"
        db_str = f"{db_val:.4f}" if not np.isnan(db_val) else "N/A"

        print(f"{emoji} #{rank}: k={k_val:<3}, density_percentile={dp_val:<3}, "
              f"{acc_metric}={value:.4f}, Silhouette={s_str}, DB={db_str}")

    return top3[0][1], top3[0][2]  # è¿”å›æœ€ä½³å‚æ•°çš„ç´¢å¼•


def create_multiple_quality_metrics_heatmaps(results_dict, superclass_name='',
                                             output_dir=heatmap_output_dir,
                                             acc_metrics=['all_acc', 'old_acc', 'new_acc'],
                                             save_plots=True):
    """
    åˆ›å»ºå¤šä¸ªACCæŒ‡æ ‡çš„è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆæ¯ä¸ªACCç”Ÿæˆä¸€å¼ çƒ­åŠ›å›¾ï¼‰
    """
    print(f"ğŸ¨ åˆ›å»ºå¤šACCè´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾...")

    for acc_metric in acc_metrics:
        print(f"\n{'='*60}")
        create_quality_metrics_heatmap(
            results_dict, acc_metric, superclass_name, output_dir, save_plots
        )

    print(f"\nâœ… æ‰€æœ‰è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾åˆ›å»ºå®Œæˆ!")


def create_multiple_heatmaps(results_dict, superclass_name='', output_dir=heatmap_output_dir,
                           metrics=['all_acc', 'old_acc', 'new_acc'], save_plots=True):
    """
    åˆ›å»ºå¤šä¸ªæŒ‡æ ‡çš„çƒ­åŠ›å›¾
    """
    print(f"ğŸ¨ åˆ›å»ºå¤šæŒ‡æ ‡çƒ­åŠ›å›¾...")

    best_params = {}

    for metric in metrics:
        print(f"\n{'='*60}")
        try:
            # åªå¯¹all_accæ˜¾ç¤ºèšç±»æ•°
            show_clusters = (metric == 'all_acc')
            best_k, best_dp, best_value = create_heatmap(
                results_dict, metric, superclass_name, output_dir, save_plots, show_clusters
            )
            best_params[metric] = {
                'k': best_k,
                'density_percentile': best_dp,
                'value': best_value
            }
        except Exception as e:
            print(f"âŒ {superclass_name} çƒ­åŠ›å›¾ç»˜åˆ¶å¤±è´¥: {e}")
            best_params[metric] = {
                'k': None,
                'density_percentile': None,
                'value': None,
                'error': str(e)
            }
            continue

    # è¾“å‡ºæœ€ä½³å‚æ•°æ€»ç»“
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {superclass_name} æœ€ä½³å‚æ•°æ€»ç»“:")
    print(f"{'='*80}")
    for metric, params in best_params.items():
        print(f"{metric.upper():<12}: k={params['k']:<3}, density_percentile={params['density_percentile']:<3}, value={params['value']:.4f}")

    return best_params


def create_mixed_heatmap(results_dict, color_metric='all_acc', display_metric='labeled_acc',
                         superclass_name='', output_dir=heatmap_output_dir,
                         save_plots=True):
    """
    åˆ›å»ºæ··åˆçƒ­åŠ›å›¾ï¼šç”¨ä¸€ä¸ªæŒ‡æ ‡ç€è‰²ï¼Œæ˜¾ç¤ºå¦ä¸€ä¸ªæŒ‡æ ‡çš„æ•°å€¼

    Args:
        results_dict: ç½‘æ ¼æœç´¢ç»“æœå­—å…¸
        color_metric: ç”¨äºç€è‰²çš„æŒ‡æ ‡ (ä¾‹å¦‚ 'all_acc')
        display_metric: ç”¨äºæ˜¾ç¤ºæ•°å€¼çš„æŒ‡æ ‡ (ä¾‹å¦‚ 'labeled_acc')
        superclass_name: è¶…ç±»åç§°
        output_dir: è¾“å‡ºç›®å½•
        save_plots: æ˜¯å¦ä¿å­˜å›¾ç‰‡

    Returns:
        best_k, best_dp, best_value: åŸºäºcolor_metricçš„æœ€ä½³å‚æ•°
    """
    print(f"ğŸ¨ ç»˜åˆ¶æ··åˆçƒ­åŠ›å›¾ - ç€è‰²: {color_metric}, æ˜¾ç¤º: {display_metric}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_plots:
        superclass_output_dir = os.path.join(output_dir, superclass_name)
        os.makedirs(superclass_output_dir, exist_ok=True)

    # æå–å‚æ•°å’Œç»“æœ
    k_values = sorted(list(set([k for k, _ in results_dict.keys()])))
    density_percentile_values = sorted(list(set([dp for _, dp in results_dict.keys()])))

    # åˆ›å»ºä¸¤ä¸ªæ•°æ®çŸ©é˜µ
    color_data = np.zeros((len(density_percentile_values), len(k_values)))  # ç”¨äºç€è‰²
    display_data = np.zeros((len(density_percentile_values), len(k_values)))  # ç”¨äºæ˜¾ç¤º

    for i, dp in enumerate(density_percentile_values):
        for j, k in enumerate(k_values):
            if (k, dp) in results_dict:
                # ç€è‰²æ•°æ®
                color_value = results_dict[(k, dp)].get(color_metric)
                color_data[i, j] = color_value if color_value is not None else np.nan

                # æ˜¾ç¤ºæ•°æ®
                display_value = results_dict[(k, dp)].get(display_metric)
                display_data[i, j] = display_value if display_value is not None else np.nan
            else:
                color_data[i, j] = np.nan
                display_data[i, j] = np.nan

    # æ‰¾åˆ°åŸºäºdisplay_metricçš„å‰3åä½ç½®ï¼ˆæŒ‰æ˜¾ç¤ºçš„æŒ‡æ ‡æ’åºï¼Œè€Œä¸æ˜¯èƒŒæ™¯é¢œè‰²ï¼‰
    valid_data = []
    for i in range(display_data.shape[0]):
        for j in range(display_data.shape[1]):
            if not np.isnan(display_data[i, j]):
                valid_data.append((display_data[i, j], i, j))

    valid_data.sort(key=lambda x: x[0], reverse=True)
    top3 = valid_data[:3] if len(valid_data) >= 3 else valid_data

    # åˆ›å»ºçƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(14, 9))

    # ç”¨color_metricç€è‰²ï¼Œä½†æ˜¾ç¤ºdisplay_metricçš„æ•°å€¼
    annot_fmt = '.4f'

    sns.heatmap(color_data,
                xticklabels=k_values,
                yticklabels=density_percentile_values,
                annot=display_data,  # æ˜¾ç¤ºdisplay_metricçš„æ•°å€¼
                fmt=annot_fmt,
                cmap='viridis',
                cbar_kws={'label': f'{color_metric.upper()} (coloring)'},
                ax=ax)

    # æ ‡æ³¨å‰3åï¼ˆåŸºäºcolor_metricï¼‰
    for rank, (value, i, j) in enumerate(top3, 1):
        ax.plot(j + 0.5, i + 0.5, marker='*', markersize=20,
                color='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                markeredgecolor='white', markeredgewidth=1.5)
        ax.text(j + 0.5, i + 0.2, f'#{rank}',
                ha='center', va='center',
                fontsize=10, fontweight='bold', color='white',
                bbox=dict(boxstyle='round,pad=0.3',
                         facecolor='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                         edgecolor='white', linewidth=1.5, alpha=0.8))

    # è®¾ç½®æ ‡é¢˜
    metric_names = {
        'all_acc': 'All ACC',
        'old_acc': 'Old ACC',
        'new_acc': 'New ACC',
        'labeled_acc': 'Labeled ACC'
    }
    color_name = metric_names.get(color_metric, color_metric.upper())
    display_name = metric_names.get(display_metric, display_metric.upper())

    ax.set_title(f'{display_name} Values (colored by {color_name}) - {superclass_name}\n'
                 f'Parameters: k vs density_percentile (Top 3 by {display_name} marked)',
                 fontsize=14, fontweight='bold')
    ax.set_xlabel('k (Number of Neighbors)', fontsize=12)
    ax.set_ylabel('Density Percentile', fontsize=12)

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    if save_plots:
        current_time = datetime.now()
        filename = f"{display_metric}_colored_by_{color_metric}_{current_time.month}_{current_time.day}_{current_time.hour}_{current_time.minute}.png"
        output_path = os.path.join(superclass_output_dir, filename)
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“ æ··åˆçƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")

    plt.show()

    # è¾“å‡ºå‰3åå‚æ•°ç»„åˆï¼ˆåŸºäºdisplay_metricï¼‰
    print(f"\nğŸ† Top 3 å‚æ•°ç»„åˆ (æŒ‰ {display_name} æ’åº):")
    print("-" * 80)
    for rank, (display_value, i, j) in enumerate(top3, 1):
        k_val = k_values[j]
        dp_val = density_percentile_values[i]
        color_value = color_data[i, j]
        emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰"

        if not np.isnan(color_value):
            print(f"{emoji} #{rank}: k={k_val:<3}, density_percentile={dp_val:<3}, "
                  f"{display_metric}={display_value:.4f}, {color_metric}={color_value:.4f}")
        else:
            print(f"{emoji} #{rank}: k={k_val:<3}, density_percentile={dp_val:<3}, "
                  f"{display_metric}={display_value:.4f}, {color_metric}=N/A")

    # è¿”å›åŸºäºcolor_metricçš„æœ€ä½³å‚æ•°
    best_idx = np.unravel_index(np.nanargmax(color_data), color_data.shape)
    best_dp = density_percentile_values[best_idx[0]]
    best_k = k_values[best_idx[1]]
    best_value = color_data[best_idx]

    return best_k, best_dp, best_value


def create_cluster_quality_heatmaps(results_dict, color_metric='all_acc',
                                    superclass_name='', output_dir=heatmap_output_dir,
                                    save_plots=True):
    """
    åˆ›å»ºä¸‰å¼ èšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼Œç”¨all_accç€è‰²

    ç”Ÿæˆä¸‰å¼ å›¾ï¼š
    1. è´¨é‡åˆ†æ•° (quality_score) - ä»¥all_accç€è‰²
    2. ç°‡é—´åˆ†ç¦»åº¦ (separation_score) - ä»¥all_accç€è‰²
    3. å¯†åº¦æƒ©ç½š (penalty_score) - ä»¥all_accç€è‰²

    Args:
        results_dict: ç½‘æ ¼æœç´¢ç»“æœå­—å…¸
        color_metric: ç”¨äºç€è‰²çš„æŒ‡æ ‡ (é»˜è®¤ 'all_acc')
        superclass_name: è¶…ç±»åç§°
        output_dir: è¾“å‡ºç›®å½•
        save_plots: æ˜¯å¦ä¿å­˜å›¾ç‰‡
    """
    print(f"ğŸ¨ ç”Ÿæˆèšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ - èƒŒæ™¯è‰²æŒ‡æ ‡: {color_metric}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    if save_plots:
        superclass_output_dir = os.path.join(output_dir, superclass_name)
        os.makedirs(superclass_output_dir, exist_ok=True)

    # å®šä¹‰ä¸‰ä¸ªæŒ‡æ ‡ï¼ˆæŒ‡æ ‡å, æ ‡é¢˜, æ˜¯å¦è¶Šå¤§è¶Šå¥½ï¼‰
    metrics_to_plot = [
        ('quality_score', 'Quality Score (Separation - Penalty)', True),   # è¶Šå¤§è¶Šå¥½
        ('separation_score', 'Cluster Separation Score', True),             # è¶Šå¤§è¶Šå¥½
        ('penalty_score', 'Local Density Penalty Score', False)             # è¶Šå°è¶Šå¥½
    ]

    # æå–å‚æ•°å’Œç»“æœ
    k_values = sorted(list(set([k for k, _ in results_dict.keys()])))
    density_percentile_values = sorted(list(set([dp for _, dp in results_dict.keys()])))

    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºä¸€å¼ çƒ­åŠ›å›¾
    for metric_key, metric_title, higher_is_better in metrics_to_plot:
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç”Ÿæˆçƒ­åŠ›å›¾: {metric_title}")
        direction = "higher better" if higher_is_better else "lower better"
        print(f"   æ’åºæ–¹å‘: {direction}")

        # åˆ›å»ºä¸¤ä¸ªæ•°æ®çŸ©é˜µ
        color_data = np.zeros((len(density_percentile_values), len(k_values)))  # ç”¨äºç€è‰²
        display_data = np.zeros((len(density_percentile_values), len(k_values)))  # ç”¨äºæ˜¾ç¤º

        for i, dp in enumerate(density_percentile_values):
            for j, k in enumerate(k_values):
                if (k, dp) in results_dict:
                    # ç€è‰²æ•°æ®ï¼ˆall_accï¼‰
                    color_value = results_dict[(k, dp)].get(color_metric)
                    color_data[i, j] = color_value if color_value is not None else np.nan

                    # æ˜¾ç¤ºæ•°æ®ï¼ˆå½“å‰æŒ‡æ ‡ï¼‰
                    display_value = results_dict[(k, dp)].get(metric_key)
                    display_data[i, j] = display_value if display_value is not None else np.nan
                else:
                    color_data[i, j] = np.nan
                    display_data[i, j] = np.nan

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
        if np.all(np.isnan(display_data)):
            print(f"âš ï¸  {metric_key} æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡æ­¤çƒ­åŠ›å›¾")
            continue

        # æ‰¾åˆ°åŸºäºå½“å‰æŒ‡æ ‡ï¼ˆdisplay_dataï¼‰çš„å‰3åä½ç½®
        valid_data = []
        for i in range(display_data.shape[0]):
            for j in range(display_data.shape[1]):
                if not np.isnan(display_data[i, j]):
                    valid_data.append((display_data[i, j], i, j))

        # æ ¹æ®æŒ‡æ ‡ç‰¹æ€§æ’åºï¼ˆè¶Šå¤§è¶Šå¥½ or è¶Šå°è¶Šå¥½ï¼‰
        valid_data.sort(key=lambda x: x[0], reverse=higher_is_better)
        top3 = valid_data[:3] if len(valid_data) >= 3 else valid_data

        # åˆ›å»ºçƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(14, 9))

        # ç”¨color_metricç€è‰²ï¼Œæ˜¾ç¤ºå½“å‰æŒ‡æ ‡çš„æ•°å€¼
        sns.heatmap(color_data,
                    xticklabels=k_values,
                    yticklabels=density_percentile_values,
                    annot=display_data,  # æ˜¾ç¤ºå½“å‰æŒ‡æ ‡çš„æ•°å€¼
                    fmt='.4f',
                    cmap='viridis',
                    cbar_kws={'label': f'{color_metric.upper()} (coloring)'},
                    ax=ax)

        # æ ‡æ³¨å‰3å
        for rank, (value, i, j) in enumerate(top3, 1):
            ax.plot(j + 0.5, i + 0.5, marker='*', markersize=20,
                    color='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                    markeredgecolor='white', markeredgewidth=1.5)
            ax.text(j + 0.5, i + 0.2, f'#{rank}',
                    ha='center', va='center',
                    fontsize=10, fontweight='bold', color='white',
                    bbox=dict(boxstyle='round,pad=0.3',
                             facecolor='red' if rank == 1 else 'orange' if rank == 2 else 'yellow',
                             edgecolor='white', linewidth=1.5, alpha=0.8))

        # è®¾ç½®æ ‡é¢˜
        direction_label = "highest" if higher_is_better else "lowest"
        ax.set_title(f'{metric_title} (colored by {color_metric.upper()}) - {superclass_name}\n'
                     f'Parameters: k vs density_percentile (Top 3 {direction_label} {metric_key} marked)',
                     fontsize=14, fontweight='bold')
        ax.set_xlabel('k (Number of Neighbors)', fontsize=12)
        ax.set_ylabel('Density Percentile', fontsize=12)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_plots:
            current_time = datetime.now()
            filename = f"{metric_key}_colored_by_{color_metric}_{current_time.month}_{current_time.day}_{current_time.hour}_{current_time.minute}.png"
            output_path = os.path.join(superclass_output_dir, filename)
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ çƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")

        plt.show()

        # è¾“å‡ºå‰3åå‚æ•°ç»„åˆçš„æŒ‡æ ‡å€¼
        direction_desc = f"{direction_label} {metric_key}"
        print(f"\nğŸ† Top 3 å‚æ•°ç»„åˆ (æŒ‰ {direction_desc} æ’åº):")
        print("-" * 80)
        for rank, (metric_value, i, j) in enumerate(top3, 1):
            k_val = k_values[j]
            dp_val = density_percentile_values[i]
            color_value = color_data[i, j]
            emoji = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰"

            if not np.isnan(color_value):
                print(f"{emoji} #{rank}: k={k_val:<3}, dp={dp_val:<3}, "
                      f"{metric_key}={metric_value:.4f}, {color_metric}={color_value:.4f}")
            else:
                print(f"{emoji} #{rank}: k={k_val:<3}, dp={dp_val:<3}, "
                      f"{metric_key}={metric_value:.4f}, {color_metric}=N/A")

    print(f"\nâœ… æ‰€æœ‰èšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾åˆ›å»ºå®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å‚æ•°çƒ­åŠ›å›¾ç»˜åˆ¶å·¥å…·')

    # å¿…è¦å‚æ•°
    parser.add_argument('--superclass_name', type=str, default=None,
                        help='æµ‹è¯•çš„è¶…ç±»åç§°ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œåˆ™è‡ªåŠ¨æ¢æµ‹å¹¶å¤„ç†æ‰€æœ‰è¶…ç±»ï¼‰')
    parser.add_argument('--model_path', type=str, default=None,
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„')

    # æœç´¢å‚æ•°
    parser.add_argument('--k_min', type=int, default=3,
                        help='kå€¼æœ€å°å€¼')
    parser.add_argument('--k_max', type=int, default=21,
                        help='kå€¼æœ€å¤§å€¼')
    parser.add_argument('--dp_min', type=int, default=20,
                        help='å¯†åº¦ç™¾åˆ†ä½æœ€å°å€¼')
    parser.add_argument('--dp_max', type=int, default=100,
                        help='å¯†åº¦ç™¾åˆ†ä½æœ€å¤§å€¼')
    parser.add_argument('--dp_step', type=int, default=5,
                        help='å¯†åº¦ç™¾åˆ†ä½æ­¥é•¿')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--eval_version', type=str, default='v2', choices=['v1', 'v2'],
                        help='è¯„ä¼°ç‰ˆæœ¬')
    parser.add_argument('--merge_clusters', type=str, default='true',
                        help='æ˜¯å¦å¯ç”¨èšç±»åˆå¹¶')
    parser.add_argument('--output_dir', type=str, default=heatmap_output_dir,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--metrics', type=str, nargs='+',
                        default=['l1_loss'],
                        help='è¦ç»˜åˆ¶çš„æŒ‡æ ‡ï¼ˆé»˜è®¤æ˜¾ç¤ºäº¤å‰ç†µæŸå¤±l1_lossï¼‰ã€‚å¯é€‰: all_acc, old_acc, new_acc, l1_loss, labeled_acc, quality_scoreç­‰')
    parser.add_argument('--use_existing_results', type=str, default='true',
                        help='æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å·²æœ‰æœç´¢ç»“æœ')
    parser.add_argument('--quality_metrics', type=str, default='false',
                        help='æ˜¯å¦ç”Ÿæˆè´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆè½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°ï¼‰')
    parser.add_argument('--cluster_quality_heatmaps', type=str, default='false',
                        help='æ˜¯å¦ç”Ÿæˆèšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆquality_scoreã€separation_scoreã€penalty_scoreï¼‰')

    args = parser.parse_args()
    merge_clusters = args.merge_clusters.lower() == 'true'
    use_existing_results = args.use_existing_results.lower() == 'true'
    quality_metrics = args.quality_metrics.lower() == 'true'
    cluster_quality_heatmaps = args.cluster_quality_heatmaps.lower() == 'true'

    # ========== è‡ªåŠ¨æ¢æµ‹è¶…ç±»ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰ ==========
    if args.superclass_name is None:
        print("ğŸ” æœªæŒ‡å®šè¶…ç±»åç§°ï¼Œè‡ªåŠ¨æ¢æµ‹ç½‘æ ¼æœç´¢ç»“æœç›®å½•...")
        search_dir = grid_search_output_dir
        superclass_list = detect_available_superclasses(search_dir)

        if not superclass_list:
            print(f"âŒ æœªåœ¨ {search_dir} ä¸­æ‰¾åˆ°ä»»ä½•è¶…ç±»æœç´¢ç»“æœ")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œç½‘æ ¼æœç´¢æˆ–æ‰‹åŠ¨æŒ‡å®šè¶…ç±»åç§° (--superclass_name)")
            return

        print(f"âœ… å‘ç° {len(superclass_list)} ä¸ªè¶…ç±»: {superclass_list}")
        print("="*80)
    else:
        superclass_list = [args.superclass_name]
        print(f"ğŸ“Š å¤„ç†æŒ‡å®šè¶…ç±»: {args.superclass_name}")
        print("="*80)

    # ========== æ‰¹é‡å¤„ç†æ‰€æœ‰è¶…ç±» ==========
    for idx, superclass_name in enumerate(superclass_list, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ”„ å¤„ç†è¶…ç±» [{idx}/{len(superclass_list)}]: {superclass_name}")
        print(f"{'='*80}")

        print("å‚æ•°çƒ­åŠ›å›¾ç»˜åˆ¶å·¥å…·")
        print("="*80)
        print(f"è¶…ç±»åç§°: {superclass_name}")
        print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
        print(f"kå€¼èŒƒå›´: {args.k_min}-{args.k_max-1}")
        print(f"å¯†åº¦ç™¾åˆ†ä½èŒƒå›´: {args.dp_min}-{args.dp_max-1} (æ­¥é•¿{args.dp_step})")
        print(f"è¯„ä¼°ç‰ˆæœ¬: {args.eval_version}")
        print(f"èšç±»åˆå¹¶: {merge_clusters}")
        print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ç»˜åˆ¶æŒ‡æ ‡: {args.metrics}")
        print(f"è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾: {'å¯ç”¨' if quality_metrics else 'ç¦ç”¨'}")
        print(f"èšç±»è´¨é‡çƒ­åŠ›å›¾: {'å¯ç”¨' if cluster_quality_heatmaps else 'ç¦ç”¨'}")
        print("="*80)

        try:
            results = None

            # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨å·²æœ‰ç»“æœ
            if use_existing_results:
                print("\nğŸ” æ£€æŸ¥æ˜¯å¦å·²æœ‰æœç´¢ç»“æœ...")
                results = load_existing_results(superclass_name)

            if results is None:
                if use_existing_results:
                    print("ğŸ“Š æœªæ‰¾åˆ°å·²æœ‰ç»“æœï¼Œå¼€å§‹æ–°çš„ç½‘æ ¼æœç´¢...")
                else:
                    print("ğŸ“Š å¼ºåˆ¶é‡æ–°è¿è¡Œç½‘æ ¼æœç´¢...")
                # è¿è¡Œç½‘æ ¼æœç´¢
                results = run_parameter_grid_search(
                    superclass_name=superclass_name,
                    model_path=args.model_path,
                    k_range=(args.k_min, args.k_max),
                    density_percentile_range=(args.dp_min, args.dp_max),
                    step=args.dp_step,
                    eval_version=args.eval_version,
                    merge_clusters=merge_clusters
                )
            else:
                print("ğŸ¯ ä½¿ç”¨å·²æœ‰æœç´¢ç»“æœç”Ÿæˆçƒ­åŠ›å›¾ï¼Œé¿å…é‡å¤è®¡ç®—")

            # ç»˜åˆ¶çƒ­åŠ›å›¾
            best_params = create_multiple_heatmaps(
                results_dict=results,
                superclass_name=superclass_name,
                output_dir=args.output_dir,
                metrics=args.metrics,
                save_plots=True
            )

            # å¦‚æœå¯ç”¨è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼Œåˆ™ç”Ÿæˆè½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°çƒ­åŠ›å›¾
            if quality_metrics:
                print(f"\n{'='*80}")
                print("ğŸ¯ ç”Ÿæˆè´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆè½®å»“ç³»æ•°å’ŒDBæŒ‡æ•°ï¼‰...")
                print(f"{'='*80}")
                create_multiple_quality_metrics_heatmaps(
                    results_dict=results,
                    superclass_name=superclass_name,
                    output_dir=args.output_dir,
                    acc_metrics=args.metrics,  # ä½¿ç”¨ç›¸åŒçš„ACCæŒ‡æ ‡åˆ—è¡¨
                    save_plots=True
                )

            # ç”Ÿæˆæ··åˆçƒ­åŠ›å›¾ï¼šä»¥all_accç€è‰²ï¼Œæ˜¾ç¤ºlabeled_accï¼ˆé»˜è®¤è¿è¡Œï¼‰
            print(f"\n{'='*80}")
            print("ğŸ¨ ç”Ÿæˆæ··åˆçƒ­åŠ›å›¾ï¼ˆä»¥all_accç€è‰²ï¼Œæ˜¾ç¤ºlabeled_accï¼‰...")
            print(f"{'='*80}")

            # ç¬¬ä¸€å¼ ï¼šlabeled_accï¼ˆä»¥all_accç€è‰²ï¼‰
            try:
                create_mixed_heatmap(
                    results_dict=results,
                    color_metric='all_acc',
                    display_metric='labeled_acc',
                    superclass_name=superclass_name,
                    output_dir=args.output_dir,
                    save_plots=True
                )
            except Exception as e:
                print(f"âš ï¸  labeled_accæ··åˆçƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")

            # ç¬¬äºŒéƒ¨åˆ†ï¼šèšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆquality_score, separation_score, penalty_scoreï¼‰
            if cluster_quality_heatmaps:
                print(f"\n{'='*80}")
                print("ğŸ¨ ç”Ÿæˆèšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ï¼ˆquality_scoreã€separation_scoreã€penalty_scoreï¼‰...")
                print(f"{'='*80}")

                try:
                    create_cluster_quality_heatmaps(
                        results_dict=results,
                        color_metric='all_acc',
                        superclass_name=superclass_name,
                        output_dir=args.output_dir,
                        save_plots=True
                    )
                except Exception as e:
                    print(f"âš ï¸  èšç±»è´¨é‡æŒ‡æ ‡çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {e}")

            print(f"\nâœ… {superclass_name} çƒ­åŠ›å›¾ç»˜åˆ¶å®Œæˆï¼")
            final_output_dir = os.path.join(args.output_dir, superclass_name)
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {final_output_dir}")

        except Exception as e:
            print(f"âŒ {superclass_name} çƒ­åŠ›å›¾ç»˜åˆ¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè¶…ç±»

    # ========== å…¨éƒ¨å®Œæˆ ==========
    print(f"\n{'='*80}")
    print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼æˆåŠŸå¤„ç† {len(superclass_list)} ä¸ªè¶…ç±»")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    print(f"{'='*80}")


if __name__ == '__main__':
    main()
