#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®é›†åŠ è½½æ¨¡å—
å¤„ç†CIFAR-100è¶…ç±»æ•°æ®é›†çš„åŠ è½½
æ³¨æ„ï¼šæ­¤æ¨¡å—éœ€è¦ä¾èµ–data/ç›®å½•ï¼ˆæ— æ³•å®Œå…¨é¿å…ï¼‰
"""

import os
import sys
from torch.utils.data import DataLoader
from copy import deepcopy

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

try:
    from data.augmentations import get_transform
    from data.get_datasets import get_single_superclass_datasets, MergedDataset
except ImportError:
    print("âš ï¸  è­¦å‘Š: æ— æ³•å¯¼å…¥dataæ¨¡å—")
    print("   æ•°æ®é›†åŠ è½½åŠŸèƒ½éœ€è¦é¡¹ç›®æ ¹ç›®å½•çš„data/ç›®å½•")
    get_transform = None
    get_single_superclass_datasets = None
    MergedDataset = None


class DatasetLoader:
    """
    æ•°æ®é›†åŠ è½½å™¨ç±»
    è´Ÿè´£åŠ è½½CIFAR-100è¶…ç±»æ•°æ®é›†å¹¶åˆ›å»ºDataLoader
    """

    def __init__(self, superclass_name, image_size=224, batch_size=64,
                 num_workers=4, prop_train_labels=0.8, seed=0):
        """
        åˆå§‹åŒ–æ•°æ®é›†åŠ è½½å™¨

        Args:
            superclass_name: è¶…ç±»åç§°
            image_size: å›¾åƒå°ºå¯¸ï¼ˆé»˜è®¤224ï¼‰
            batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤64ï¼‰
            num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°ï¼ˆé»˜è®¤4ï¼‰
            prop_train_labels: è®­ç»ƒé›†ä¸­æœ‰æ ‡ç­¾æ ·æœ¬çš„æ¯”ä¾‹ï¼ˆé»˜è®¤0.8ï¼‰
            seed: éšæœºç§å­ï¼ˆé»˜è®¤0ï¼‰
        """
        self.superclass_name = superclass_name
        self.image_size = image_size
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.prop_train_labels = prop_train_labels
        self.seed = seed

    def load(self, silent=False):
        """
        åŠ è½½æ•°æ®é›†å¹¶åˆ›å»ºDataLoader

        Args:
            silent: æ˜¯å¦é™é»˜æ¨¡å¼

        Returns:
            dict: åŒ…å«æ•°æ®åŠ è½½å™¨çš„å­—å…¸
                - 'train_loader': è®­ç»ƒé›†åŠ è½½å™¨ï¼ˆåˆå¹¶æœ‰æ ‡ç­¾+æ— æ ‡ç­¾ï¼‰
                - 'test_loader': æµ‹è¯•é›†åŠ è½½å™¨
                - 'train_dataset': è®­ç»ƒé›†æ•°æ®é›†
                - 'test_dataset': æµ‹è¯•é›†æ•°æ®é›†

        Raises:
            ImportError: å¦‚æœdataæ¨¡å—ä¸å¯ç”¨
        """
        if get_transform is None or get_single_superclass_datasets is None:
            raise ImportError("dataæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½æ•°æ®é›†")

        if not silent:
            print(f"ğŸ”„ åŠ è½½æ•°æ®é›†: {self.superclass_name}")

        # åˆ›å»ºæ•°æ®è½¬æ¢å‚æ•°ï¼ˆæ¨¡æ‹Ÿargsï¼‰
        class Args:
            def __init__(self, image_size, prop_train_labels, seed):
                self.image_size = image_size
                self.interpolation = 3
                self.crop_pct = 0.875
                self.prop_train_labels = prop_train_labels
                self.seed = seed

        args = Args(self.image_size, self.prop_train_labels, self.seed)

        # è·å–æ•°æ®è½¬æ¢
        train_transform, test_transform = get_transform(
            'imagenet',
            image_size=self.image_size,
            args=args
        )

        # è·å–æ•°æ®é›†
        datasets = get_single_superclass_datasets(
            superclass_name=self.superclass_name,
            train_transform=train_transform,
            test_transform=test_transform,
            prop_train_labels=self.prop_train_labels,
            split_train_val=False,
            seed=self.seed
        )

        # åˆ›å»ºè®­ç»ƒé›†ï¼ˆåˆå¹¶æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾ï¼‰
        train_labelled = datasets['train_labelled']
        train_unlabelled = datasets['train_unlabelled']
        test_dataset = datasets['test']

        merged_train_dataset = MergedDataset(
            labelled_dataset=deepcopy(train_labelled),
            unlabelled_dataset=deepcopy(train_unlabelled)
        )

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            merged_train_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers
        )

        test_loader = DataLoader(
            test_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers
        )

        if not silent:
            print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
            print(f"   è®­ç»ƒé›†: {len(merged_train_dataset)} æ ·æœ¬")
            print(f"   æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")

        return {
            'train_loader': train_loader,
            'test_loader': test_loader,
            'train_dataset': merged_train_dataset,
            'test_dataset': test_dataset
        }
