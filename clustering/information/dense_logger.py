#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éª¨å¹²ç½‘ç»œèšç±»è¯¦ç»†æ—¥å¿—è®°å½•å™¨
ç”¨äºè®°å½•é«˜å¯†åº¦ç‚¹èšç±»è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯
"""

import os
from datetime import datetime
import numpy as np

from config import clustering_log_dir


class DenseNetworkLogger:
    """
    éª¨å¹²ç½‘ç»œèšç±»è¯¦ç»†æ—¥å¿—è®°å½•å™¨

    è®°å½•å†…å®¹åŒ…æ‹¬ï¼š
    - ç‚¹åºå·ã€å¯†åº¦å€¼ã€ç›¸å¯¹coå€¼
    - å·²çŸ¥/æœªçŸ¥çŠ¶æ€ã€æ˜¯å¦æœ‰æ ‡ç­¾
    - æ¥è‡ªè®­ç»ƒé›†/æµ‹è¯•é›†
    - è¢«åˆ†é…åˆ°å“ªä¸ªç°‡/åˆ›å»ºäº†å“ªä¸ªç°‡
    - é‚»å±…ä¿¡æ¯
    - èšç±»åŠ¨ä½œï¼ˆæ‰©å±•/åˆå¹¶/ç§»åŠ¨/æ‹’ç»/è·³è¿‡ï¼‰
    """

    def __init__(self, log_dir=None, enabled=True):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨

        Args:
            log_dir: æ—¥å¿—æ–‡ä»¶ä¿å­˜ç›®å½•
            enabled: æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•ï¼ˆdetail_denseå‚æ•°ï¼‰
        """
        self.enabled = enabled
        self.log_dir = log_dir or clustering_log_dir
        self.records = []

        if self.enabled:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            os.makedirs(log_dir, exist_ok=True)

    def set_metadata(self, dataset_name, total_points, n_high_density,
                     train_size, test_size, co_mode, co_value):
        """
        è®¾ç½®èšç±»å…ƒæ•°æ®

        Args:
            dataset_name: æ•°æ®é›†åç§°
            total_points: æ€»æ ·æœ¬æ•°
            n_high_density: é«˜å¯†åº¦ç‚¹æ•°é‡
            train_size: è®­ç»ƒé›†æ ·æœ¬æ•°ï¼ˆåŸå§‹åˆ’åˆ†ï¼‰
            test_size: æµ‹è¯•é›†æ ·æœ¬æ•°ï¼ˆåŸå§‹åˆ’åˆ†ï¼‰
            co_mode: coè®¡ç®—æ¨¡å¼
            co_value: coå€¼ï¼ˆå¯èƒ½æ˜¯æ ‡é‡æˆ–æ•°ç»„ï¼‰
        """
        if not self.enabled:
            return

        self.metadata = {
            'dataset_name': dataset_name,
            'total_points': total_points,
            'n_high_density': n_high_density,
            'train_size': train_size,
            'test_size': test_size,
            'co_mode': co_mode,
            'co_value': co_value,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

    def update_dataset_name(self, dataset_name):
        """
        æ›´æ–°æ•°æ®é›†åç§°ï¼ˆåœ¨å·²è®¾ç½®å…ƒæ•°æ®åï¼‰

        Args:
            dataset_name: æ–°çš„æ•°æ®é›†åç§°
        """
        if not self.enabled:
            return

        if hasattr(self, 'metadata') and self.metadata is not None:
            self.metadata['dataset_name'] = dataset_name

    def log_point(self, point_idx, density, co_value,
                  is_known, has_label, is_from_train, true_label,
                  action, cluster_id, neighbors_info, cluster_status=None):
        """
        è®°å½•å•ä¸ªé«˜å¯†åº¦ç‚¹çš„èšç±»ä¿¡æ¯

        Args:
            point_idx: ç‚¹åœ¨å…¨å±€æ•°æ®é›†ä¸­çš„ç´¢å¼•
            density: å¯†åº¦å€¼
            co_value: è¯¥ç‚¹çš„ç›¸å¯¹coå€¼ï¼ˆå¦‚æœæ˜¯æ•°ç»„coï¼Œå–è¯¥ç‚¹çš„å€¼ï¼‰
            is_known: æ˜¯å¦ä¸ºå·²çŸ¥ç±»
            has_label: æ˜¯å¦æœ‰æ ‡ç­¾
            is_from_train: æ˜¯å¦æ¥è‡ªåŸå§‹è®­ç»ƒé›†
            true_label: å½“å‰ç‚¹çš„çœŸå®æ ‡ç­¾ï¼ˆç”¨äºä¸Šå¸è§†è§’åˆ†æï¼‰
            action: èšç±»åŠ¨ä½œï¼ˆ'create', 'expand', 'merge', 'move', 'reject', 'skip'ï¼‰
            cluster_id: æ‰€å±/åˆ›å»ºçš„ç°‡IDï¼ˆå¯èƒ½æ˜¯å•ä¸ªIDæˆ–åˆ—è¡¨ï¼‰
            neighbors_info: é‚»å±…ä¿¡æ¯å­—å…¸
                {
                    'n_neighbors': int,
                    'neighbor_indices': list,
                    'neighbor_clusters': list,  # é‚»å±…æ‰€å±çš„ç°‡ID
                    'neighbor_densities': list,
                    'neighbor_true_labels': list,  # é‚»å±…çš„çœŸå®æ ‡ç­¾
                    'neighbor_distances': list  # é‚»å±…ä¸å½“å‰ç‚¹çš„è·ç¦»
                }
            cluster_status: å½“å‰ç°‡çŠ¶æ€ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                {
                    cluster_id: {'size': int, 'label': int or None}
                }
        """
        if not self.enabled:
            return

        record = {
            'point_idx': point_idx,
            'density': density,
            'co_value': co_value,
            'is_known': is_known,
            'has_label': has_label,
            'is_from_train': is_from_train,
            'true_label': true_label,
            'action': action,
            'cluster_id': cluster_id,
            'neighbors_info': neighbors_info,
            'cluster_status': cluster_status
        }

        self.records.append(record)

    def _format_cluster_id(self, cluster_id):
        """æ ¼å¼åŒ–ç°‡IDï¼ˆå¯èƒ½æ˜¯å•ä¸ªå€¼æˆ–åˆ—è¡¨ï¼‰"""
        if isinstance(cluster_id, (list, tuple)):
            return f"[{', '.join(map(str, cluster_id))}]"
        elif cluster_id is None:
            return "None"
        else:
            return str(cluster_id)

    def _format_action_description(self, action, cluster_id):
        """æ ¼å¼åŒ–åŠ¨ä½œæè¿°"""
        action_map = {
            'create': f"åˆ›å»ºæ–°ç°‡ {self._format_cluster_id(cluster_id)}",
            'expand': f"åŠ å…¥ç°‡ {self._format_cluster_id(cluster_id)}ï¼ˆæ‰©å±•ï¼‰",
            'merge': f"åˆå¹¶ç°‡ {self._format_cluster_id(cluster_id)}",
            'move': f"ç§»åŠ¨åˆ°ç°‡ {self._format_cluster_id(cluster_id)}",
            'reject': "è¢«æ‹’ç»ï¼ˆå†²çªæœªè§£å†³ï¼‰",
            'skip': "è·³è¿‡ï¼ˆå·²åˆ†é…ï¼‰"
        }
        return action_map.get(action, f"æœªçŸ¥åŠ¨ä½œ: {action}")

    def write_log(self, filename=None):
        """
        å°†æ—¥å¿—å†™å…¥æ–‡ä»¶

        Args:
            filename: æ—¥å¿—æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        if not self.enabled:
            return None

        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            dataset = self.metadata.get('dataset_name', 'unknown')
            filename = f"dense_network_{dataset}_{timestamp}.txt"

        log_path = os.path.join(self.log_dir, filename)

        with open(log_path, 'w', encoding='utf-8') as f:
            # å†™å…¥å¤´éƒ¨ä¿¡æ¯
            f.write("=" * 100 + "\n")
            f.write("éª¨å¹²ç½‘ç»œèšç±»è¯¦ç»†æ—¥å¿—\n")
            f.write("=" * 100 + "\n\n")

            # å†™å…¥å…ƒæ•°æ®
            f.write("ã€èšç±»å…ƒæ•°æ®ã€‘\n")
            f.write(f"æ•°æ®é›†åç§°: {self.metadata.get('dataset_name', 'N/A')}\n")
            f.write(f"æ€»æ ·æœ¬æ•°: {self.metadata.get('total_points', 'N/A')}\n")
            f.write(f"é«˜å¯†åº¦ç‚¹æ•°é‡: {self.metadata.get('n_high_density', 'N/A')}\n")
            f.write(f"åŸå§‹è®­ç»ƒé›†æ ·æœ¬æ•°: {self.metadata.get('train_size', 'N/A')}\n")
            f.write(f"åŸå§‹æµ‹è¯•é›†æ ·æœ¬æ•°: {self.metadata.get('test_size', 'N/A')}\n")
            f.write(f"Coæ¨¡å¼: {self.metadata.get('co_mode', 'N/A')}\n")

            co_val = self.metadata.get('co_value', 'N/A')
            if isinstance(co_val, np.ndarray):
                f.write(f"Coå€¼: æ•°ç»„ï¼ˆæ¯ä¸ªç‚¹ä¸åŒï¼‰\n")
            else:
                f.write(f"Coå€¼: {co_val}\n")

            f.write(f"è®°å½•æ—¶é—´: {self.metadata.get('timestamp', 'N/A')}\n")
            f.write("\n" + "=" * 100 + "\n\n")

            # å†™å…¥æ¯ä¸ªç‚¹çš„è®°å½•
            f.write("ã€é«˜å¯†åº¦ç‚¹èšç±»è¿‡ç¨‹ã€‘\n\n")

            for i, record in enumerate(self.records):
                f.write(f"{'â”€' * 100}\n")
                f.write(f"å¤„ç†é¡ºåº: #{i+1}\n")
                f.write(f"ç‚¹åºå·: {record['point_idx']}\n")
                f.write(f"å¯†åº¦å€¼: {record['density']:.6f}\n")
                f.write(f"ç›¸å¯¹Coå€¼: {record['co_value']:.6f}\n")

                # æ ·æœ¬çŠ¶æ€
                f.write(f"å·²çŸ¥/æœªçŸ¥: {'å·²çŸ¥ç±»' if record['is_known'] else 'æœªçŸ¥ç±»'}\n")
                f.write(f"æ˜¯å¦æœ‰æ ‡ç­¾: {'æ˜¯' if record['has_label'] else 'å¦'}\n")
                f.write(f"æ¥æº: {'åŸå§‹è®­ç»ƒé›†' if record['is_from_train'] else 'åŸå§‹æµ‹è¯•é›†'}\n")
                f.write(f"çœŸå®æ ‡ç­¾: {record['true_label']}\n")

                # èšç±»åŠ¨ä½œ
                f.write(f"èšç±»åŠ¨ä½œ: {self._format_action_description(record['action'], record['cluster_id'])}\n")

                # å½“å‰ç°‡çŠ¶æ€
                cluster_status = record.get('cluster_status')
                if cluster_status is not None and len(cluster_status) > 0:
                    f.write(f"\nå½“å‰ç°‡çŠ¶æ€:\n")
                    # æŒ‰ç°‡IDæ’åº
                    sorted_clusters = sorted(cluster_status.items(), key=lambda x: x[0])
                    status_parts = []
                    for cid, info in sorted_clusters:
                        size = info.get('size', 0)
                        label = info.get('label')
                        if label is not None:
                            status_parts.append(f"ç°‡{cid}:{size}(æ ‡ç­¾:{label})")
                        else:
                            status_parts.append(f"ç°‡{cid}:{size}(æ— æ ‡ç­¾)")
                    f.write(f"  {' '.join(status_parts)}\n")

                # é‚»å±…ä¿¡æ¯
                neighbors = record['neighbors_info']
                f.write(f"\né‚»å±…ä¿¡æ¯:\n")
                f.write(f"  é‚»å±…æ•°é‡: {neighbors.get('n_neighbors', 0)}\n")

                if neighbors.get('n_neighbors', 0) > 0:
                    neighbor_indices = neighbors.get('neighbor_indices', [])
                    neighbor_clusters = neighbors.get('neighbor_clusters', [])
                    neighbor_densities = neighbors.get('neighbor_densities', [])
                    neighbor_true_labels = neighbors.get('neighbor_true_labels', [])
                    neighbor_distances = neighbors.get('neighbor_distances', [])

                    f.write(f"  é‚»å±…è¯¦æƒ…:\n")
                    for j, (nb_idx, nb_cluster, nb_density, nb_label, nb_dist) in enumerate(
                        zip(neighbor_indices, neighbor_clusters, neighbor_densities,
                            neighbor_true_labels, neighbor_distances), 1):
                        cluster_str = self._format_cluster_id(nb_cluster)
                        f.write(f"    #{j}: ç‚¹{nb_idx}, ç°‡{cluster_str}, å¯†åº¦{nb_density:.6f}, çœŸå®æ ‡ç­¾{nb_label}, è·ç¦»{nb_dist:.6f}\n")

                f.write("\n")

            # å†™å…¥å°¾éƒ¨
            f.write("=" * 100 + "\n")
            f.write(f"æ—¥å¿—è®°å½•å®Œæˆï¼Œå…±è®°å½• {len(self.records)} ä¸ªé«˜å¯†åº¦ç‚¹çš„èšç±»è¿‡ç¨‹\n")
            f.write("=" * 100 + "\n")

        print(f"\nğŸ“ éª¨å¹²ç½‘ç»œèšç±»æ—¥å¿—å·²ä¿å­˜è‡³: {log_path}")
        return log_path

    def clear(self):
        """æ¸…ç©ºè®°å½•"""
        self.records = []


# å…¨å±€æ—¥å¿—å®ä¾‹ï¼ˆç”¨äºç®€åŒ–è°ƒç”¨ï¼‰
_global_logger = None


def get_logger():
    """è·å–å…¨å±€æ—¥å¿—å®ä¾‹"""
    global _global_logger
    if _global_logger is None:
        _global_logger = DenseNetworkLogger(enabled=False)
    return _global_logger


def init_logger(log_dir=None, enabled=True):
    """
    åˆå§‹åŒ–å…¨å±€æ—¥å¿—å®ä¾‹

    Args:
        log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
        enabled: æ˜¯å¦å¯ç”¨ï¼ˆç”±detail_denseå‚æ•°æ§åˆ¶ï¼‰

    Returns:
        logger: DenseNetworkLoggerå®ä¾‹
    """
    global _global_logger
    _global_logger = DenseNetworkLogger(log_dir=log_dir, enabled=enabled)
    return _global_logger


def reset_logger():
    """é‡ç½®å…¨å±€æ—¥å¿—å®ä¾‹"""
    global _global_logger
    _global_logger = None
