#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
èšç±»æŸå¤±å‡½æ•°è®¡ç®—æ¨¡å—
ç”¨äºè®¡ç®—ç›‘ç£æŸå¤±L1å’Œæ— ç›‘ç£æŸå¤±L2ï¼Œä»¥åŠç»¼åˆæŸå¤±L
"""

import warnings
from typing import Dict, List, Optional

import numpy as np
from sklearn.metrics import accuracy_score

from .l2_strategies import L2_REGISTRY, available_l2_components


def compute_supervised_loss_l1(predictions, targets, labeled_mask, cluster_category_labels=None, loss_type='accuracy'):
    """
    è®¡ç®—ç›‘ç£æŸå¤±L1

    Args:
        predictions: èšç±»é¢„æµ‹æ ‡ç­¾ (n_samples,)
        targets: çœŸå®æ ‡ç­¾ (n_samples,)
        labeled_mask: æœ‰æ ‡ç­¾æ ·æœ¬çš„æ©ç  (n_samples,)
        cluster_category_labels: ç°‡IDåˆ°ç±»åˆ«æ ‡ç­¾çš„æ˜ å°„å­—å…¸ {cluster_id: category_label}ï¼ˆå¯é€‰ï¼‰
                                å¦‚æœæä¾›ï¼Œåˆ™å°†ç°‡IDè½¬æ¢ä¸ºç°‡ç±»åˆ«æ ‡ç­¾åå†è®¡ç®—ACC
        loss_type: æŸå¤±ç±»å‹ï¼Œå¯é€‰'accuracy'(å‡†ç¡®ç‡)æˆ–'cross_entropy'(äº¤å‰ç†µ)

    Returns:
        l1: ç›‘ç£æŸå¤±ï¼ŒèŒƒå›´[0, 1]
        metrics: è¯¦ç»†æŒ‡æ ‡å­—å…¸
    """
    # ç›´æ¥ä½¿ç”¨ç°‡IDè¿›è¡Œè®¡ç®—ï¼ˆä¸è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾ï¼‰
    predictions_for_acc = predictions

    # åªè€ƒè™‘æœ‰æ ‡ç­¾çš„æ ·æœ¬
    labeled_predictions = predictions_for_acc[labeled_mask]
    labeled_targets = targets[labeled_mask]

    n_labeled = len(labeled_predictions)

    if n_labeled == 0:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æœ‰æ ‡ç­¾æ ·æœ¬ï¼Œæ— æ³•è®¡ç®—ç›‘ç£æŸå¤±")
        return 0.0, {'n_labeled': 0, 'accuracy': 0.0}

    if loss_type == 'accuracy':
        # ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºç›‘ç£æŸå¤±
        # éœ€è¦å°†èšç±»æ ‡ç­¾æ˜ å°„åˆ°çœŸå®æ ‡ç­¾
        from scipy.optimize import linear_sum_assignment

        # è·å–èšç±»æ ‡ç­¾å’ŒçœŸå®æ ‡ç­¾çš„uniqueå€¼
        unique_clusters = np.unique(labeled_predictions)
        unique_targets = np.unique(labeled_targets)

        # æ„å»ºæ··æ·†çŸ©é˜µ
        n_clusters = len(unique_clusters)
        n_classes = len(unique_targets)
        confusion_matrix = np.zeros((n_clusters, n_classes))

        for i, cluster_id in enumerate(unique_clusters):
            cluster_mask = (labeled_predictions == cluster_id)
            for j, true_label in enumerate(unique_targets):
                confusion_matrix[i, j] = np.sum(labeled_targets[cluster_mask] == true_label)

        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•æ‰¾åˆ°æœ€ä¼˜åŒ¹é…
        row_ind, col_ind = linear_sum_assignment(confusion_matrix, maximize=True)

        # è®¡ç®—æœ€ä¼˜åŒ¹é…ä¸‹çš„å‡†ç¡®æ ·æœ¬æ•°
        correct_samples = confusion_matrix[row_ind, col_ind].sum()
        accuracy = correct_samples / n_labeled

        # æŸå¤±å®šä¹‰ä¸º 1 - accuracyï¼ˆæŸå¤±è¶Šå°è¶Šå¥½ï¼‰
        l1 = 1.0 - accuracy

        metrics = {
            'n_labeled': n_labeled,
            'accuracy': accuracy,
            'correct_samples': int(correct_samples)
        }

    elif loss_type == 'cross_entropy':
        # æ–¹æ¡ˆ2: åŸºäºç°‡å†…ç±»åˆ«åˆ†å¸ƒçš„äº¤å‰ç†µæŸå¤±
        # åªä½¿ç”¨æœ‰æ ‡ç­¾æ ·æœ¬ï¼Œéµç…§accuracyæ–¹æ³•çš„ç°‡IDå¤„ç†æ–¹å¼

        # è·å–æ‰€æœ‰ç°‡IDå’Œç±»åˆ«
        unique_clusters = np.unique(labeled_predictions)
        unique_targets = np.unique(labeled_targets)
        n_classes = len(unique_targets)

        # ä¸ºäº†å¤„ç†ç±»åˆ«æ ‡ç­¾ä¸è¿ç»­çš„æƒ…å†µï¼ˆå¦‚0,2,5ï¼‰ï¼Œåˆ›å»ºæ˜ å°„
        target_to_idx = {label: idx for idx, label in enumerate(unique_targets)}

        # æ­¥éª¤1: è®¡ç®—æ¯ä¸ªç°‡çš„ç±»åˆ«åˆ†å¸ƒæ¦‚ç‡
        cluster_class_probs = {}

        for cluster_id in unique_clusters:
            # æ‰¾åˆ°å½“å‰ç°‡çš„æ‰€æœ‰æœ‰æ ‡ç­¾æ ·æœ¬
            cluster_mask = (labeled_predictions == cluster_id)
            cluster_targets = labeled_targets[cluster_mask]

            if len(cluster_targets) > 0:
                # è®¡ç®—ç±»åˆ«è®¡æ•°
                class_counts = np.zeros(n_classes)
                for target in cluster_targets:
                    class_counts[target_to_idx[target]] += 1

                # å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ
                cluster_class_probs[cluster_id] = class_counts / len(cluster_targets)
            else:
                # å¦‚æœç°‡å†…æ²¡æœ‰æœ‰æ ‡ç­¾æ ·æœ¬ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ
                cluster_class_probs[cluster_id] = np.ones(n_classes) / n_classes

        # æ­¥éª¤2: è®¡ç®—äº¤å‰ç†µæŸå¤±
        epsilon = 1e-10  # é¿å…log(0)
        cross_entropy_sum = 0.0

        for pred_cluster, true_label in zip(labeled_predictions, labeled_targets):
            # è·å–è¯¥æ ·æœ¬æ‰€åœ¨ç°‡çš„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ
            prob_dist = cluster_class_probs[pred_cluster]

            # çœŸå®æ ‡ç­¾å¯¹åº”çš„æ¦‚ç‡
            true_label_idx = target_to_idx[true_label]
            true_label_prob = prob_dist[true_label_idx]

            # ç´¯åŠ äº¤å‰ç†µï¼š-log(p(true_label))
            cross_entropy_sum += -np.log(true_label_prob + epsilon)

        # å¹³å‡äº¤å‰ç†µä½œä¸ºæŸå¤±
        l1 = cross_entropy_sum / n_labeled

        # ä¸ºäº†ä¾¿äºæ¯”è¾ƒï¼Œé¢å¤–è®¡ç®—ä¸€ä¸ªç­‰æ•ˆçš„å‡†ç¡®ç‡ï¼ˆéå¿…éœ€ï¼Œä»…ä¾›å‚è€ƒï¼‰
        # åŸºäºç°‡ç±»åˆ«åˆ†å¸ƒçš„é¢„æµ‹ï¼šé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«
        correct_samples = 0
        for pred_cluster, true_label in zip(labeled_predictions, labeled_targets):
            prob_dist = cluster_class_probs[pred_cluster]
            predicted_label_idx = np.argmax(prob_dist)
            predicted_label = unique_targets[predicted_label_idx]
            if predicted_label == true_label:
                correct_samples += 1

        equiv_accuracy = correct_samples / n_labeled

        metrics = {
            'n_labeled': n_labeled,
            'cross_entropy': l1,
            'equiv_accuracy': equiv_accuracy,  # åŸºäºç°‡åˆ†å¸ƒé¢„æµ‹çš„ç­‰æ•ˆå‡†ç¡®ç‡
            'correct_samples': int(correct_samples)
        }

    else:
        raise ValueError(f"æœªçŸ¥çš„loss_type: {loss_type}ï¼Œæ”¯æŒ'accuracy'æˆ–'cross_entropy'")

    return l1, metrics


def compute_l2_loss(*,
                    X,
                    predictions,
                    targets,
                    labeled_mask,
                    clusters,
                    k: int,
                    cluster_distance_method: str = 'prototype',
                    neighbors=None,
                    l2_components: Optional[List[str]] = None,
                    l2_component_weights: Optional[Dict[str, float]] = None,
                    l2_component_params: Optional[Dict[str, dict]] = None):
    """
    æŒ‰ç…§ç»„ä»¶é…ç½®è®¡ç®— L2ï¼ˆæ— ç›‘ç£æŸå¤±ï¼‰
    """
    if not l2_components:
        return 0.0, {
            'total_l2': 0.0,
            'components': {},
            'component_order': [],
            'component_weights': {}
        }

    component_weights = dict(l2_component_weights or {})
    component_params = dict(l2_component_params or {})

    components_summary: Dict[str, Dict[str, object]] = {}
    total_l2 = 0.0

    for name in l2_components:
        entry = L2_REGISTRY.get(name)
        if entry is None:
            available = ", ".join(sorted(available_l2_components().keys()))
            raise ValueError(f"æœªçŸ¥çš„ L2 ç»„ä»¶ '{name}'ï¼Œå¯é€‰ç»„ä»¶: {available}")

        fn = entry['fn']
        orientation = entry.get('orientation', 'minimize')
        params = component_params.get(name, {})

        value, metrics = fn(
            clusters=clusters,
            X=X,
            predictions=predictions,
            targets=targets,
            labeled_mask=labeled_mask,
            k=k,
            cluster_distance_method=cluster_distance_method,
            neighbors=neighbors,
            **params
        )

        weight = float(component_weights.get(name, 1.0))

        if orientation == 'maximize':
            contribution = weight * value
        elif orientation == 'minimize':
            contribution = -weight * value
        else:
            contribution = weight * value

        components_summary[name] = {
            'value': value,
            'weight': weight,
            'orientation': orientation,
            'contribution': contribution,
            'metrics': metrics
        }
        total_l2 += contribution

    summary = {
        'total_l2': total_l2,
        'components': components_summary,
        'component_order': list(l2_components),
        'component_weights': {name: components_summary[name]['weight'] for name in l2_components}
    }

    unused_weights = {k: v for k, v in component_weights.items() if k not in components_summary}
    if unused_weights:
        summary['unused_weights'] = unused_weights

    return total_l2, summary


def compute_total_loss(X, predictions, targets, labeled_mask,
                       cluster_category_labels=None,
                       l1_weight=1.0, l2_weight=1.0,
                       l1_type='accuracy', l2_type=None,
                       use_cluster_quality=False,
                       clusters=None,
                       k=10,
                       cluster_distance_method='prototype',
                       neighbors=None,
                       separation_weight=1.0,
                       penalty_weight=1.0,
                       silent=False,
                       l2_components: Optional[List[str]] = None,
                       l2_component_weights: Optional[Dict[str, float]] = None,
                       l2_component_params: Optional[Dict[str, dict]] = None):
    """
    è®¡ç®—ç»¼åˆæŸå¤±L = l1_weight * L1 + l2_weight * L2

    Args:
        X: ç‰¹å¾çŸ©é˜µ (n_samples, n_features)
        predictions: èšç±»é¢„æµ‹æ ‡ç­¾ (n_samples,)
        targets: çœŸå®æ ‡ç­¾ (n_samples,)
        labeled_mask: æœ‰æ ‡ç­¾æ ·æœ¬çš„æ©ç  (n_samples,)
        cluster_category_labels: ç°‡IDåˆ°ç±»åˆ«æ ‡ç­¾çš„æ˜ å°„å­—å…¸ï¼ˆå¯é€‰ï¼‰
        l1_weight: L1æƒé‡ï¼Œé»˜è®¤1.0
        l2_weight: L2æƒé‡ï¼Œé»˜è®¤1.0
        l1_type: L1æŸå¤±ç±»å‹ï¼Œé»˜è®¤'accuracy'
        l2_type: L2æŸå¤±ç±»å‹ [å·²åºŸå¼ƒ]
        use_cluster_quality: æ˜¯å¦å¯ç”¨æ—§ç‰ˆèšç±»è´¨é‡è¯„ä¼°ï¼ˆå·²åºŸå¼ƒï¼‰
        clusters: æ ¸å¿ƒç°‡åˆ—è¡¨
        k: è¿‘é‚»æ•°é‡
        cluster_distance_method: ç°‡è·ç¦»è®¡ç®—æ–¹æ³•
        neighbors: é¢„è®¡ç®—çš„è¿‘é‚»ç´¢å¼•
        separation_weight: é»˜è®¤åˆ†ç¦»åº¦æƒé‡
        penalty_weight: é»˜è®¤å¯†åº¦æƒ©ç½šæƒé‡
        silent: æ˜¯å¦é™é»˜æ¨¡å¼
        l2_components: L2 ç»„ä»¶åˆ—è¡¨
        l2_component_weights: ç»„ä»¶æƒé‡æ˜ å°„
        l2_component_params: ç»„ä»¶é™„åŠ å‚æ•°æ˜ å°„

    Returns:
        loss_dict: åŒ…å«æ‰€æœ‰æŸå¤±ä¿¡æ¯çš„å­—å…¸
    """
    if l2_type:
        warnings.warn("å‚æ•° l2_type å·²åºŸå¼ƒï¼Œè¯·æ”¹ç”¨ l2_components", DeprecationWarning)

    l1, l1_metrics = compute_supervised_loss_l1(
        predictions, targets, labeled_mask,
        cluster_category_labels=cluster_category_labels,
        loss_type=l1_type
    )

    explicit_components = l2_components is not None
    resolved_components = l2_components

    if resolved_components is None:
        if use_cluster_quality:
            warnings.warn("use_cluster_quality å°†åœ¨æœªæ¥ç§»é™¤ï¼Œè¯·æ˜¾å¼è®¾ç½® l2_components=['separation', 'penalty']",
                          DeprecationWarning)
            resolved_components = ['separation', 'penalty']
        else:
            resolved_components = []
    else:
        if isinstance(resolved_components, str):
            resolved_components = [comp.strip() for comp in resolved_components.split(',') if comp.strip()]
        else:
            resolved_components = list(resolved_components)
        if use_cluster_quality:
            warnings.warn("æ£€æµ‹åˆ° use_cluster_quality ä¸ l2_components åŒæ—¶è®¾ç½®ï¼Œå°†ä¼˜å…ˆä½¿ç”¨ l2_components",
                          RuntimeWarning)

    component_weights = {}
    if l2_component_weights:
        component_weights = {str(k): float(v) for k, v in l2_component_weights.items()}

    if 'separation' in resolved_components and 'separation' not in component_weights:
        component_weights['separation'] = separation_weight
    if 'penalty' in resolved_components and 'penalty' not in component_weights:
        component_weights['penalty'] = penalty_weight
    for name in resolved_components:
        component_weights.setdefault(name, 1.0)

    component_params = {str(k): dict(v) for k, v in (l2_component_params or {}).items()}

    if 'separation' in resolved_components and clusters is None:
        raise ValueError("å¯ç”¨ separation ç»„ä»¶æ—¶å¿…é¡»æä¾› clusters å‚æ•°")

    l2 = None
    l2_metrics: Dict[str, object] = {}

    if resolved_components:
        l2_value, l2_summary = compute_l2_loss(
            X=X,
            predictions=predictions,
            targets=targets,
            labeled_mask=labeled_mask,
            clusters=clusters,
            k=k,
            cluster_distance_method=cluster_distance_method,
            neighbors=neighbors,
            l2_components=resolved_components,
            l2_component_weights=component_weights,
            l2_component_params=component_params
        )

        l2 = l2_value
        l2_metrics = {
            'method': '+'.join(resolved_components),
            'components': l2_summary.get('components', {}),
            'component_order': l2_summary.get('component_order', []),
            'component_weights': l2_summary.get('component_weights', {}),
            'quality_score': l2_value,
            'total_l2': l2_value
        }
        if 'unused_weights' in l2_summary:
            l2_metrics['unused_weights'] = l2_summary['unused_weights']

        if {'separation', 'penalty'}.issubset(set(resolved_components)):
            sep_entry = l2_summary['components'].get('separation', {})
            pen_entry = l2_summary['components'].get('penalty', {})
            cluster_quality_metrics = {
                'quality_score': l2_value,
                'separation_score': sep_entry.get('value'),
                'penalty_score': pen_entry.get('value'),
                'separation_weight': sep_entry.get('weight'),
                'penalty_weight': pen_entry.get('weight'),
                'weighted_separation': (
                    sep_entry.get('weight', 0.0) * sep_entry.get('value', 0.0) if sep_entry else None
                ),
                'weighted_penalty': (
                    pen_entry.get('weight', 0.0) * pen_entry.get('value', 0.0) if pen_entry else None
                ),
                'separation_metrics': sep_entry.get('metrics'),
                'penalty_metrics': pen_entry.get('metrics')
            }
            l2_metrics['cluster_quality'] = cluster_quality_metrics
    elif explicit_components:
        l2 = 0.0
        l2_metrics = {
            'method': 'none',
            'components': {},
            'component_order': [],
            'component_weights': {},
            'quality_score': 0.0,
            'total_l2': 0.0
        }

    if l2 is not None:
        total_loss = l1_weight * l1 + l2_weight * l2
    else:
        total_loss = l1

    loss_dict = {
        'total_loss': total_loss,
        'l1': l1,
        'l2': l2,
        'l1_weight': l1_weight,
        'l2_weight': l2_weight,
        'l1_metrics': l1_metrics,
        'l2_metrics': l2_metrics,
        'l2_components': resolved_components,
        'l2_component_weights': component_weights,
        'l2_component_params': component_params
    }

    if not silent:
        print(f"\n{'=' * 80}")
        print("ğŸ“‰ æŸå¤±å‡½æ•°è®¡ç®—")
        print(f"{'=' * 80}")
        print("L1 (ç›‘ç£æŸå¤±):")
        print(f"   ç±»å‹: {l1_type}")
        print(f"   æœ‰æ ‡ç­¾æ ·æœ¬æ•°: {l1_metrics.get('n_labeled', 0)}")
        if 'accuracy' in l1_metrics:
            print(f"   æ ‡ç­¾å‡†ç¡®ç‡: {l1_metrics['accuracy']:.4f}")
        elif 'cross_entropy' in l1_metrics:
            print(f"   äº¤å‰ç†µ: {l1_metrics['cross_entropy']:.4f}")
            print(f"   ç­‰æ•ˆå‡†ç¡®ç‡: {l1_metrics['equiv_accuracy']:.4f}")
        print(f"   L1æŸå¤±å€¼: {l1:.4f}")

        if l2 is not None:
            print("\nL2 (æ— ç›‘ç£æŸå¤±):")
            for comp in l2_metrics.get('component_order', []):
                entry = l2_metrics['components'].get(comp, {})
                orientation = entry.get('orientation')
                value = entry.get('value')
                weight = entry.get('weight')
                contribution = entry.get('contribution')
                if value is not None:
                    print(f"   ç»„ä»¶[{comp}] (æ–¹å‘: {orientation}) -> å€¼={value:.4f}, æƒé‡={weight:.3f}, è´¡çŒ®={contribution:.4f}")
            if 'cluster_quality' in l2_metrics:
                cq = l2_metrics['cluster_quality']
                print(f"   ç°‡é—´åˆ†ç¦»åº¦: {cq.get('separation_score', 0.0):.4f}")
                print(f"   å¯†åº¦æƒ©ç½š: {cq.get('penalty_score', 0.0):.4f}")
            print(f"   L2æŸå¤±å€¼: {l2:.4f}")

            print("\nç»¼åˆæŸå¤±:")
            print(f"   L = {l1_weight:.2f} Ã— L1 + {l2_weight:.2f} Ã— L2")
            print(f"   L = {l1_weight:.2f} Ã— {l1:.4f} + {l2_weight:.2f} Ã— {l2:.4f}")
            print(f"   L = {total_loss:.4f}")
        else:
            print(f"\næ€»æŸå¤±: {total_loss:.4f}")

        print(f"{'=' * 80}")

    return loss_dict
