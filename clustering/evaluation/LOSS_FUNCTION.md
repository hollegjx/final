# 聚类损失函数说明

## 概述

本模块实现了用于评估和优化聚类结果的综合损失函数。损失函数结合了**监督损失**(L1)和**无监督损失**(L2)，提供了对聚类质量的全面评估。

## 损失函数公式

```
L = w1 × L1 + w2 × L2
```

其中：
- `L1`: 监督损失（基于有标签样本）
- `L2`: 无监督损失（基于聚类质量指标）
- `w1`, `w2`: 权重系数，默认均为1.0

---

## L1 - 监督损失

### 定义

监督损失评估聚类对有标签样本的分类准确性。

### 计算方法

**基于准确率 (默认):**

```
L1 = 1 - accuracy
```

其中 `accuracy` 是有标签样本的聚类准确率，通过匈牙利算法（Hungarian Algorithm）进行最优聚类-类别匹配后计算得到。

### 计算步骤

1. **提取有标签样本**: 根据`labeled_mask`筛选有标签的样本
2. **构建混淆矩阵**: 计算每个聚类中每个真实类别的样本数
3. **最优匹配**: 使用匈牙利算法找到聚类标签到真实标签的最优一对一映射
4. **计算准确率**:
   ```
   accuracy = (匹配后正确分类的样本数) / (有标签样本总数)
   ```
5. **计算损失**:
   ```
   L1 = 1 - accuracy
   ```

### 取值范围

- **范围**: [0, 1]
- **越小越好**: L1 = 0 表示所有有标签样本都被正确聚类
- **典型值**:
  - `L1 < 0.2`: 优秀
  - `L1 = 0.2~0.4`: 良好
  - `L1 > 0.4`: 需要改进

### 返回指标

```python
{
    'n_labeled': 有标签样本数量,
    'accuracy': 标签准确率 [0, 1],
    'correct_samples': 正确分类的样本数
}
```

---

## L2 - 无监督损失

### 定义

无监督损失评估聚类本身的质量，不依赖于标签信息。

### 计算方法

**基于DBCV (默认):**

```
L2 = 1 - DBCV
```

其中 `DBCV` (Density-Based Clustering Validation) 是一种基于密度的聚类验证指标。

### DBCV 指标

**特点:**
- 专门为基于密度的聚类算法设计
- 考虑聚类的内聚性和分离性
- 适用于任意形状的聚类
- 不需要知道真实标签

**计算依赖:**
- 需要安装 `validclust` 库
- 如果未安装，L2将返回默认值1.0

**DBCV取值范围:**
- **范围**: [-1, 1]
- **越大越好**:
  - `DBCV > 0.5`: 优秀的聚类结构
  - `DBCV = 0.0~0.5`: 中等聚类质量
  - `DBCV < 0`: 较差的聚类质量

### L2取值范围

- **范围**: [0, 2]
- **越小越好**:
  - `L2 < 0.5`: 优秀 (对应 DBCV > 0.5)
  - `L2 = 0.5~1.0`: 良好 (对应 DBCV = 0~0.5)
  - `L2 > 1.0`: 需要改进 (对应 DBCV < 0)

### 返回指标

```python
{
    'dbcv': DBCV分数 [-1, 1],
}
```

---

## 综合损失 L

### 公式

```
L = w1 × L1 + w2 × L2
  = w1 × (1 - accuracy) + w2 × (1 - DBCV)
```

### 默认配置

```python
w1 = 1.0  # 监督损失权重
w2 = 1.0  # 无监督损失权重
```

### 取值范围

- **范围**: [0, 3]（当w1=w2=1.0时）
- **越小越好**:
  - `L < 0.5`: 优秀
  - `L = 0.5~1.0`: 良好
  - `L = 1.0~1.5`: 中等
  - `L > 1.5`: 需要改进

### 权重调整建议

#### 1. 平衡模式 (默认)
```python
w1 = 1.0, w2 = 1.0
```
- 同时重视监督和无监督性能
- 适用于大多数场景

#### 2. 强调监督性能
```python
w1 = 2.0, w2 = 1.0
```
- 更重视有标签样本的分类准确性
- 适用于标签信息较多且可靠的场景

#### 3. 强调聚类质量
```python
w1 = 1.0, w2 = 2.0
```
- 更重视聚类本身的结构质量
- 适用于标签信息较少或不可靠的场景

#### 4. 仅监督
```python
w1 = 1.0, w2 = 0.0
```
- 完全基于标签准确率
- 适用于只关心分类性能的场景

#### 5. 仅无监督
```python
w1 = 0.0, w2 = 1.0
```
- 完全基于聚类质量
- 适用于无标签或标签不可信的场景

---

## 使用方法

### Python API

```python
from clustering.evaluation.loss_function import compute_total_loss

# 计算损失
loss_dict = compute_total_loss(
    X=features,              # 特征矩阵 (n_samples, n_features)
    predictions=pred_labels, # 聚类预测标签 (n_samples,)
    targets=true_labels,     # 真实标签 (n_samples,)
    labeled_mask=mask,       # 有标签样本掩码 (n_samples,)
    l1_weight=1.0,           # L1权重
    l2_weight=1.0,           # L2权重
    l1_type='accuracy',      # L1计算方式
    l2_type='dbcv',          # L2计算方式
    silent=False             # 是否静默模式
)

# 访问结果
print(f"总损失: {loss_dict['total_loss']:.4f}")
print(f"L1损失: {loss_dict['l1']:.4f}")
print(f"L2损失: {loss_dict['l2']:.4f}")
print(f"标签准确率: {loss_dict['l1_metrics']['accuracy']:.4f}")
print(f"DBCV分数: {loss_dict['l2_metrics']['dbcv']:.4f}")
```

### 集成到聚类流程

损失函数已自动集成到`test_adaptive_clustering_on_superclass`函数中，在聚类完成后自动计算并输出。

```bash
python -m clustering.testing.main --superclass_name trees
```

输出示例：
```
================================================================================
📉 损失函数计算
================================================================================
L1 (监督损失):
   类型: accuracy
   有标签样本数: 240
   标签准确率: 0.8750
   L1损失值: 0.1250

L2 (无监督损失):
   类型: dbcv
   DBCV分数: 0.3542
   L2损失值: 0.6458

综合损失:
   L = 1.00 × L1 + 1.00 × L2
   L = 1.00 × 0.1250 + 1.00 × 0.6458
   L = 0.7708
================================================================================
```

---

## 返回值结构

```python
{
    'total_loss': float,       # 综合损失L
    'l1': float,               # 监督损失L1
    'l2': float,               # 无监督损失L2
    'l1_weight': float,        # L1权重
    'l2_weight': float,        # L2权重
    'l1_metrics': {            # L1详细指标
        'n_labeled': int,
        'accuracy': float,
        'correct_samples': int
    },
    'l2_metrics': {            # L2详细指标
        'dbcv': float or None
    }
}
```

---

## 安装DBCV依赖

为了计算L2损失，需要安装`validclust`库：

```bash
pip install validclust
```

如果未安装该库，系统会输出警告信息，并使用默认的L2值（1.0）。

---

## 优化建议

### 1. 降低L1（提高监督性能）

**策略:**
- 调整`density_percentile`，选择更可靠的核心点
- 优化`k`值，改善密度估计
- 调整`assign_model`，使用更精确的分配策略

### 2. 降低L2（提高聚类质量）

**策略:**
- 使用`co_mode=3`（相对自适应co）提高聚类紧密度
- 调整`dense_method`，选择更适合数据分布的密度计算方法
- 增加`density_percentile`，减少噪声点的影响

### 3. 平衡L1和L2

**策略:**
- 使用网格搜索找到最佳参数组合
- 根据具体任务调整`l1_weight`和`l2_weight`
- 监控L1和L2的变化趋势，避免过度优化单一指标

---

## 与ACC指标的关系

**损失函数L vs ACC:**

- **L1监督损失**: 直接基于有标签样本的准确率计算，与ACC密切相关
  - `L1 ≈ 1 - labeled_accuracy`

- **ACC指标**: 在测试集上计算的聚类准确率
  - All ACC: 全部测试样本
  - Old ACC: 已知类别测试样本
  - New ACC: 新类别测试样本

**主要区别:**
1. **计算范围不同**: L1使用全部有标签样本（训练+测试），ACC只使用测试集
2. **用途不同**: L1用于优化和训练，ACC用于最终评估
3. **L2额外考虑**: 损失函数还包含无监督质量L2，更全面

**建议:**
- **训练/优化时**: 最小化综合损失L
- **最终评估时**: 报告ACC指标
- **两者结合**: 损失函数低且ACC高的模型最理想

---

## 注意事项

1. **DBCV计算要求**:
   - 至少需要2个聚类
   - 需要安装`validclust`库
   - 计算可能较慢（大数据集）

2. **匈牙利算法匹配**:
   - L1计算使用最优匹配，可能与直接准确率不同
   - 确保公平比较不同聚类数量的结果

3. **权重选择**:
   - 根据具体任务调整权重
   - 建议先使用默认权重(1.0, 1.0)观察
   - 再根据需求调整

4. **静默模式**:
   - 网格搜索时建议使用`silent=True`减少输出
   - 调试时使用`silent=False`查看详细信息

---

## 更新历史

- 2025-01-20: 初始版本，实现L1(accuracy)和L2(DBCV)损失
- 2025-01-20: 集成到test_superclass.py，自动计算和输出
- 2025-01-20: 创建完整文档

---

## 相关文档

- 密度计算方法: `clustering/density/DENSITY_METHODS.md`
- co计算模式: `clustering/utils/CO_MODES.md`
- 参数指南: `clustering/testing/PARAMETERS_GUIDE.md`
