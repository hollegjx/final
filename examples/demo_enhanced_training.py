#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºè®­ç»ƒåŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ–°æ·»åŠ çš„è®­ç»ƒåŠŸèƒ½ï¼šè½®æ¬¡åˆ†å‰²ã€æ—¶é—´æ˜¾ç¤ºã€æ€§èƒ½å·®è·ã€æ—©åœæœºåˆ¶
"""

import os
import sys
import time
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.training_utils import (
    EarlyStoppingMonitor,
    PerformanceTracker,
    TrainingSession,
    print_epoch_separator,
    print_performance_summary,
    print_training_start_info,
    print_training_complete_info
)


def demo_early_stopping():
    """æ¼”ç¤ºæ—©åœæœºåˆ¶"""
    print("Early Stopping Demo")
    print("=" * 50)

    # åˆ›å»ºæ—©åœç›‘æ§å™¨
    early_stopping = EarlyStoppingMonitor(patience=5, metric_name="test_acc")

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    test_accs = [0.6, 0.65, 0.68, 0.69, 0.70, 0.69, 0.68, 0.67, 0.66, 0.65, 0.64]

    for epoch, acc in enumerate(test_accs):
        print(f"è½®æ¬¡ {epoch}: æµ‹è¯•å‡†ç¡®ç‡ = {acc:.3f}")
        should_stop = early_stopping.update(acc, epoch)

        if should_stop:
            print(f"æ—©åœè§¦å‘ï¼åœ¨ç¬¬{epoch}è½®åœæ­¢")
            break

        time.sleep(0.5)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´

    best_acc, best_epoch = early_stopping.get_best_info()
    print(f"\næœ€ä½³æ€§èƒ½: {best_acc:.3f} (ç¬¬{best_epoch}è½®)")


def demo_performance_tracker():
    """æ¼”ç¤ºæ€§èƒ½è·Ÿè¸ªå™¨"""
    print("\nğŸ¯ æ€§èƒ½è·Ÿè¸ªå™¨æ¼”ç¤º")
    print("=" * 50)

    tracker = PerformanceTracker()

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    performances = [
        (0.60, 0.55, 0.65),  # epoch 0
        (0.65, 0.62, 0.68),  # epoch 1
        (0.70, 0.68, 0.72),  # epoch 2 (æœ€ä½³)
        (0.68, 0.66, 0.70),  # epoch 3
        (0.66, 0.64, 0.68),  # epoch 4
    ]

    for epoch, (all_acc, old_acc, new_acc) in enumerate(performances):
        tracker.update(all_acc, old_acc, new_acc, epoch)

        # è®¡ç®—ä¸æœ€ä½³æ€§èƒ½çš„å·®è·
        gap = tracker.get_performance_gap(all_acc, old_acc, new_acc)
        elapsed = tracker.get_elapsed_time()

        print(f"\nè½®æ¬¡ {epoch}: All={all_acc:.3f}, Old={old_acc:.3f}, New={new_acc:.3f}")
        print(f"  å·²ç”¨æ—¶: {elapsed}")
        print(f"  å·®è·: All={gap['all_acc_gap']:+.3f}, Old={gap['old_acc_gap']:+.3f}, New={gap['new_acc_gap']:+.3f}")

        time.sleep(0.3)

    best_perf = tracker.get_best_performance()
    print(f"\næœ€ä½³æ€§èƒ½ (ç¬¬{best_perf['best_epoch']}è½®):")
    print(f"  All: {best_perf['best_all_acc']:.3f}")
    print(f"  Old: {best_perf['best_old_acc']:.3f}")
    print(f"  New: {best_perf['best_new_acc']:.3f}")


def demo_training_session():
    """æ¼”ç¤ºå®Œæ•´è®­ç»ƒä¼šè¯"""
    print("\nğŸ¯ å®Œæ•´è®­ç»ƒä¼šè¯æ¼”ç¤º")
    print("=" * 50)

    # æ¨¡æ‹Ÿè®­ç»ƒå‚æ•°
    class MockArgs:
        dataset_name = "cifar100_superclass"
        superclass_name = "mammals"
        num_labeled_classes = 20
        num_unlabeled_classes = 3
        epochs = 10
        batch_size = 128
        lr = 0.1
        sup_con_weight = 0.5

    args = MockArgs()

    # åˆ›å»ºè®­ç»ƒä¼šè¯
    session = TrainingSession(args, enable_early_stopping=True, patience=3)

    # å¼€å§‹è®­ç»ƒ
    model_info = {
        'name': 'vit_dino',
        'feat_dim': 768
    }
    session.start_training(model_info)

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    performances = [
        (0.80, 0.40, 0.60, 0.55, 0.65, 0.62, 0.68, 0.66, 0.70),  # epoch 0
        (0.82, 0.42, 0.65, 0.60, 0.70, 0.67, 0.73, 0.71, 0.75),  # epoch 1
        (0.85, 0.45, 0.70, 0.65, 0.75, 0.72, 0.78, 0.76, 0.80),  # epoch 2 (æœ€ä½³)
        (0.83, 0.43, 0.68, 0.63, 0.73, 0.70, 0.76, 0.74, 0.78),  # epoch 3
        (0.81, 0.41, 0.66, 0.61, 0.71, 0.68, 0.74, 0.72, 0.76),  # epoch 4
        (0.79, 0.39, 0.64, 0.59, 0.69, 0.66, 0.72, 0.70, 0.74),  # epoch 5 - åº”è¯¥è§¦å‘æ—©åœ
    ]

    for epoch, (train_acc, loss_avg, all_acc, old_acc, new_acc,
                all_acc_test, old_acc_test, new_acc_test) in enumerate(performances):

        # å¼€å§‹è½®æ¬¡
        session.start_epoch(epoch)

        # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        time.sleep(1)

        # ç»“æŸè½®æ¬¡ï¼Œæ£€æŸ¥æ˜¯å¦æ—©åœ
        should_stop = session.end_epoch(
            epoch=epoch,
            train_acc=train_acc,
            loss_avg=loss_avg,
            all_acc=all_acc,
            old_acc=old_acc,
            new_acc=new_acc,
            all_acc_test=all_acc_test,
            old_acc_test=old_acc_test,
            new_acc_test=new_acc_test
        )

        # æ¨¡æ‹Ÿæ¨¡å‹ä¿å­˜
        session.save_model_info(f"model_epoch_{epoch}.pt")
        if old_acc_test > 0.75:  # æ¨¡æ‹Ÿæœ€ä½³æ¨¡å‹
            session.save_model_info(f"model_best.pt", is_best=True, acc=old_acc_test)

        if should_stop:
            print(f"\nğŸ›‘ æ¼”ç¤ºï¼šæ—©åœè§¦å‘åœ¨ç¬¬{epoch+1}è½®")
            session.finish_training(epoch, early_stopped=True)
            break
    else:
        session.finish_training(args.epochs - 1, early_stopped=False)

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    best_perf = session.get_best_performance()
    print(f"\nğŸ“Š æœ€ç»ˆæœ€ä½³æ€§èƒ½:")
    for key, value in best_perf.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.4f}")
        else:
            print(f"  {key}: {value}")


def demo_output_formatting():
    """æ¼”ç¤ºè¾“å‡ºæ ¼å¼"""
    print("\nğŸ¯ è¾“å‡ºæ ¼å¼æ¼”ç¤º")
    print("=" * 50)

    # æ¼”ç¤ºè½®æ¬¡åˆ†éš”ç¬¦
    for epoch in range(3):
        print_epoch_separator(epoch, 10, f"00:0{epoch+1}:30")

        # æ¨¡æ‹Ÿä¸€äº›è¾“å‡º
        print("ğŸ”„ è®­ç»ƒä¸­...")
        print("ğŸ“Š è®¡ç®—æŒ‡æ ‡...")
        time.sleep(0.5)

        # æ¼”ç¤ºæ€§èƒ½æ€»ç»“
        performance_gap = {
            'all_acc_gap': -0.02 + epoch * 0.01,
            'old_acc_gap': -0.03 + epoch * 0.015,
            'new_acc_gap': -0.01 + epoch * 0.005
        }

        best_performance = {
            'best_all_acc': 0.75,
            'best_old_acc': 0.72,
            'best_new_acc': 0.78,
            'best_epoch': 1
        }

        print_performance_summary(
            epoch=epoch,
            train_acc=0.80 + epoch * 0.02,
            all_acc=0.65 + epoch * 0.03,
            old_acc=0.62 + epoch * 0.04,
            new_acc=0.68 + epoch * 0.02,
            all_acc_test=0.70 + epoch * 0.02,
            old_acc_test=0.67 + epoch * 0.03,
            new_acc_test=0.73 + epoch * 0.01,
            performance_gap=performance_gap,
            best_performance=best_performance,
            loss_avg=1.5 - epoch * 0.3
        )


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºè®­ç»ƒåŠŸèƒ½æ¼”ç¤º')
    parser.add_argument('--demo', type=str, default='all',
                        choices=['early_stopping', 'performance_tracker', 'training_session', 'output_formatting', 'all'],
                        help='é€‰æ‹©è¦æ¼”ç¤ºçš„åŠŸèƒ½')

    args = parser.parse_args()

    print("*** GCD Enhanced Training Features Demo ***")
    print("Demonstrating new features: epoch separation, time display, performance gap, early stopping")
    print("=" * 80)

    if args.demo in ['early_stopping', 'all']:
        demo_early_stopping()

    if args.demo in ['performance_tracker', 'all']:
        demo_performance_tracker()

    if args.demo in ['output_formatting', 'all']:
        demo_output_formatting()

    if args.demo in ['training_session', 'all']:
        demo_training_session()

    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("ç°åœ¨æ‚¨å¯ä»¥åœ¨å®é™…è®­ç»ƒä¸­ä½“éªŒè¿™äº›æ–°åŠŸèƒ½äº†ã€‚")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. åŸç‰ˆGCDè®­ç»ƒ: python methods/contrastive_training/contrastive_training.py [å‚æ•°]")
    print("2. è¶…ç±»è®­ç»ƒ: python train_superclass.py --superclass_name mammals [å‚æ•°]")
    print("3. æ‰€æœ‰åŠŸèƒ½éƒ½è‡ªåŠ¨å¯ç”¨ï¼ŒåŒ…æ‹¬29è½®æ—©åœæœºåˆ¶")


if __name__ == "__main__":
    main()