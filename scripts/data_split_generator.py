#!/usr/bin/env python3
"""
GCDé¡¹ç›®è¶…ç±»æ•°æ®åˆ’åˆ†ç”Ÿæˆå™¨
åŸºäºDCCLé¡¹ç›®çš„level_a_superclass_splitter.pyï¼Œé€‚é…GCDé¡¹ç›®ç»“æ„
"""

import os
import json
import numpy as np
from collections import defaultdict, Counter
from torchvision import datasets
import datetime
import argparse
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥è¶…ç±»å®šä¹‰
from data.cifar100_superclass import CIFAR100_SUPERCLASSES, CLASS_TO_SUPERCLASS, SUPERCLASS_NAMES


def simple_train_test_split(indices, targets, test_size=0.5, random_state=42):
    """ç®€å•çš„åˆ†å±‚åˆ’åˆ†å‡½æ•°ï¼Œæ›¿ä»£sklearn"""
    import random
    random.seed(random_state)

    # æŒ‰ç±»åˆ«åˆ†ç»„
    class_indices = {}
    for i, (idx, target) in enumerate(zip(indices, targets)):
        if target not in class_indices:
            class_indices[target] = []
        class_indices[target].append(idx)

    train_indices = []
    test_indices = []

    # å¯¹æ¯ä¸ªç±»åˆ«æŒ‰æ¯”ä¾‹åˆ’åˆ†
    for target, cls_indices in class_indices.items():
        random.shuffle(cls_indices)
        n_test = int(len(cls_indices) * test_size)
        test_indices.extend(cls_indices[:n_test])
        train_indices.extend(cls_indices[n_test:])

    return train_indices, test_indices


class GCDSuperclassSplitter:
    """GCDé¡¹ç›®è¶…ç±»æ•°æ®åˆ’åˆ†å™¨"""

    def __init__(self, output_dir='./data_splits', cifar100_root='./data'):
        self.output_dir = output_dir
        self.cifar100_root = cifar100_root

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)

        # GCDè®¾å®šï¼šå‰80ä¸ªç±»ä¸ºå·²çŸ¥ç±»ï¼Œå20ä¸ªç±»ä¸ºæœªçŸ¥ç±»
        self.known_classes = list(range(80))
        self.unknown_classes = list(range(80, 100))

        print(f"ğŸš€ GCDè¶…ç±»æ•°æ®åˆ’åˆ†å™¨åˆå§‹åŒ–")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“Š å·²çŸ¥ç±»: {len(self.known_classes)}ä¸ª (0-79)")
        print(f"ğŸ“Š æœªçŸ¥ç±»: {len(self.unknown_classes)}ä¸ª (80-99)")

    def load_cifar100_data(self):
        """åŠ è½½CIFAR-100æ•°æ®"""
        print("\nğŸ“‚ åŠ è½½CIFAR-100æ•°æ®...")

        try:
            # åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            cifar100_train = datasets.CIFAR100(root=self.cifar100_root, train=True, download=False)
            cifar100_test = datasets.CIFAR100(root=self.cifar100_root, train=False, download=False)
        except Exception as e:
            print(f"âŒ åŠ è½½CIFAR-100æ•°æ®å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•ä¸‹è½½æ•°æ®...")
            cifar100_train = datasets.CIFAR100(root=self.cifar100_root, train=True, download=True)
            cifar100_test = datasets.CIFAR100(root=self.cifar100_root, train=False, download=True)

        # åˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ‡ç­¾å’Œç´¢å¼• (å…¨å±€ç´¢å¼•)
        all_targets = []
        all_indices = []
        all_is_train = []

        # è®­ç»ƒé›†: ç´¢å¼• 0-49999
        for i, target in enumerate(cifar100_train.targets):
            all_targets.append(target)
            all_indices.append(i)
            all_is_train.append(True)

        # æµ‹è¯•é›†: ç´¢å¼• 50000-59999
        for i, target in enumerate(cifar100_test.targets):
            all_targets.append(target)
            all_indices.append(50000 + i)
            all_is_train.append(False)

        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: æ€»å…± {len(all_targets)} ä¸ªæ ·æœ¬")
        return all_targets, all_indices, all_is_train

    def get_superclass_samples(self, all_targets, all_indices, all_is_train, superclass_id):
        """è·å–æŒ‡å®šè¶…ç±»çš„æ‰€æœ‰æ ·æœ¬"""
        superclass_name = SUPERCLASS_NAMES[superclass_id]

        # è·å–å½“å‰è¶…ç±»åŒ…å«çš„æ‰€æœ‰ç±»åˆ«
        superclass_classes = CIFAR100_SUPERCLASSES[superclass_name]

        # ç­›é€‰å½“å‰è¶…ç±»çš„æ ·æœ¬
        superclass_targets = []
        superclass_indices = []
        superclass_is_train = []

        for target, idx, is_train in zip(all_targets, all_indices, all_is_train):
            if target in superclass_classes:
                superclass_targets.append(target)
                superclass_indices.append(idx)
                superclass_is_train.append(is_train)

        # åˆ†ç¦»å·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»
        known_classes_in_superclass = [cls for cls in superclass_classes if cls in self.known_classes]
        unknown_classes_in_superclass = [cls for cls in superclass_classes if cls in self.unknown_classes]

        print(f"\nğŸ¯ è¶…ç±» {superclass_id}: {superclass_name}")
        print(f"  æ€»æ ·æœ¬æ•°: {len(superclass_indices)}")
        print(f"  åŒ…å«ç±»åˆ«: {superclass_classes}")
        print(f"  å·²çŸ¥ç±»åˆ«: {known_classes_in_superclass} ({len(known_classes_in_superclass)}ä¸ª)")
        print(f"  æœªçŸ¥ç±»åˆ«: {unknown_classes_in_superclass} ({len(unknown_classes_in_superclass)}ä¸ª)")

        return {
            'superclass_id': superclass_id,
            'superclass_name': superclass_name,
            'all_classes': superclass_classes,
            'known_classes': known_classes_in_superclass,
            'unknown_classes': unknown_classes_in_superclass,
            'targets': superclass_targets,
            'indices': superclass_indices,
            'is_train': superclass_is_train
        }

    def create_superclass_split(self, superclass_data):
        """ä¸ºå•ä¸ªè¶…ç±»åˆ›å»ºGCDå…¼å®¹çš„åˆ’åˆ†"""
        superclass_id = superclass_data['superclass_id']
        superclass_name = superclass_data['superclass_name']

        print(f"\nğŸ“Š ä¸ºè¶…ç±» {superclass_id} ({superclass_name}) åˆ›å»ºGCDåˆ’åˆ†...")

        # åˆ†ç¦»è®­ç»ƒé›†æ¥æºå’Œæµ‹è¯•é›†æ¥æºçš„æ ·æœ¬
        train_set_known_indices = []  # æ¥è‡ªè®­ç»ƒé›†çš„å·²çŸ¥ç±»æ ·æœ¬
        train_set_unknown_indices = []  # æ¥è‡ªè®­ç»ƒé›†çš„æœªçŸ¥ç±»æ ·æœ¬
        test_set_indices = []  # æ¥è‡ªæµ‹è¯•é›†çš„æ‰€æœ‰è¶…ç±»æ ·æœ¬ï¼ˆç”¨ä½œæœ€ç»ˆæµ‹è¯•é›†ï¼‰

        for target, idx, is_train in zip(superclass_data['targets'],
                                       superclass_data['indices'],
                                       superclass_data['is_train']):
            if is_train:  # æ¥è‡ªCIFAR100è®­ç»ƒé›† (ç´¢å¼•0-49999)
                if target in superclass_data['known_classes']:
                    train_set_known_indices.append(idx)
                elif target in superclass_data['unknown_classes']:
                    train_set_unknown_indices.append(idx)
            else:  # æ¥è‡ªCIFAR100æµ‹è¯•é›† (ç´¢å¼•50000-59999)
                test_set_indices.append(idx)  # æµ‹è¯•é›†åŒ…å«æ‰€æœ‰è¶…ç±»æ ·æœ¬

        print(f"  è®­ç»ƒé›†ä¸­å·²çŸ¥ç±»æ ·æœ¬: {len(train_set_known_indices)}")
        print(f"  è®­ç»ƒé›†ä¸­æœªçŸ¥ç±»æ ·æœ¬: {len(train_set_unknown_indices)}")
        print(f"  æµ‹è¯•é›†ä¸­è¶…ç±»æ ·æœ¬: {len(test_set_indices)}")

        # ä»è®­ç»ƒé›†çš„å·²çŸ¥ç±»æ ·æœ¬ä¸­åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        if len(train_set_known_indices) > 0:
            # åŠ è½½è®­ç»ƒé›†è·å–æ ‡ç­¾
            try:
                cifar100_train = datasets.CIFAR100(root=self.cifar100_root, train=True, download=False)
            except:
                cifar100_train = datasets.CIFAR100(root=self.cifar100_root, train=True, download=True)

            # è·å–è®­ç»ƒé›†å·²çŸ¥ç±»æ ·æœ¬çš„æ ‡ç­¾ç”¨äºåˆ†å±‚åˆ’åˆ†
            train_known_targets = []
            for idx in train_set_known_indices:
                train_known_targets.append(cifar100_train.targets[idx])

            # 8:2åˆ’åˆ†ä¸ºè®­ç»ƒ/éªŒè¯é›†ï¼ˆä¸GCDæ ‡å‡†ä¸€è‡´ï¼‰
            train_indices, val_indices = simple_train_test_split(
                train_set_known_indices,
                train_known_targets,
                test_size=0.2,  # 20%éªŒè¯é›†
                random_state=42
            )
        else:
            train_indices, val_indices = [], []

        # æµ‹è¯•é›†ä½¿ç”¨CIFAR100åŸå§‹æµ‹è¯•é›†ä¸­çš„è¶…ç±»æ ·æœ¬
        test_indices = test_set_indices

        # ä¸ºGCDå…¼å®¹æ€§ä¿ç•™è¿™äº›å­—æ®µ
        labeled_indices = train_indices + val_indices  # æ‰€æœ‰æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ®
        unlabeled_indices = train_set_unknown_indices  # è®­ç»ƒé›†ä¸­çš„æœªçŸ¥ç±»æ ·æœ¬
        unknown_indices = test_set_indices  # æµ‹è¯•é›†ä¸­çš„æ‰€æœ‰æ ·æœ¬

        # åˆ›å»ºè¯¦ç»†çš„åˆ’åˆ†ç»“æœ
        split_result = {
            'superclass_info': {
                'superclass_id': superclass_id,
                'superclass_name': superclass_name,
                'all_classes': superclass_data['all_classes'],
                'known_classes': superclass_data['known_classes'],
                'unknown_classes': superclass_data['unknown_classes']
            },
            'split_statistics': {
                'train_samples': len(train_indices),
                'val_samples': len(val_indices),
                'test_samples': len(test_indices),
                'labeled_samples': len(labeled_indices),
                'unlabeled_samples': len(unlabeled_indices),
                'unknown_samples': len(unknown_indices),
                'total_samples': len(superclass_data['indices'])
            },
            'data_splits': {
                'train_indices': train_indices,
                'val_indices': val_indices,
                'test_indices': test_indices,
                'labeled_indices': labeled_indices,
                'unlabeled_indices': unlabeled_indices,
                'unknown_indices': unknown_indices
            }
        }

        print(f"  ğŸ¯ æœ€ç»ˆåˆ’åˆ† (GCDå…¼å®¹):")
        print(f"    è®­ç»ƒé›†: {len(train_indices)} æ ·æœ¬ (æ¥è‡ªCIFAR100è®­ç»ƒé›†çš„å·²çŸ¥ç±»)")
        print(f"    éªŒè¯é›†: {len(val_indices)} æ ·æœ¬ (æ¥è‡ªCIFAR100è®­ç»ƒé›†çš„å·²çŸ¥ç±»)")
        print(f"    æµ‹è¯•é›†: {len(test_indices)} æ ·æœ¬ (æ¥è‡ªCIFAR100åŸå§‹æµ‹è¯•é›†çš„æ‰€æœ‰è¶…ç±»æ ·æœ¬)")
        print(f"    æ— æ ‡ç­¾: {len(unlabeled_indices)} æ ·æœ¬ (æ¥è‡ªCIFAR100è®­ç»ƒé›†çš„æœªçŸ¥ç±»)")

        return split_result

    def save_superclass_split(self, split_result):
        """ä¿å­˜å•ä¸ªè¶…ç±»çš„åˆ’åˆ†ç»“æœ"""
        superclass_id = split_result['superclass_info']['superclass_id']
        superclass_name = split_result['superclass_info']['superclass_name']

        # ä¸ºæ¯ä¸ªè¶…ç±»åˆ›å»ºç‹¬ç«‹çš„JSONæ–‡ä»¶
        output_file = os.path.join(self.output_dir, f'superclass_{superclass_id:02d}_{superclass_name}.json')

        # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
        json_data = {
            'superclass_info': split_result['superclass_info'],
            'split_statistics': split_result['split_statistics'],
            'data_splits': {
                'train_indices': [int(idx) for idx in split_result['data_splits']['train_indices']],
                'val_indices': [int(idx) for idx in split_result['data_splits']['val_indices']],
                'test_indices': [int(idx) for idx in split_result['data_splits']['test_indices']],
                'labeled_indices': [int(idx) for idx in split_result['data_splits']['labeled_indices']],
                'unlabeled_indices': [int(idx) for idx in split_result['data_splits']['unlabeled_indices']],
                'unknown_indices': [int(idx) for idx in split_result['data_splits']['unknown_indices']]
            },
            'metadata': {
                'split_version': 'gcd_superclass_v1.0',
                'gcd_config': 'GCD-compatible splits for superclass training',
                'train_val_ratio': '8:2 for labeled samples',
                'random_seed': 42,
                'created_time': datetime.datetime.now().isoformat(),
                'dataset': 'CIFAR-100',
                'framework': 'Generalized Category Discovery'
            }
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ è¶…ç±» {superclass_id} åˆ’åˆ†ç»“æœå·²ä¿å­˜: {output_file}")
        return output_file

    def create_all_superclass_splits(self):
        """ä¸ºæ‰€æœ‰15ä¸ªè¶…ç±»åˆ›å»ºåˆ’åˆ†"""
        print("ğŸš€ å¼€å§‹ä¸ºæ‰€æœ‰è¶…ç±»åˆ›å»ºGCDå…¼å®¹åˆ’åˆ†")
        print("=" * 80)

        # 1. åŠ è½½æ•°æ®
        all_targets, all_indices, all_is_train = self.load_cifar100_data()

        # 2. ä¸ºæ¯ä¸ªè¶…ç±»åˆ›å»ºåˆ’åˆ†
        saved_files = []
        summary_stats = []

        for superclass_id in range(15):  # 0-14
            # è·å–è¶…ç±»æ ·æœ¬
            superclass_data = self.get_superclass_samples(all_targets, all_indices, all_is_train, superclass_id)

            # åˆ›å»ºåˆ’åˆ†
            split_result = self.create_superclass_split(superclass_data)

            # ä¿å­˜ç»“æœ
            output_file = self.save_superclass_split(split_result)
            saved_files.append(output_file)

            # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            summary_stats.append(split_result['split_statistics'])

        # 3. åˆ›å»ºæ€»ç»“æ–‡ä»¶
        self.create_summary_file(summary_stats, saved_files)

        print(f"\nâœ… æ‰€æœ‰15ä¸ªè¶…ç±»çš„GCDå…¼å®¹åˆ’åˆ†åˆ›å»ºå®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“Š ç”Ÿæˆæ–‡ä»¶æ•°: {len(saved_files)}")

        return saved_files

    def create_summary_file(self, summary_stats, saved_files):
        """åˆ›å»ºæ€»ç»“æ–‡ä»¶"""
        summary = {
            'gcd_superclass_splits_summary': {
                'total_superclasses': 15,
                'superclass_names': SUPERCLASS_NAMES,
                'gcd_config': {
                    'known_classes': self.known_classes,
                    'unknown_classes': self.unknown_classes,
                    'labeled_ratio': 0.8,
                    'train_val_ratio': 0.8
                },
                'files_created': [os.path.basename(f) for f in saved_files],
                'statistics_by_superclass': []
            }
        }

        total_train = total_val = total_test = 0

        for i, stats in enumerate(summary_stats):
            summary['gcd_superclass_splits_summary']['statistics_by_superclass'].append({
                'superclass_id': i,
                'superclass_name': SUPERCLASS_NAMES[i],
                'train_samples': stats['train_samples'],
                'val_samples': stats['val_samples'],
                'test_samples': stats['test_samples'],
                'total_samples': stats['total_samples']
            })

            total_train += stats['train_samples']
            total_val += stats['val_samples']
            total_test += stats['test_samples']

        summary['gcd_superclass_splits_summary']['total_statistics'] = {
            'total_train_samples': total_train,
            'total_val_samples': total_val,
            'total_test_samples': total_test,
            'grand_total': total_train + total_val + total_test
        }

        summary_file = os.path.join(self.output_dir, 'gcd_superclass_splits_summary.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“‹ æ€»ç»“æ–‡ä»¶å·²ä¿å­˜: {summary_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='GCDé¡¹ç›®è¶…ç±»æ•°æ®åˆ’åˆ†ç”Ÿæˆå™¨')
    parser.add_argument('--output_dir', type=str, default='./data_splits',
                        help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--cifar100_root', type=str, default='./data',
                        help='CIFAR-100æ•°æ®é›†æ ¹ç›®å½•')

    args = parser.parse_args()

    print("ğŸ¯ GCDé¡¹ç›®è¶…ç±»æ•°æ®åˆ’åˆ†ç”Ÿæˆå™¨")
    print("=" * 80)

    # åˆ›å»ºåˆ’åˆ†å™¨
    splitter = GCDSuperclassSplitter(
        output_dir=args.output_dir,
        cifar100_root=args.cifar100_root
    )

    # åˆ›å»ºæ‰€æœ‰è¶…ç±»çš„åˆ’åˆ†
    saved_files = splitter.create_all_superclass_splits()

    print(f"\nğŸ‰ åˆ’åˆ†å®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {splitter.output_dir}")
    print(f"ğŸ“Š 15ä¸ªè¶…ç±»çš„æ•°æ®åˆ’åˆ†å·²ç”Ÿæˆï¼Œå¯ç”¨äºGCDè®­ç»ƒ")

    return saved_files


if __name__ == "__main__":
    main()