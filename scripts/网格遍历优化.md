# KNN磁盘缓存优化方案

## 背景与总体目标

我们当前正在进行**GCD (Generalized Category Discovery)** 问题的研究，使用SS-DDBC自适应密度聚类算法在CIFAR-100数据集上进行实验。核心训练流程包括：对比学习特征提取 → 网格搜索最优聚类参数 → 生成伪标签 → 继续训练。

**当前问题**：之前实现的内存传递KNN缓存方案，在并行模式下因大数组pickle序列化导致程序卡住。用户需要运行至少600次聚类任务（如15个超类 × 40个参数组合），每个k值会重复计算十几次（density_range有12个值），内存传递方案存在严重的序列化瓶颈和内存爆炸问题。

**优化目标**：改用磁盘I/O缓存方案，将KNN结果保存为`.npy`文件，子进程按需加载，实现跨进程、跨运行的KNN结果复用，解决卡顿问题并提升长期性能。

**关键约束**：系统存在两种不同的使用场景，需要区别对待：
1. **训练循环场景**（在线）：每轮训练后特征空间变化，旧KNN缓存失效，必须清理
2. **离线搜索场景**（批量）：特征固定不变，KNN缓存可跨运行复用

---

## 代码定位

```
ssddbc/grid_search/batch_runner.py - 批量网格搜索入口（离线场景，持久缓存）
ssddbc/grid_search/api.py - 内存级网格搜索API（训练场景，临时缓存）
ssddbc/density/density_estimation.py - KNN计算（保持不变，已支持precomputed_knn）
ssddbc/ssddbc/adaptive_clustering.py - 聚类主算法（保持不变）
ssddbc/testing/test_superclass.py - 测试层（保持不变）
```

---

## 第一部分：需求理解

### 核心需求

1. **修改什么**：将KNN缓存从内存字典传递改为磁盘文件存储，子进程按需加载
2. **保持什么**：底层聚类算法逻辑不变，向后兼容现有API，结果确定性不变
3. **方案要求**：避免大数组序列化，降低内存占用，区分在线/离线场景的缓存策略

### 本质分析

**业务动机**：600次任务场景下，内存传递方案每启动一个子进程都要序列化数MB的numpy数组，造成卡顿；磁盘I/O读取`.npy`文件耗时<1ms，远小于KNN计算（数百ms）。

**技术约束**：
1. multiprocessing的pickle机制对大数组序列化效率低
2. numpy的`.npy`格式支持高效二进制读写
3. **训练循环中特征动态变化**，旧KNN缓存会导致正确性问题（用过时的邻居关系聚类）
4. **离线搜索中特征固定**，KNN缓存可安全复用

---

## 第二部分：方案思路

### 核心策略

**区分两种使用场景，采用不同的缓存策略**：
- **训练循环（api.py）**：临时缓存 + 自动清理，避免跨轮次复用
- **离线搜索（batch_runner.py）**：持久缓存 + 手动清理，支持跨运行复用

### 关键原则

- **最小侵入性**：只修改网格搜索层的缓存逻辑，底层聚类函数不变
- **向后兼容**：保留precomputed_knn参数机制，只改变数据来源（从内存字典 → 磁盘文件）
- **可维护性**：缓存目录结构清晰，职责分离
- **一致性**：串行/并行模式使用统一的磁盘缓存策略
- **正确性优先**：训练循环中必须避免使用过时的KNN缓存

### 最优理由

- **灵活性**：两种场景各取所需，训练保证正确性，离线保证性能
- **可维护性**：临时缓存自动管理（无需手动清理），持久缓存路径可读性强
- **可测试性**：可单独验证缓存文件的正确性，不依赖进程间通信
- **清晰度**：数据流明确（计算→保存→加载→使用→清理），无隐式状态共享

---

**注**：如有更优方案（如使用特征哈希自动检测缓存有效性），可斟酌后修改。

---

## 第三部分：函数层级修改

### 第0层：density_estimation.py（底层）

**函数**：`compute_median_density`

**职责**：计算k近邻并基于中位数距离估计密度

**修改点**：
- **无需修改**：已支持`precomputed_knn`参数，只需上层提供正确的数据即可

**决策**：
- 为什么不在此层处理磁盘I/O？**决策**：底层函数应保持纯粹的计算职责，不关心数据来源（内存还是磁盘）

**影响检查**：无影响，保持现有实现

---

### 第1层：adaptive_clustering.py（中间层）

**函数**：`adaptive_density_clustering`

**职责**：SS-DDBC聚类主流程

**修改点**：
- **无需修改**：已支持`precomputed_knn`参数传递

**决策**：
- 是否需要感知数据来自磁盘？**决策**：不需要，此层只负责流程编排，数据来源由上层决定

**影响检查**：无影响，保持现有实现

---

### 第2层A：batch_runner.py（预计算函数 - 离线场景）

**函数**：`_precompute_knn_cache`

**职责**：预计算所有k值的KNN结果（持久缓存）

**修改点**：
1. **改变返回值**：从返回内存字典`{k: (neighbors, distances)}`改为返回缓存目录路径字符串
2. **新增磁盘保存逻辑**：为每个k生成两个`.npy`文件（`k{k}_neighbors.npy`, `k{k}_distances.npy`）
3. **新增缓存检查**：如果文件已存在，跳过计算直接复用（支持跨运行复用）
4. **确定缓存目录结构**：`{feature_cache_dir}/{superclass}/knn_cache/`
5. **支持手动清理**：如果命令行传入`--clear_knn_cache`，在计算前删除旧缓存

**决策**：
- 文件命名格式？**决策**：`k{k}_neighbors.npy`，简洁且可读性强，便于手动检查
- 缓存目录位置？**决策**：与特征缓存平行，便于统一管理（删除超类时可一并删除）
- 是否需要校验文件完整性？**决策**：不需要，numpy的`save/load`自带数据完整性保证，文件损坏会抛出异常
- 为什么离线场景可以持久化？**决策**：离线搜索中特征来自固定的缓存文件，不会变化，可安全复用

**影响检查**：下游函数需要改为接收路径字符串而非字典

---

### 第2层B：batch_runner.py（并行搜索函数）

**函数**：`_run_parallel_grid_search`

**职责**：并行执行网格搜索

**修改点**：
1. **修改参数接收**：`knn_cache`从字典类型改为字符串类型（目录路径）
2. **修改参数传递**：在构建`args_tuple`时，传递`knn_cache_dir`字符串而非`knn_cache.get(k)`数组

**决策**：
- 为什么传递目录路径而非文件路径？**决策**：子进程需要根据自己的k值拼接文件名，传递目录更灵活；且字符串序列化开销可忽略不计

**影响检查**：需要同步修改`_run_single_process`的参数解包和使用逻辑

---

### 第2层C：batch_runner.py（worker函数）

**函数**：`_run_single_process`

**职责**：子进程中执行单个(k, dp)组合的聚类

**修改点**：
1. **修改参数解包**：`knn_cache_dir`从字典改为字符串
2. **新增磁盘加载逻辑**：根据k值拼接文件路径，使用`np.load`加载数组
3. **构建precomputed_knn元组**：将加载的数组传递给聚类函数

**决策**：
- 文件不存在时的处理？**决策**：`precomputed_knn=None`，退化为自动计算（容错性）
- 是否需要缓存加载的数组？**决策**：不需要，子进程只执行一次聚类就结束，无需缓存

**影响检查**：确保加载的数组维度与原计算结果一致（density_estimation.py第40-43行已处理k+1的情况）

---

### 第2层D：batch_runner.py（串行搜索函数）

**函数**：`_run_serial_grid_search`

**职责**：串行执行网格搜索（调试模式）

**修改点**：
1. **修改参数接收**：`knn_cache`从字典改为字符串
2. **新增磁盘加载逻辑**：在调用`_run_single`前，加载对应k的KNN数据

**决策**：
- 串行模式是否可以复用内存缓存？**决策**：不，保持与并行模式一致的逻辑，便于切换模式调试

**影响检查**：需要同步修改`_run_single`的参数签名

---

### 第2层E：batch_runner.py（单次聚类函数）

**函数**：`_run_single`

**职责**：执行单次聚类（串行模式使用）

**修改点**：
1. **新增参数**：添加`knn_cache_dir`参数
2. **新增加载逻辑**：与`_run_single_process`相同

**决策**：
- 是否合并两个函数？**决策**：不，两者服务于不同场景（进程内/进程间），保持分离便于维护

**影响检查**：串行搜索函数调用此函数时需传递新参数

---

### 第3层：api.py（内存级网格搜索 - 训练循环场景）

**函数**：`run_clustering_search_on_features`

**职责**：供训练代码调用的内存级网格搜索API

**修改点**：
1. **使用临时缓存目录**：使用`tempfile.TemporaryDirectory`创建临时缓存，而非持久化到`feature_cache_dir`
2. **预计算并保存KNN**：将所有k值的KNN结果保存到临时目录
3. **修改参数传递**：单进程模式直接加载文件；多进程模式传递临时目录路径
4. **worker函数修改**：`_worker_evaluate_config`接收路径并加载
5. **自动清理**：退出`with`块后，临时目录及其中的KNN缓存自动删除

**决策**：
- 为什么使用临时缓存而非持久缓存？**决策**：训练循环中，每轮训练后模型权重更新 → 特征空间变化 → 旧KNN缓存基于过时的特征，会导致聚类错误。必须每轮重新计算并在结束后清理。
- 临时目录位置？**决策**：使用`tempfile.TemporaryDirectory(prefix="knn_cache_")`，系统会在`/tmp`或`%TEMP%`下创建，并自动管理生命周期
- 是否需要保留缓存？**决策**：不需要，下一轮训练的特征已变化，复用会导致错误

**影响检查**：此API被训练脚本（如`pseudo_pipeline.py`）调用，行为变化对用户透明（无需修改训练脚本）

---

### 第3层辅助：api.py（worker函数）

**函数**：`_worker_evaluate_config`

**职责**：多进程模式下的评估worker

**修改点**：
1. **新增参数**：接收`knn_cache_dir`路径
2. **新增加载逻辑**：根据k值从临时目录加载KNN数据

**决策**：
- 与batch_runner的worker有何不同？**决策**：逻辑相同（都是从磁盘加载KNN），只是缓存目录来源不同（临时 vs 持久）

**影响检查**：需要同步修改`_run_single_configuration`的参数

---

## 第四部分：数据流对比

### 修改前（内存传递，存在卡顿）

```
主进程内存: 预计算 knn_cache = {k1: (大数组1), k2: (大数组2), ...}
         ↓ pickle序列化（卡顿点）
子进程1: 反序列化完整字典 → 提取 knn_cache[k1] → 聚类
子进程2: 反序列化完整字典 → 提取 knn_cache[k1] → 聚类（重复序列化）
子进程3: 反序列化完整字典 → 提取 knn_cache[k2] → 聚类
         ↓
结束后释放内存，下次运行重新计算
```

**问题点**：
- 每个子进程都要反序列化完整字典（包含所有k的数据，即使只用一个k）
- 序列化大数组导致进程启动卡顿
- 无法跨运行复用

---

### 修改后（磁盘缓存，按需加载）

#### 场景1：离线批量搜索（batch_runner.py）

```
主进程: 预计算并保存（持久缓存）
    检查 feature_cache/trees/knn_cache/k3_neighbors.npy 是否存在
    不存在 → 计算并保存 .npy 文件
    返回 knn_cache_dir = "feature_cache/trees/knn_cache"
         ↓ 只传递路径字符串（几字节）
子进程1: 接收路径 "...knn_cache" + k=3
         → 拼接文件路径 "...knn_cache/k3_neighbors.npy"
         → np.load(文件) ← 1ms读取
         → 聚类
子进程2: 接收路径 + k=3 → 加载k3文件 → 聚类（独立加载，无等待）
子进程3: 接收路径 + k=4 → 加载k4文件 → 聚类
         ↓
结束后文件保留在磁盘，下次运行可直接复用（跳过计算） ✅
```

---

#### 场景2：训练循环（api.py）

```
第50轮训练:
    提取特征 features_epoch50 (特征空间A)
    ↓
主进程: 创建临时缓存目录 /tmp/knn_cache_xxxxx/
    预计算 KNN (基于特征空间A) 并保存到临时目录
    返回 knn_cache_dir = "/tmp/knn_cache_xxxxx"
         ↓ 只传递路径字符串
子进程1-N: 加载临时缓存 → 聚类 → 生成伪标签
         ↓
函数结束，临时目录自动删除 ✅

第60轮训练:
    提取特征 features_epoch60 (特征空间B，已变化！)
    ↓
主进程: 创建新的临时缓存目录 /tmp/knn_cache_yyyyy/
    重新计算 KNN (基于特征空间B) 并保存
    ↓
子进程1-N: 加载新的临时缓存 → 聚类
         ↓
函数结束，临时目录自动删除 ✅
```

**关键保证**：每轮训练使用独立的临时缓存，互不干扰，避免使用过时的KNN

---

### 改进总结

**性能改进**：
- 从序列化完整字典 → 传递轻量字符串
- 从反序列化卡顿 → 按需快速加载（1ms级别）
- 离线场景：从一次性缓存 → 永久复用

**正确性保证**：
- 训练场景：自动清理旧缓存，避免使用过时的KNN
- 离线场景：特征固定，缓存安全复用

---

## 第五部分：方案说明

本方案通过磁盘文件缓存避免了大数组跨进程序列化的瓶颈，并针对两种使用场景采用不同的缓存策略：

### 场景区分

| 场景 | 使用模块 | 特征特点 | 缓存策略 | 清理方式 |
|------|---------|---------|---------|---------|
| **训练循环** | `api.py` | 动态变化 | 临时缓存 | 自动清理 |
| **离线搜索** | `batch_runner.py` | 固定不变 | 持久缓存 | 手动清理 |

### 命令行参数（batch_runner.py）

```bash
# 默认行为：使用持久缓存，支持跨运行复用
python batch_runner.py --superclasses trees,humans --k_min 3 --k_max 21

# 清理旧缓存后重新计算（特征更新后使用）
python batch_runner.py --superclasses trees --clear_knn_cache

# 手动清理所有KNN缓存
rm -rf /path/to/feature_cache/*/knn_cache
```

### 未来优化方向

**如有以下情况，可考虑更优方案**：
- 若k_range非常密集（如100个k值），可改用HDF5格式将所有k的KNN存入单文件，减少文件数量
- 若需要自动检测特征更新，可在缓存文件中保存特征哈希值，自动失效旧缓存
- 若磁盘空间受限，可为batch_runner添加LRU淘汰策略自动清理最久未用的缓存

当前方案优先解决**卡顿问题**、**重复计算问题**和**训练循环中的正确性问题**，在实测后可根据新瓶颈进一步优化。
