# 伪标签损失样本范围控制：Pipeline 超参数

## 背景交代

我们正在开发基于 GCD 的三阶段训练 pipeline。当前实现中：

**当前状态**：
- 伪标签损失只使用**未标注样本**（`mask_lab=False`）
- 已标注样本（`mask_lab=True`）只参与真实标签的监督对比损失
- 导致样本数量严重不平衡：已标注约100个不参与伪标签，未标注约3600个参与伪标签

**核心问题**：
- 聚类时使用了**所有样本**（已标注+未标注）生成伪标签
- 但训练时只用了**未标注样本**的伪标签
- 信息利用不完整，已标注样本在伪标签空间中"缺席"

**用户需求**：
- 增加一个模式开关，控制伪标签损失使用哪些样本
- `mode='off'`：只用未标注样本（当前行为，向后兼容）
- `mode='all'`：所有样本一起参与（已标注+未标注，在同一个对比损失中）

**核心目标**：
1. 解决样本数量不平衡问题
2. 保持聚类结果的完整性（生成时用全部，训练时也用全部）
3. 让已标注样本在伪标签空间中也有表示
4. 通过模式切换验证"全部样本伪标签"的有效性

---

## 代码定位

```
scripts/pseudo_pipeline.py - Pipeline 参数定义与传递
scripts/train_superclass.py - 训练脚本参数定义与训练逻辑
    - build_superclass_train_parser: 参数定义
    - train_superclass: 训练主函数
        - 轮次级别变量定义区域
        - 伪标签损失计算区域（关键修改点）
        - 日志输出区域
```

---

## 第一部分：需求理解

**核心需求**：
- 增加模式选择参数，控制伪标签损失包含哪些样本
- 默认值保持当前行为（只用未标注样本）
- 从 pipeline 自动传递到训练脚本

**保持不变**：
- 真实标签的监督对比损失（sup_con_loss）
- 对比损失（contrastive_loss）
- 伪标签的计算和加载逻辑
- Stage1 和 Stage2 的所有逻辑

**本质分析**：
- **业务动机**：解决样本不平衡（已标注100个 vs 未标注3600个），利用聚类的全局一致性信息
- **技术约束**：必须保持已标注样本的真实标签损失，伪标签只是辅助监督

---

## 第二部分：方案思路

**核心策略**：通过模式参数控制伪标签损失的样本范围，在同一个对比损失中计算

**参数设计**：
- 参数名：`--pseudo_for_labeled_mode`
- 类型：字符串枚举 `{'off', 'all'}`
- 默认值：`'off'`（向后兼容）
- 语义：
  - `'off'`：伪标签损失只用未标注样本（当前行为）
  - `'all'`：伪标签损失用所有样本（已标注+未标注一起）

**控制逻辑伪代码**：
```
if 有伪标签缓存:
    if 模式 == 'off':
        # 当前行为：只用未标注样本
        筛选未标注样本
        提取特征和伪标签
        pseudo_loss = SupConLoss(未标注样本特征, 未标注样本伪标签)

    elif 模式 == 'all':
        # 新行为：所有样本一起
        筛选所有有效伪标签的样本（已标注+未标注）
        提取特征和伪标签
        pseudo_loss = SupConLoss(所有样本特征, 所有样本伪标签)  # 一起对比

    总损失 += γ × λ × pseudo_loss
```

**数据流对比**：
```
【mode='off'】当前行为
Batch中的样本划分：
├─ 已标注样本 (62个)
│  └─ 真实标签 → sup_con_loss
│  └─ 伪标签 → 不参与 ✗
│
└─ 未标注样本 (66个)
   └─ 伪标签 → pseudo_loss (只有这66个在对比)

【mode='all'】新行为
Batch中的样本划分：
├─ 已标注样本 (62个)
│  ├─ 真实标签 → sup_con_loss（保持）
│  └─ 伪标签 → pseudo_loss（和未标注样本一起）✓
│
└─ 未标注样本 (66个)
   └─ 伪标签 → pseudo_loss（和已标注样本一起）✓

伪标签对比损失计算：
SupConLoss(128个样本的特征, 128个样本的伪标签)
→ 已标注和未标注样本在伪标签空间中相互对比
```

**关键原则**：
- **最小侵入性**：只修改样本筛选逻辑，不改变损失计算方式
- **向后兼容**：默认 'off' 保持当前行为
- **全局一致性**：'all' 模式让所有样本在同一个伪标签空间中对比
- **双重监督**：已标注样本同时受真实标签和伪标签的监督

**为什么这是最优方案**：
- **灵活性**：模式切换简单，便于对比实验
- **一致性**：所有样本在同一个对比损失中，全局结构更统一
- **可测试性**：A/B 测试只需切换一个参数
- **理论支撑**：对比学习的本质是让相似样本接近，全部样本参与能提供更强的监督信号

---

## 第三部分：函数层级修改

### 第1层：Pipeline 参数定义

**文件**：`scripts/pseudo_pipeline.py`
**职责**：定义 pipeline 统一管理的超参数

**修改点**：
- 在伪标签相关参数区域，增加模式选择参数
- 参数名：`pseudo_for_labeled_mode`
- 类型：字符串，限制为 `{'off', 'all'}`
- 默认值：`'off'`
- help 说明清晰表达两种模式的含义和区别

**决策**：
- 为什么叫 'all' 而非 'on'？**语义清晰**，明确表示"所有样本"而不只是"开启"
- 为什么默认 'off'？**向后兼容**，避免破坏现有实验
- 为什么用 choices 限制？**防止拼写错误**导致静默失败

---

### 第2层：Pipeline 参数传递

**文件**：`scripts/pseudo_pipeline.py`
**职责**：将 pipeline 参数传递给 Stage3 训练脚本

**修改点**：
- 在构建 Stage3 训练命令时，增加参数传递
- 位置：伪标签相关参数传递区域
- 传递方式：字符串直接传递

**决策**：
- 为什么与伪标签参数放在一起？**逻辑相关**，都是控制伪标签行为

---

### 第3层：训练脚本参数定义

**文件**：`scripts/train_superclass.py`
**职责**：定义训练脚本的命令行参数接口

**修改点**：
- 在 `build_superclass_train_parser` 函数中增加参数定义
- 保持与 pipeline 一致的参数名、类型、默认值、choices

**决策**：
- 为什么重复定义？**独立运行支持**，用户可以绕过 pipeline 直接调用

---

### 第4层：轮次级别变量定义

**文件**：`scripts/train_superclass.py`
**职责**：在每个训练轮次开始前初始化变量

**修改点**：
- 在伪标签相关变量定义区域，增加模式变量
- 使用 `getattr` 读取参数值，默认为 `'off'`
- 如果是 'all' 模式，输出提示信息（让用户知道使用了新模式）

**决策**：
- 为什么在轮次级别定义？**避免批次内重复读取**，提高效率

---

### 第5层：伪标签损失计算逻辑修改（核心）

**文件**：`scripts/train_superclass.py`
**职责**：在训练循环的批次处理中计算伪标签损失

**当前逻辑**：
```
1. 筛选未标注样本（mask_lab=False）
2. 查询这些样本的伪标签
3. 过滤有效伪标签
4. 提取特征
5. 计算 SupConLoss
```

**修改后逻辑**：
```
if 模式 == 'off':
    # 保持当前逻辑
    1. 筛选未标注样本（mask_lab=False）
    2. 查询伪标签
    3. 过滤有效伪标签
    4. 提取特征
    5. SupConLoss(未标注样本)

elif 模式 == 'all':
    # 新逻辑：所有样本
    1. 使用所有样本（不筛选 mask_lab）
    2. 查询伪标签
    3. 过滤有效伪标签（排除 -1）
    4. 提取特征
    5. SupConLoss(所有有效样本)  # 已标注和未标注一起
```

**关键修改点**：
- 样本筛选条件从 `~mask_lab` 改为根据模式决定
- 'off' 模式：`valid_mask = (伪标签 >= 0) AND (未标注)`
- 'all' 模式：`valid_mask = (伪标签 >= 0)`（不管是否标注）
- 后续的特征提取、权重处理、损失计算逻辑完全一致

**决策**：
- 为什么不分别计算已标注和未标注的损失？**违背需求**，用户要的是"一起对比"
- 为什么用 valid_mask 而非两个分支？**代码简洁**，只改筛选条件，其他逻辑复用

**影响检查**：
- 是否影响真实标签损失？**否**，sup_con_loss 完全独立
- 是否影响对比损失？**否**，contrastive_loss 独立
- 是否影响梯度？**是**，已标注样本在 'all' 模式下会受伪标签梯度影响

---

### 第6层：日志输出调整

**文件**：`scripts/train_superclass.py`
**职责**：输出训练日志和 TensorBoard 记录

**修改点**：

1. **控制台输出**：
   - 在轮次开始时，显示当前使用的模式
   - 在损失输出时，显示参与伪标签损失的样本数量
   - 'all' 模式下，样本数应该约等于 batch_size（而非只有未标注样本数）

2. **TensorBoard 记录**：
   - 新增 `Pseudo/mode` 指标：'off'=0.0, 'all'=1.0
   - `Pseudo/samples_per_batch` **已存在**（无需新增），在不同模式下数值会自动变化：
     - 'off' 模式：约66个（未标注样本数）
     - 'all' 模式：约128个（所有有效样本数）

**决策**：
- 为什么新增模式标记？**可追溯性**，TensorBoard 中可以看到使用的配置
- 为什么强调样本数差异？**帮助用户验证**模式是否生效（观察现有指标数值变化即可）

---

## 第四部分：数据流对比

**修改前（mode='off'，当前）**：
```
训练批次 (128样本)
├─ 已标注样本 (62个)
│  ├─ 真实标签 → sup_con_loss ✓
│  └─ 伪标签 → 不参与 ✗
│
└─ 未标注样本 (66个)
   └─ 伪标签 → pseudo_loss ✓

伪标签损失计算：
SupConLoss(66个未标注样本, 66个伪标签)
→ 只有未标注样本之间对比

样本在伪标签空间的表示：
- 已标注样本：缺席 ✗
- 未标注样本：参与 ✓
```

**修改后（mode='all'）**：
```
训练批次 (128样本)
├─ 已标注样本 (62个)
│  ├─ 真实标签 → sup_con_loss ✓
│  └─ 伪标签 → pseudo_loss ✓（和未标注一起）
│
└─ 未标注样本 (66个)
   └─ 伪标签 → pseudo_loss ✓（和已标注一起）

伪标签损失计算：
SupConLoss(128个样本, 128个伪标签)
→ 所有样本在伪标签空间中相互对比

样本在伪标签空间的表示：
- 已标注样本：参与 ✓
- 未标注样本：参与 ✓
→ 全局一致性增强
```

**执行流程对比**：
```
【mode='off' 执行流程】
1. 读取批次数据 (128样本)
2. 计算对比损失（所有样本）
3. 计算监督对比损失（已标注样本，真实标签）
4. 计算伪标签损失：
   ├─ 筛选条件：未标注 AND 伪标签>=0
   ├─ 筛选结果：约66个样本
   ├─ 提取特征：f1[66], f2[66]
   ├─ SupConLoss(66个样本)
   └─ 只有未标注样本参与对比
5. 累加总损失
6. 反向传播

【mode='all' 执行流程】
1. 读取批次数据 (128样本)
2. 计算对比损失（所有样本）
3. 计算监督对比损失（已标注样本，真实标签）
4. 计算伪标签损失：
   ├─ 筛选条件：伪标签>=0（不管是否标注）
   ├─ 筛选结果：约128个样本
   ├─ 提取特征：f1[128], f2[128]
   ├─ SupConLoss(128个样本)
   └─ 已标注和未标注样本一起对比
5. 累加总损失
6. 反向传播
   └─ 已标注样本受到两个梯度：真实标签 + 伪标签
```

**关键差异**：
- **样本范围**：从66个变为128个
- **对比关系**：从"未标注之间"变为"所有样本之间"
- **已标注样本梯度**：从1个来源变为2个来源（真实标签 + 伪标签）

---

## 第五部分：方案说明

### 技术优势

1. **全局一致性**：
   - 所有样本在同一个伪标签空间中对比
   - 已标注样本起到"锚点"作用，帮助对齐真实标签空间和伪标签空间
   - 聚类结果的完整利用（生成时用全部，训练时也用全部）

2. **样本平衡**：
   - 解决严重的样本不平衡问题（100 vs 3600）
   - 已标注样本在伪标签空间中有表示
   - 伪标签损失不会被未标注样本完全主导

3. **双重监督**：
   - 已标注样本：真实标签（主要）+ 伪标签（辅助）
   - 未标注样本：伪标签（唯一监督）
   - 真实标签确保准确性，伪标签提供全局结构约束

4. **向后兼容**：
   - 默认 'off' 模式保持当前行为
   - 用户可以自主选择升级时机
   - 便于对比实验验证效果

### 实验建议

**对比实验设计**：
```
实验组1：mode='off'（基线）
  → 验证当前设计的性能上限

实验组2：mode='all'
  → 验证全局一致性的效果
  → 观察 Old ACC 是否下降（风险点）
  → 观察 New ACC 是否提升（预期收益）
```

**预期效果分析**：
- **Old ACC**：可能持平或微降（已标注样本受伪标签噪声影响）
- **New ACC**：预期提升（未标注样本受已标注样本"锚点"引导）
- **All ACC**：目标是提升（整体性能改善）

**关键观察指标**：
- `Pseudo/samples_per_batch`：从66升到128，验证模式生效
- `Loss/Pseudo`：损失值可能变化，需观察收敛趋势
- Old ACC vs New ACC 的权衡：是否值得用 Old ACC 的小幅下降换取 New ACC 的提升

### 风险与缓解

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|---------|
| **已标注样本性能下降** | 中 | 中 | 伪标签质量要高（ACC>80时生成），降低 `pseudo_loss_weight` |
| **伪标签噪声放大** | 中 | 中 | 使用 `pseudo_weight_mode='density'` 降低低质量样本权重 |
| **训练不稳定** | 低 | 低 | 使用 `warmup_epochs` 延长预热期，慢慢引入伪标签 |
| **梯度冲突** | 低 | 低 | 真实标签损失权重远大于伪标签，主要方向由真实标签控制 |

### 实现注意事项

1. **条件判断简洁**：
   - 只需改变样本筛选条件
   - 后续逻辑完全复用，避免重复代码

2. **验证模式生效**：
   - 观察日志中的样本数变化（66 → 128）
   - TensorBoard 中 `Pseudo/mode` 标记正确

3. **兼容性检查**：
   - 确保旧的伪标签文件（没有 densities）也能正常工作
   - 确保默认行为不变

---

如有更优方案可斟酌后修改。
