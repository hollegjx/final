#!/usr/bin/env python3
"""
è¶…ç±»ç½‘æ ¼æœç´¢è„šæœ¬
ç”¨äºåœ¨CIFAR-100è¶…ç±»ä»»åŠ¡ä¸­å¯¹lrä¸sup_con_weightè¿›è¡Œç½‘æ ¼æœç´¢ï¼Œå¹¶æ™ºèƒ½ç®¡ç†æ¨¡å‹æ–‡ä»¶
"""

import argparse
import itertools
import os
import sys
from copy import deepcopy
from typing import Dict, Optional, Set, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œå¤ç”¨è®­ç»ƒè„šæœ¬ä¸­çš„æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
from tqdm import tqdm

from data.cifar100_superclass import SUPERCLASS_NAMES
from data.get_datasets import get_class_splits
from project_utils.general_utils import init_experiment
from project_utils.superclass_model_saver import SuperclassModelSaver
from scripts.train_superclass import (
    train_single_superclass,
    build_superclass_train_parser
)

# ç½‘æ ¼æœç´¢å›ºå®šçš„å­¦ä¹ ç‡ä¸ sup_con_weight ç½‘æ ¼
DEFAULT_LR_GRID = [0.1, 0.05, 0.01, 0.001]
DEFAULT_SUP_CON_GRID = [round(0.2 + 0.05 * i, 2) for i in range(13)]  # 0.2~0.8 æ­¥é•¿0.05


class SuperclassGridSearchSaver(SuperclassModelSaver):
    """ç½‘æ ¼æœç´¢ä¸“ç”¨ä¿å­˜å™¨ï¼šåªè®°å½•æŒ‡æ ‡ä¸æ—¥å¿—ï¼Œä¸è½åœ°æ¨¡å‹æ–‡ä»¶"""

    def __init__(self, superclass_name: str):
        super().__init__(superclass_name)
        self.run_context: Optional[Dict] = None
        self.current_run_best = -1.0
        self.current_run_metadata: Dict = {}
        self.log_file_path = os.path.join(self.save_dir, 'grid_search_log.txt')
        self._init_log_file()

    def _init_log_file(self):
        """ç¡®ä¿æ—¥å¿—æ–‡ä»¶å­˜åœ¨å¹¶å†™å…¥è¡¨å¤´"""
        if not os.path.exists(self.log_file_path):
            with open(self.log_file_path, 'w', encoding='utf-8') as log_file:
                log_file.write(f"# Grid Search Log for {self.superclass_name}\n")
                log_file.write("# Format: lr sup_con_weight all_acc old_acc new_acc\n")

    def _append_search_log(self, lr: float, sup_con_weight: float,
                           all_acc: float, old_acc: float, new_acc: float):
        """å°†å•æ¬¡ç»„åˆçš„æœ€ä¼˜æŒ‡æ ‡è¿½åŠ åˆ°æ—¥å¿—"""
        log_line = (
            f"lr:{lr} "
            f"sup_con_weight:{sup_con_weight} "
            f"all_acc:{all_acc:.4f} "
            f"old_acc:{old_acc:.4f} "
            f"new_acc:{new_acc:.4f}\n"
        )
        try:
            with open(self.log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(log_line)
        except OSError as exc:
            print(f"âš ï¸ å†™å…¥æœç´¢æ—¥å¿—å¤±è´¥: {exc}")

    def load_completed_runs(self) -> Set[Tuple[float, float]]:
        """è¯»å–æ—¥å¿—æ–‡ä»¶ï¼Œè¿”å›å·²å®Œæˆç»„åˆé›†åˆ"""
        completed: Set[Tuple[float, float]] = set()
        if not os.path.exists(self.log_file_path):
            return completed

        try:
            with open(self.log_file_path, 'r', encoding='utf-8') as log_file:
                for line in log_file:
                    record = line.strip()
                    if not record or record.startswith('#'):
                        continue

                    try:
                        parts = dict(segment.split(':', 1) for segment in record.split())
                        if 'lr' not in parts or 'sup_con_weight' not in parts:
                            continue
                        lr_val = round(float(parts['lr']), 4)
                        sup_val = round(float(parts['sup_con_weight']), 4)
                        completed.add((lr_val, sup_val))
                    except (ValueError, KeyError):
                        continue
        except OSError as exc:
            print(f"âš ï¸ è¯»å–æœç´¢æ—¥å¿—å¤±è´¥: {exc}")

        return completed

    def start_new_run(self, context: Dict):
        """å¼€å§‹æ–°çš„è¶…å‚æ•°ç»„åˆï¼Œé‡ç½®æœ¬è½®ç¼“å­˜"""
        self.run_context = context
        self.current_run_best = -1.0
        self.current_run_metadata = {}

    def save_best_model(self, model, projection_head, acc: float, metadata: Optional[Dict] = None) -> Tuple[Optional[str], Optional[str]]:
        """ç½‘æ ¼æœç´¢æ¨¡å¼ï¼šä¸è½åœ°æ¨¡å‹ï¼Œä»…ç¼“å­˜æœ€ä¼˜æŒ‡æ ‡"""
        if self.run_context is None:
            raise RuntimeError("ä¿å­˜å‰å¿…é¡»å…ˆè°ƒç”¨ start_new_run()")

        metadata = metadata or {}
        if acc > self.current_run_best:
            self.current_run_best = acc
            self.current_run_metadata = metadata
            if acc > self.best_acc:
                self.best_acc = acc

        return None, None

    def finalize_run(self) -> Tuple[str, Optional[Dict]]:
        """ç»“æŸå½“å‰ç»„åˆï¼Œä»…å†™å…¥æ—¥å¿—"""
        if self.run_context is None or self.current_run_best < 0:
            self.current_run_best = -1.0
            self.current_run_metadata = {}
            return "skipped", None

        hyperparams = self.run_context.get('hyperparams', {})
        self._append_search_log(
            lr=hyperparams.get('lr', 0.0),
            sup_con_weight=hyperparams.get('sup_con_weight', 0.0),
            all_acc=self.current_run_metadata.get('all_acc_test', 0.0),
            old_acc=self.current_run_metadata.get('old_acc_test', 0.0),
            new_acc=self.current_run_metadata.get('new_acc_test', 0.0)
        )

        logged_metadata = self.current_run_metadata
        self.current_run_best = -1.0
        self.current_run_metadata = {}
        return "logged", logged_metadata

    def cleanup_keep_best_only(self):
        """ç½‘æ ¼æœç´¢æ¨¡å¼æ— éœ€æ¸…ç†æ¨¡å‹æ–‡ä»¶"""
        return


class GridSearchManager:
    """åè°ƒå¤šè¶…ç±»ç½‘æ ¼æœç´¢æµç¨‹"""

    def __init__(self, args):
        self.args = args
        self.device = self._prepare_device(args.gpu)
        self.args.device = self.device
        self.learning_rates = DEFAULT_LR_GRID
        self.sup_con_weights = DEFAULT_SUP_CON_GRID

    @staticmethod
    def _prepare_device(gpu_index: int):
        if torch.cuda.is_available():
            device = torch.device(f'cuda:{gpu_index}')
            torch.cuda.set_device(gpu_index)
            print(f"ğŸ›ï¸  ä½¿ç”¨GPU: cuda:{gpu_index}")
        else:
            device = torch.device('cpu')
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ‰§è¡Œç½‘æ ¼æœç´¢")
        return device

    def run(self):
        summary: Dict[str, Dict] = {}

        print(f"\n{'=' * 70}")
        print("ğŸ“‹ CIFAR-100 å¯ç”¨è¶…ç±»åˆ—è¡¨ï¼ˆå…±15ä¸ªï¼‰:")
        for idx, name in enumerate(SUPERCLASS_NAMES, start=1):
            print(f"  {idx:2d}. {name}")
        print(f"{'=' * 70}")
        print(f"æœ¬æ¬¡æœç´¢è¶…ç±»: {', '.join(self.args.superclasses)}")
        print(f"{'=' * 70}")

        for superclass in self.args.superclasses:
            if superclass not in SUPERCLASS_NAMES:
                print(f"âŒ è¶…ç±» '{superclass}' éæ³•ï¼Œè·³è¿‡")
                continue

            print(f"\n{'=' * 70}")
            print(f"ğŸ” å¼€å§‹è¶…ç±» '{superclass}' çš„ç½‘æ ¼æœç´¢")
            saver = SuperclassGridSearchSaver(superclass)

            best_info = self._search_single_superclass(superclass, saver)
            saver.cleanup_keep_best_only()
            if best_info['acc'] >= 0:
                print(
                    f"ğŸ“Œ è¶…ç±» '{superclass}' æœ€ä½³ç»„åˆ: lr={best_info['lr']} "
                    f"sup_con_weight={best_info['sup_con_weight']} "
                    f"(éœ€ä½¿ç”¨è¯¥è¶…å‚æ•°å•ç‹¬è®­ç»ƒä»¥å¯¼å‡ºæ¨¡å‹)"
                )
            else:
                print(f"âš ï¸  è¶…ç±» '{superclass}' æœªèƒ½å¾—åˆ°æœ‰æ•ˆçš„ç»„åˆç»“æœ")
            summary[superclass] = best_info

        self._print_summary(summary)

    def _search_single_superclass(self, superclass: str, saver: SuperclassGridSearchSaver) -> Dict:
        best_result = {
            'acc': -1.0,
            'lr': None,
            'sup_con_weight': None,
            'model_path': None,
            'params_path': None
        }

        def _quantize(value: float) -> float:
            return round(float(value), 4)

        combos = list(itertools.product(self.learning_rates, self.sup_con_weights))
        combo_keys = {(_quantize(lr), _quantize(sup)) for lr, sup in combos}
        total_combos = len(combos)

        completed_runs = saver.load_completed_runs()
        completed_in_grid = completed_runs & combo_keys
        completed_count = len(completed_in_grid)
        pending_count = max(total_combos - completed_count, 0)

        historical_best = self._restore_best_from_log(saver) if completed_count else None
        if historical_best and historical_best['acc'] > best_result['acc']:
            best_result = historical_best

        if completed_count:
            print(
                f"â„¹ï¸  è¶…ç±» '{superclass}' å·²å®Œæˆ {completed_count}/{total_combos} ä¸ªç»„åˆï¼Œæœ¬æ¬¡é¢„è®¡è®­ç»ƒ {pending_count} ä¸ªç»„åˆ"
            )
        else:
            print(f"â„¹ï¸  æœªæ£€æµ‹åˆ° '{superclass}' çš„å†å²ç½‘æ ¼æœç´¢è®°å½•ï¼Œå°†å®Œæ•´éå† {total_combos} ä¸ªç»„åˆ")

        skipped_count = 0

        outer_pbar = tqdm(
            combos,
            desc=f"[{superclass}] ç½‘æ ¼æœç´¢",
            position=0,
            leave=True,
            dynamic_ncols=True
        )
        try:
            for lr, sup_weight in outer_pbar:
                quantized_lr = _quantize(lr)
                quantized_sup = _quantize(sup_weight)

                outer_pbar.set_postfix({
                    'lr': f"{lr:.3f}",
                    'sup': f"{sup_weight:.3f}",
                    'best_acc': f"{best_result['acc']:.4f}" if best_result['acc'] >= 0 else "N/A"
                })

                if (quantized_lr, quantized_sup) in completed_in_grid:
                    skipped_count += 1
                    outer_pbar.update(1)
                    outer_pbar.set_postfix({
                        'lr': f"{lr:.3f}",
                        'sup': f"{sup_weight:.3f}",
                        'best_acc': f"{best_result['acc']:.4f}" if best_result['acc'] >= 0 else "N/A",
                        'status': 'skipped'
                    })
                    tqdm.write(
                        f"â­ï¸  ç»„åˆå·²å®Œæˆï¼Œè·³è¿‡ lr={lr:.4f} sup_con_weight={sup_weight:.4f}"
                    )
                    continue

                run_args = self._prepare_run_args(superclass, lr, sup_weight)

                saver.start_new_run({
                    'hyperparams': self._collect_hparams(run_args)
                })

                # è®­ç»ƒå¹¶è®°å½•æ˜¯å¦æˆåŠŸ
                training_success = False
                try:
                    _, _, best_acc = train_single_superclass(
                        run_args,
                        model_saver=saver,
                        progress_parent=outer_pbar
                    )
                    training_success = True
                except Exception as exc:
                    tqdm.write(f"âš ï¸  è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡è¯¥ç»„åˆ: {exc}")
                    if hasattr(run_args, 'writer') and run_args.writer:
                        run_args.writer.close()
                    best_acc = -1.0

                # âœ… æ— è®ºè®­ç»ƒæ˜¯å¦æˆåŠŸï¼Œéƒ½è°ƒç”¨finalize_runå†™å…¥æ—¥å¿—æˆ–å¤ä½çŠ¶æ€
                status, _ = saver.finalize_run()

                # åªæœ‰è®­ç»ƒæˆåŠŸæ—¶æ‰æ›´æ–°æœ€ä½³ç»“æœ
                if training_success:
                    tqdm.write(f"   âœ… ç»„åˆå®Œæˆï¼Œæœ€ä¼˜all_acc_test={best_acc:.4f}ï¼Œæ ‡è®°ä¸º{status}")

                    if best_acc > best_result['acc']:
                        best_result.update({
                            'acc': best_acc,
                            'lr': lr,
                            'sup_con_weight': sup_weight,
                            'model_path': None,
                            'params_path': None
                        })
                        outer_pbar.set_postfix({
                            'lr': f"{lr:.3f}",
                            'sup': f"{sup_weight:.3f}",
                            'best_acc': f"{best_acc:.4f}"
                        })

                    if hasattr(run_args, 'writer') and run_args.writer:
                        run_args.writer.close()
        finally:
            outer_pbar.close()

        if skipped_count:
            print(f"â­ï¸  è¶…ç±» '{superclass}' å…±è·³è¿‡ {skipped_count} ä¸ªç»„åˆ")
        if best_result['acc'] < 0 and skipped_count == total_combos:
            restored = self._restore_best_from_log(saver)
            if restored:
                best_result = restored
                print(
                    f"â„¹ï¸  æ‰€æœ‰ç»„åˆå‡ç”±æ—¥å¿—æ¢å¤ï¼Œbest_all_acc={best_result['acc']:.4f} "
                    f"lr={best_result['lr']} sup_con_weight={best_result['sup_con_weight']}"
                )

        return best_result

    def _prepare_run_args(self, superclass: str, lr: float, sup_weight: float):
        run_args = deepcopy(self.args)
        run_args.superclass_name = superclass
        run_args.train_all_superclasses = False
        run_args.lr = lr
        run_args.sup_con_weight = sup_weight
        run_args.dataset_name = 'cifar100_superclass'
        run_args.is_grid_search = True

        run_args = get_class_splits(run_args)
        run_args.num_labeled_classes = len(run_args.train_classes)
        run_args.num_unlabeled_classes = len(run_args.unlabeled_classes)

        run_args.exp_name = self._build_experiment_name(superclass, lr, sup_weight)
        init_experiment(run_args, runner_name=['grid_search_superclass'])
        run_args.device = self.device

        return run_args

    @staticmethod
    def _collect_hparams(args) -> Dict:
        return {
            'lr': args.lr,
            'sup_con_weight': args.sup_con_weight,
            'epochs': args.epochs,
            'batch_size': args.batch_size,
            'grad_from_block': args.grad_from_block,
            'weight_decay': args.weight_decay,
            'momentum': args.momentum,
            'temperature': args.temperature,
            'n_views': args.n_views,
            'contrast_unlabel_only': args.contrast_unlabel_only,
            'seed': args.seed
        }

    @staticmethod
    def _build_experiment_name(superclass: str, lr: float, sup_weight: float) -> str:
        def _sanitize(value: float) -> str:
            text = f"{value:.4f}".rstrip('0').rstrip('.')
            return text.replace('.', 'p') if text else "0"

        lr_tag = _sanitize(lr)
        sup_tag = _sanitize(sup_weight)
        return f"grid_{superclass}_lr{lr_tag}_sup{sup_tag}"

    @staticmethod
    def _print_summary(summary: Dict[str, Dict]):
        if not summary:
            print("\nâš ï¸ æœªè·å¾—ä»»ä½•æœ‰æ•ˆç»“æœ")
            return

        print(f"\n{'=' * 70}")
        print("ğŸ“‹ ç½‘æ ¼æœç´¢æ±‡æ€»ï¼ˆæ¨¡å‹æœªä¿å­˜ï¼Œè¯·ç”¨æœ€ä½³è¶…å‚æ•°é‡æ–°è®­ç»ƒè·å–æœ€ç»ˆæ¨¡å‹ï¼‰")
        for superclass, info in summary.items():
            if info['acc'] < 0:
                print(f" - {superclass}: æ— æœ‰æ•ˆæ¨¡å‹")
                continue
            print(f" - {superclass}: best_all_acc={info['acc']:.4f} | lr={info['lr']} | sup_con_weight={info['sup_con_weight']}")
            if info['model_path']:
                print(f"   æ¨¡å‹: {info['model_path']}")
            if info['params_path']:
                print(f"   å‚æ•°: {info['params_path']}")

    @staticmethod
    def _restore_best_from_log(saver: SuperclassGridSearchSaver) -> Optional[Dict]:
        """å½“å…¨éƒ¨ç»„åˆè¢«è·³è¿‡æ—¶ï¼Œä»æ—¥å¿—ä¸­æ¢å¤æœ€ä½³æŒ‡æ ‡"""
        if not os.path.exists(saver.log_file_path):
            return None

        best_entry: Optional[Dict] = None
        try:
            with open(saver.log_file_path, 'r', encoding='utf-8') as log_file:
                for line in log_file:
                    record = line.strip()
                    if not record or record.startswith('#'):
                        continue

                    try:
                        parts = dict(segment.split(':', 1) for segment in record.split())
                        required = ('lr', 'sup_con_weight', 'all_acc')
                        if not all(key in parts for key in required):
                            continue
                        all_acc = float(parts['all_acc'])
                        lr_val = float(parts['lr'])
                        sup_val = float(parts['sup_con_weight'])
                    except (ValueError, KeyError):
                        continue

                    if best_entry is None or all_acc > best_entry['acc']:
                        best_entry = {
                            'acc': all_acc,
                            'lr': lr_val,
                            'sup_con_weight': sup_val,
                            'model_path': None,
                            'params_path': None
                        }
        except OSError as exc:
            print(f"âš ï¸  è¯»å–æ—¥å¿—æ¢å¤æœ€ä½³ç»“æœå¤±è´¥: {exc}")
            return None

        return best_entry


def parse_args():
    base_parser = build_superclass_train_parser(add_help=False)  # ç¦ç”¨çˆ¶parserçš„å¸®åŠ©
    parser = argparse.ArgumentParser(
        description='CIFAR-100è¶…ç±»ç½‘æ ¼æœç´¢å·¥å…·',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        parents=[base_parser],
        add_help=True  # å½“å‰parserå¯ç”¨å¸®åŠ©
    )

    parser.add_argument('--superclasses', nargs='+', default=SUPERCLASS_NAMES,
                        help='éœ€è¦æ‰§è¡Œç½‘æ ¼æœç´¢çš„è¶…ç±»åˆ—è¡¨')

    # æ‰¹é‡æœç´¢é»˜è®¤è®­ç»ƒ200è½®ï¼ˆæ—©åœä¼šæå‰ç»“æŸï¼‰
    parser.set_defaults(epochs=200)

    return parser.parse_args()


def main():
    args = parse_args()
    args.train_all_superclasses = False
    manager = GridSearchManager(args)
    manager.run()


if __name__ == "__main__":
    main()
